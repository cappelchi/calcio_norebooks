{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JnoakdYG0WIm",
        "7dEcqW_jH4pw",
        "X69hHEsFix4n",
        "RocnM6a5lPkc"
      ],
      "authorship_tag": "ABX9TyMEINK/h1ZJOr0vqjkEhVvr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cappelchi/calcio_notebooks/blob/main/draft/football_GRAPH_prediction_disjoint_spektral_models_train_test_221029.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project config"
      ],
      "metadata": {
        "id": "JnoakdYG0WIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neptune-client neptune-tensorflow-keras"
      ],
      "metadata": {
        "id": "qJoD3JIX0x58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbc37ee-a5f3-441a-e677-09595e713075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neptune-client\n",
            "  Downloading neptune-client-0.16.11.tar.gz (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting neptune-tensorflow-keras\n",
            "  Downloading neptune-tensorflow-keras-1.1.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bravado<12.0.0,>=11.0.0\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.16.0\n",
            "  Downloading boto3-1.25.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting swagger-spec-validator>=2.7.4\n",
            "  Downloading swagger_spec_validator-3.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Collecting importlib-metadata<4\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting botocore<1.29.0,>=1.28.4\n",
            "  Downloading botocore-1.28.4-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.4->boto3>=1.16.0->neptune-client) (2.8.2)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.1.1)\n",
            "Collecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.1-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.4)\n",
            "Collecting jsonref\n",
            "  Downloading jsonref-1.0.0.post1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (2022.5)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (4.3.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->neptune-client) (3.9.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (22.1.0)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (2.10)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2022.9.24)\n",
            "Requirement already satisfied: tensorflow>2.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-tensorflow-keras) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (2.0.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.50.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (0.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.0.0->neptune-tensorflow-keras) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>2.0.0->neptune-tensorflow-keras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>2.0.0->neptune-tensorflow-keras) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (4.9)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.1 MB/s \n",
            "\u001b[?25h  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s \n",
            "\u001b[?25h  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.2 MB/s \n",
            "\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>2.0.0->neptune-tensorflow-keras) (0.4.8)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (3.0.9)\n",
            "Building wheels for collected packages: neptune-client, future, neptune-tensorflow-keras\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.16.11-py2.py3-none-any.whl size=426888 sha256=5566b32719bf32c47ee6f809b64c9b9bb8b73fccab18ce11fe7571bfcaff715f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/42/aa/a62cc1a67cc458039f574d6dbb193156521b7c76200879fd3c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ba347f43616b2c333ea233ee3979447628a7cf6178c77f49a84d37f3baafb998\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for neptune-tensorflow-keras (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-tensorflow-keras: filename=neptune_tensorflow_keras-1.1.0-py3-none-any.whl size=10916 sha256=89cf41cf79870f5df1499d8967bdf5f9433523d1ecadfa1c427caca22d93f771\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/dc/a44ae47d486c26d3ed9a738f2c7268cb0e72bf9b424d39bc45\n",
            "Successfully built neptune-client future neptune-tensorflow-keras\n",
            "Installing collected packages: urllib3, importlib-metadata, arrow, webcolors, uri-template, rfc3987, rfc3339-validator, jsonpointer, jmespath, isoduration, fqdn, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, markdown, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client, neptune-tensorflow-keras\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.4.1\n",
            "    Uninstalling Markdown-3.4.1:\n",
            "      Successfully uninstalled Markdown-3.4.1\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.29 PyJWT-2.6.0 arrow-1.2.3 boto3-1.25.4 botocore-1.28.4 bravado-11.0.3 bravado-core-5.17.1 fqdn-1.5.1 future-0.18.2 gitdb-4.0.9 importlib-metadata-3.10.1 isoduration-20.11.0 jmespath-1.0.1 jsonpointer-2.3 jsonref-1.0.0.post1 markdown-3.3.4 monotonic-1.6 neptune-client-0.16.11 neptune-tensorflow-keras-1.1.0 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.6.0 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-3.0.2 uri-template-1.2.0 urllib3-1.25.11 webcolors-1.12 websocket-client-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune.new as neptune\n",
        "#from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "def get_credential(frmwork = 'neptune_team'):\n",
        "    with open('cred_andrey.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw"
      ],
      "metadata": {
        "id": "O9bCK_dx0QSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set API key for neptune.ai\n",
        "set_api = True #@param {type:\"boolean\"}\n",
        "if set_api:\n",
        "    username, api_key = get_credential()"
      ],
      "metadata": {
        "id": "oDK6n6CVQidT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dEcqW_jH4pw"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spektral"
      ],
      "metadata": {
        "id": "dP-bo_CB7GgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357209d2-23d4-4839-b377-a18937ee38ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.2.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.21.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.3.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.50.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.27.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2.0->spektral) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.10.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.2.0->spektral) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->spektral) (3.1.0)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X69hHEsFix4n"
      },
      "source": [
        "### Downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_version = 'data_graph_221019/'\n",
        "validation_dataset_name = './prem_validation.csv'\n",
        "dataset_version = 'data/dataset_val_prod_0818'\n",
        "project = neptune.init_project(\n",
        "    name=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "\n",
        "project[data_version + 'nodes'].download('./nodes.csv.gz')\n",
        "project[data_version + 'edges'].download('./edges.csv.gz')\n",
        "project[data_version + 'conversion'].download('./conversion.csv.gz')\n",
        "project.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFhlCBt1jw8",
        "outputId": "4c2d3f55-35bc-490d-ab4d-914926a2e5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RocnM6a5lPkc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyCzUjbzRuA",
        "outputId": "726d9ebf-06ac-44ea-915b-cfa414600fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n",
            "1.21.6\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 100\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse as sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbfhlbNrIf2v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "5-uRpl6v6u87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spektral.data.loaders import SingleLoader, DisjointLoader\n",
        "from spektral.datasets.citation import Citation\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.transforms import LayerPreprocess"
      ],
      "metadata": {
        "id": "GJrptVxI76Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spektral.data import Dataset, Graph\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj"
      ],
      "metadata": {
        "id": "6NqujUkhOmrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umm53OS2Ljgg"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class calcio_graph(Dataset):\n",
        "    def __init__(self, amount = 500_000, left = 0, train = 350_000, validation = 10_000, **kwargs):\n",
        "        self.amount = amount\n",
        "        self.left = left\n",
        "        self.train = train\n",
        "        self.validation = validation\n",
        "        self.mask_tr = self.mask_va = self.mask_te = None\n",
        "        super().__init__(**kwargs)\n",
        "    def read(self):\n",
        "        print('Load nodes...')\n",
        "        x_df = pd.read_csv('./nodes.csv.gz', usecols = [0, 1, 2], header = 0, names = ['idx','feat', 'y'])\n",
        "        lower_slice = -self.left\n",
        "        if self.left == 0:\n",
        "            lower_slice = None            \n",
        "        x_df = x_df.iloc[-self.amount - self.left:lower_slice, :].set_index('idx').sort_index()\n",
        "        x = np.zeros((len(x_df), max(x_df.feat) + 1)).astype(np.float32)\n",
        "        for cnt, feat in enumerate(x_df.feat):\n",
        "            x[cnt, feat] = 1\n",
        "        print('Load edges...')\n",
        "        start_row = x_df.index.min()\n",
        "        end_row = x_df.index.max()\n",
        "        edges_df = pd.read_csv('./edges.csv.gz')\n",
        "        #edges_df = edges_df[(edges_df.source < self.amount) & (edges_df.target < self.amount)]\n",
        "        edges_df = edges_df[(edges_df.source >= start_row) & \\\n",
        "                            (edges_df.source <= end_row) & \\\n",
        "                            (edges_df.target >= start_row) & \\\n",
        "                            (edges_df.target <= end_row)]\n",
        "        edges_df.source = edges_df.source - start_row\n",
        "        edges_df.target = edges_df.target - start_row\n",
        "        a = sp.csr_matrix((\n",
        "            np.ones(len(edges_df)), \n",
        "            (edges_df.source.values, edges_df.target.values)\n",
        "                            ), shape=None).astype(np.float32)\n",
        "        y = x_df.y.values.reshape(-1,1).astype(np.float32)\n",
        "        self.mask_tr = np.arange(self.amount) < int(self.train)\n",
        "        self.mask_va = (np.arange(self.amount) >= int(self.train)) & \\\n",
        "                        (np.arange(self.amount) < int(self.amount - self.validation))\n",
        "        self.mask_te = np.arange(self.amount) >= int(self.amount - self.validation)\n",
        "        return [Graph(x = x, a = a, y = y)]"
      ],
      "metadata": {
        "id": "LdcMR1-bKY0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2v0RQst89VZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9rGIUwV9VTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6eqIx7x89VQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vrz3Qujs9VM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "devHk6c09VJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGCN:\n",
        "    def __init__(self, K):\n",
        "        self.K = K\n",
        "\n",
        "    def __call__(self, graph):\n",
        "        out = graph.a\n",
        "        for _ in range(self.K - 1):\n",
        "            out = out.dot(out)\n",
        "        out.sort_indices()\n",
        "        graph.a = out\n",
        "        return graph"
      ],
      "metadata": {
        "id": "Scl-Qp_zYDk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2\n",
        "dataset = calcio_graph(\n",
        "                    amount = 500_000,\n",
        "                    left = 10_000,\n",
        "                    #transforms=[LayerPreprocess(GCNConv)]#, SGCN(K)]\n",
        "                    #transforms=[SGCN(K)]\n",
        "                    #transforms=[LayerPreprocess(GCNConv), AdjToSpTensor()]\n",
        "                    #transforms=[LayerPreprocess(ARMAConv)]\n",
        "                    #transforms=[NormalizeAdj()]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOj3rdNVOG56",
        "outputId": "268f88a1-379f-4b7b-8406-ec0c91bfa70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load nodes...\n",
            "Load edges...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzc35k4-4Ykp",
        "outputId": "b1dc4397-b83d-4a08-c93c-6915823a555b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(n_nodes=500000, n_node_features=793, n_edge_features=None, n_labels=1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0].a)"
      ],
      "metadata": {
        "id": "1Cv9vjKZRc3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "id": "yjZ7gx5WPuyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_tr.sum(), mask_va.sum(), mask_te.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQwHEMpBNS_f",
        "outputId": "5db82b5c-5c80-438e-ae8b-2b8df4c1944b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(350000, 140000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "l2_reg = 5e-6  # L2 regularization rate\n",
        "learning_rate = 0.005  # Learning rate\n",
        "epochs = 200  # Number of training epochs\n",
        "patience = 50  # Patience for early stopping\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1"
      ],
      "metadata": {
        "id": "oBm-44LAVEEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = dataset.n_nodes  # Number of nodes in the graph\n",
        "F = dataset.n_node_features  # Original size of node features\n",
        "n_out = dataset.n_labels  # Number of classes"
      ],
      "metadata": {
        "id": "SkMCDo1WVPZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, F, n_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8tIQkHsYpfP",
        "outputId": "ee7c0484-65da-4a13-8f88-13129045cef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500000, 793, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "x_in = Input(shape=(F,))\n",
        "a_in = Input((N,), sparse=True, dtype=a_dtype)"
      ],
      "metadata": {
        "id": "q-W7hSJdVS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = GCNConv(\n",
        "    n_out, activation = \"sigmoid\", kernel_regularizer=l2(l2_reg), use_bias=False\n",
        ")([x_in, a_in])"
      ],
      "metadata": {
        "id": "F5LHy0snVXb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "model = Model(inputs=[x_in, a_in], outputs=output)\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", weighted_metrics=[\"acc\"]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4nJPcG3VXXT",
        "outputId": "3a931b69-3e5a-4772-8804-d83301a3a89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 793)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 500000)]     0           []                               \n",
            "                                                                                                  \n",
            " gcn_conv_1 (GCNConv)           (None, 1)            793         ['input_3[0][0]',                \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 793\n",
            "Trainable params: 793\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)"
      ],
      "metadata": {
        "id": "fGSAd7QuVXMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=1000,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "plnj_yYqXM4Y",
        "outputId": "76ae5f24-23f7-4a5c-f09e-b63fa968ab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4847 - acc: 0.5190 - val_loss: 0.1936 - val_acc: 0.5421\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4839 - acc: 0.5431 - val_loss: 0.1933 - val_acc: 0.5655\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4831 - acc: 0.5690 - val_loss: 0.1930 - val_acc: 0.5858\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4824 - acc: 0.5901 - val_loss: 0.1927 - val_acc: 0.6025\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4816 - acc: 0.6086 - val_loss: 0.1924 - val_acc: 0.6190\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4808 - acc: 0.6273 - val_loss: 0.1921 - val_acc: 0.6344\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4800 - acc: 0.6430 - val_loss: 0.1918 - val_acc: 0.6469\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4793 - acc: 0.6556 - val_loss: 0.1915 - val_acc: 0.6590\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4785 - acc: 0.6685 - val_loss: 0.1912 - val_acc: 0.6701\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4777 - acc: 0.6791 - val_loss: 0.1909 - val_acc: 0.6788\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4770 - acc: 0.6876 - val_loss: 0.1906 - val_acc: 0.6878\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.4762 - acc: 0.6974 - val_loss: 0.1903 - val_acc: 0.6952\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4755 - acc: 0.7038 - val_loss: 0.1900 - val_acc: 0.7013\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4747 - acc: 0.7104 - val_loss: 0.1898 - val_acc: 0.7063\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4740 - acc: 0.7151 - val_loss: 0.1895 - val_acc: 0.7097\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4732 - acc: 0.7190 - val_loss: 0.1892 - val_acc: 0.7134\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4725 - acc: 0.7226 - val_loss: 0.1889 - val_acc: 0.7145\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4717 - acc: 0.7237 - val_loss: 0.1886 - val_acc: 0.7148\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4710 - acc: 0.7239 - val_loss: 0.1883 - val_acc: 0.7150\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4702 - acc: 0.7239 - val_loss: 0.1881 - val_acc: 0.7153\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.4695 - acc: 0.7240 - val_loss: 0.1878 - val_acc: 0.7155\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4688 - acc: 0.7240 - val_loss: 0.1875 - val_acc: 0.7157\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4681 - acc: 0.7241 - val_loss: 0.1872 - val_acc: 0.7160\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.4673 - acc: 0.7241 - val_loss: 0.1869 - val_acc: 0.7163\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.4666 - acc: 0.7241 - val_loss: 0.1867 - val_acc: 0.7166\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4659 - acc: 0.7241 - val_loss: 0.1864 - val_acc: 0.7169\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4652 - acc: 0.7241 - val_loss: 0.1861 - val_acc: 0.7172\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4644 - acc: 0.7241 - val_loss: 0.1858 - val_acc: 0.7174\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.4637 - acc: 0.7242 - val_loss: 0.1856 - val_acc: 0.7178\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4630 - acc: 0.7242 - val_loss: 0.1853 - val_acc: 0.7181\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4623 - acc: 0.7242 - val_loss: 0.1850 - val_acc: 0.7183\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4616 - acc: 0.7243 - val_loss: 0.1848 - val_acc: 0.7185\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4609 - acc: 0.7243 - val_loss: 0.1845 - val_acc: 0.7189\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4602 - acc: 0.7243 - val_loss: 0.1842 - val_acc: 0.7193\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4595 - acc: 0.7243 - val_loss: 0.1840 - val_acc: 0.7197\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4588 - acc: 0.7244 - val_loss: 0.1837 - val_acc: 0.7200\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.4581 - acc: 0.7245 - val_loss: 0.1835 - val_acc: 0.7203\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4575 - acc: 0.7245 - val_loss: 0.1832 - val_acc: 0.7206\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4568 - acc: 0.7246 - val_loss: 0.1830 - val_acc: 0.7208\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.4561 - acc: 0.7247 - val_loss: 0.1827 - val_acc: 0.7210\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.4554 - acc: 0.7247 - val_loss: 0.1824 - val_acc: 0.7212\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4547 - acc: 0.7247 - val_loss: 0.1822 - val_acc: 0.7216\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4541 - acc: 0.7248 - val_loss: 0.1819 - val_acc: 0.7218\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4534 - acc: 0.7248 - val_loss: 0.1817 - val_acc: 0.7220\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4527 - acc: 0.7248 - val_loss: 0.1814 - val_acc: 0.7221\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4521 - acc: 0.7249 - val_loss: 0.1812 - val_acc: 0.7224\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4514 - acc: 0.7249 - val_loss: 0.1810 - val_acc: 0.7226\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.4508 - acc: 0.7250 - val_loss: 0.1807 - val_acc: 0.7230\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4501 - acc: 0.7251 - val_loss: 0.1805 - val_acc: 0.7232\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4495 - acc: 0.7252 - val_loss: 0.1802 - val_acc: 0.7235\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4488 - acc: 0.7252 - val_loss: 0.1800 - val_acc: 0.7237\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4482 - acc: 0.7252 - val_loss: 0.1797 - val_acc: 0.7238\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.4475 - acc: 0.7252 - val_loss: 0.1795 - val_acc: 0.7241\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.4469 - acc: 0.7252 - val_loss: 0.1793 - val_acc: 0.7243\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4462 - acc: 0.7252 - val_loss: 0.1790 - val_acc: 0.7245\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4456 - acc: 0.7252 - val_loss: 0.1788 - val_acc: 0.7245\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.4450 - acc: 0.7252 - val_loss: 0.1786 - val_acc: 0.7247\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4444 - acc: 0.7252 - val_loss: 0.1783 - val_acc: 0.7249\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4437 - acc: 0.7252 - val_loss: 0.1781 - val_acc: 0.7251\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4431 - acc: 0.7254 - val_loss: 0.1779 - val_acc: 0.7253\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.4425 - acc: 0.7254 - val_loss: 0.1776 - val_acc: 0.7255\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.4419 - acc: 0.7257 - val_loss: 0.1774 - val_acc: 0.7257\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4413 - acc: 0.7258 - val_loss: 0.1772 - val_acc: 0.7257\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.4406 - acc: 0.7258 - val_loss: 0.1770 - val_acc: 0.7258\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.4400 - acc: 0.7258 - val_loss: 0.1767 - val_acc: 0.7261\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4394 - acc: 0.7259 - val_loss: 0.1765 - val_acc: 0.7261\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4388 - acc: 0.7258 - val_loss: 0.1763 - val_acc: 0.7263\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4382 - acc: 0.7258 - val_loss: 0.1761 - val_acc: 0.7265\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4376 - acc: 0.7259 - val_loss: 0.1759 - val_acc: 0.7265\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4370 - acc: 0.7258 - val_loss: 0.1756 - val_acc: 0.7266\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.4365 - acc: 0.7258 - val_loss: 0.1754 - val_acc: 0.7268\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.4359 - acc: 0.7258 - val_loss: 0.1752 - val_acc: 0.7271\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4353 - acc: 0.7259 - val_loss: 0.1750 - val_acc: 0.7272\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.4347 - acc: 0.7259 - val_loss: 0.1748 - val_acc: 0.7272\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4341 - acc: 0.7260 - val_loss: 0.1746 - val_acc: 0.7274\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.4335 - acc: 0.7260 - val_loss: 0.1744 - val_acc: 0.7276\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4330 - acc: 0.7261 - val_loss: 0.1742 - val_acc: 0.7276\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.4324 - acc: 0.7260 - val_loss: 0.1740 - val_acc: 0.7276\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 1s 639ms/step - loss: 0.4318 - acc: 0.7260 - val_loss: 0.1737 - val_acc: 0.7278\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4312 - acc: 0.7260 - val_loss: 0.1735 - val_acc: 0.7278\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4307 - acc: 0.7259 - val_loss: 0.1733 - val_acc: 0.7279\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.4301 - acc: 0.7260 - val_loss: 0.1731 - val_acc: 0.7279\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.4296 - acc: 0.7260 - val_loss: 0.1729 - val_acc: 0.7280\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4290 - acc: 0.7259 - val_loss: 0.1727 - val_acc: 0.7279\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4285 - acc: 0.7259 - val_loss: 0.1725 - val_acc: 0.7282\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4279 - acc: 0.7260 - val_loss: 0.1723 - val_acc: 0.7283\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4274 - acc: 0.7260 - val_loss: 0.1721 - val_acc: 0.7283\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4268 - acc: 0.7261 - val_loss: 0.1719 - val_acc: 0.7284\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4263 - acc: 0.7261 - val_loss: 0.1717 - val_acc: 0.7286\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4257 - acc: 0.7262 - val_loss: 0.1716 - val_acc: 0.7286\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4252 - acc: 0.7262 - val_loss: 0.1714 - val_acc: 0.7287\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4246 - acc: 0.7262 - val_loss: 0.1712 - val_acc: 0.7287\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4241 - acc: 0.7264 - val_loss: 0.1710 - val_acc: 0.7288\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4236 - acc: 0.7265 - val_loss: 0.1708 - val_acc: 0.7288\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4231 - acc: 0.7266 - val_loss: 0.1706 - val_acc: 0.7289\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.4225 - acc: 0.7266 - val_loss: 0.1704 - val_acc: 0.7290\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.4220 - acc: 0.7266 - val_loss: 0.1702 - val_acc: 0.7290\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4215 - acc: 0.7266 - val_loss: 0.1700 - val_acc: 0.7290\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.4210 - acc: 0.7266 - val_loss: 0.1699 - val_acc: 0.7290\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4204 - acc: 0.7267 - val_loss: 0.1697 - val_acc: 0.7291\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4199 - acc: 0.7268 - val_loss: 0.1695 - val_acc: 0.7292\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4194 - acc: 0.7268 - val_loss: 0.1693 - val_acc: 0.7293\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.4189 - acc: 0.7269 - val_loss: 0.1691 - val_acc: 0.7293\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.4184 - acc: 0.7269 - val_loss: 0.1690 - val_acc: 0.7294\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.4179 - acc: 0.7270 - val_loss: 0.1688 - val_acc: 0.7295\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 1s 638ms/step - loss: 0.4174 - acc: 0.7272 - val_loss: 0.1686 - val_acc: 0.7296\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4169 - acc: 0.7272 - val_loss: 0.1684 - val_acc: 0.7296\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4164 - acc: 0.7272 - val_loss: 0.1682 - val_acc: 0.7295\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4159 - acc: 0.7272 - val_loss: 0.1681 - val_acc: 0.7296\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4154 - acc: 0.7271 - val_loss: 0.1679 - val_acc: 0.7296\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4149 - acc: 0.7271 - val_loss: 0.1677 - val_acc: 0.7297\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.4144 - acc: 0.7271 - val_loss: 0.1676 - val_acc: 0.7297\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4139 - acc: 0.7271 - val_loss: 0.1674 - val_acc: 0.7297\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4135 - acc: 0.7271 - val_loss: 0.1672 - val_acc: 0.7297\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4130 - acc: 0.7271 - val_loss: 0.1671 - val_acc: 0.7298\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4125 - acc: 0.7273 - val_loss: 0.1669 - val_acc: 0.7298\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.4120 - acc: 0.7272 - val_loss: 0.1667 - val_acc: 0.7298\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.4116 - acc: 0.7272 - val_loss: 0.1666 - val_acc: 0.7298\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.4111 - acc: 0.7273 - val_loss: 0.1664 - val_acc: 0.7298\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4106 - acc: 0.7273 - val_loss: 0.1662 - val_acc: 0.7298\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4101 - acc: 0.7273 - val_loss: 0.1661 - val_acc: 0.7298\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.4097 - acc: 0.7273 - val_loss: 0.1659 - val_acc: 0.7297\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4092 - acc: 0.7273 - val_loss: 0.1657 - val_acc: 0.7297\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.4088 - acc: 0.7274 - val_loss: 0.1656 - val_acc: 0.7297\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.4083 - acc: 0.7274 - val_loss: 0.1654 - val_acc: 0.7298\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.4078 - acc: 0.7276 - val_loss: 0.1653 - val_acc: 0.7298\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4074 - acc: 0.7276 - val_loss: 0.1651 - val_acc: 0.7298\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.4069 - acc: 0.7276 - val_loss: 0.1650 - val_acc: 0.7298\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4065 - acc: 0.7276 - val_loss: 0.1648 - val_acc: 0.7298\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4060 - acc: 0.7276 - val_loss: 0.1646 - val_acc: 0.7297\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4056 - acc: 0.7276 - val_loss: 0.1645 - val_acc: 0.7299\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4051 - acc: 0.7277 - val_loss: 0.1643 - val_acc: 0.7298\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.4047 - acc: 0.7276 - val_loss: 0.1642 - val_acc: 0.7299\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.4043 - acc: 0.7276 - val_loss: 0.1640 - val_acc: 0.7300\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.4038 - acc: 0.7277 - val_loss: 0.1639 - val_acc: 0.7300\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.4034 - acc: 0.7278 - val_loss: 0.1637 - val_acc: 0.7301\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.4030 - acc: 0.7278 - val_loss: 0.1636 - val_acc: 0.7302\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.4025 - acc: 0.7278 - val_loss: 0.1634 - val_acc: 0.7301\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.4021 - acc: 0.7277 - val_loss: 0.1633 - val_acc: 0.7302\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.4017 - acc: 0.7278 - val_loss: 0.1632 - val_acc: 0.7303\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.4012 - acc: 0.7278 - val_loss: 0.1630 - val_acc: 0.7302\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.4008 - acc: 0.7279 - val_loss: 0.1629 - val_acc: 0.7303\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4004 - acc: 0.7279 - val_loss: 0.1627 - val_acc: 0.7303\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4000 - acc: 0.7278 - val_loss: 0.1626 - val_acc: 0.7302\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.3996 - acc: 0.7277 - val_loss: 0.1624 - val_acc: 0.7301\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3991 - acc: 0.7277 - val_loss: 0.1623 - val_acc: 0.7301\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3987 - acc: 0.7278 - val_loss: 0.1622 - val_acc: 0.7301\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3983 - acc: 0.7278 - val_loss: 0.1620 - val_acc: 0.7302\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3979 - acc: 0.7279 - val_loss: 0.1619 - val_acc: 0.7301\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.3975 - acc: 0.7278 - val_loss: 0.1617 - val_acc: 0.7301\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3971 - acc: 0.7279 - val_loss: 0.1616 - val_acc: 0.7302\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3967 - acc: 0.7278 - val_loss: 0.1615 - val_acc: 0.7302\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3963 - acc: 0.7278 - val_loss: 0.1613 - val_acc: 0.7301\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3959 - acc: 0.7278 - val_loss: 0.1612 - val_acc: 0.7303\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3955 - acc: 0.7280 - val_loss: 0.1611 - val_acc: 0.7303\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 1s 639ms/step - loss: 0.3951 - acc: 0.7280 - val_loss: 0.1609 - val_acc: 0.7302\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.3947 - acc: 0.7279 - val_loss: 0.1608 - val_acc: 0.7304\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.3943 - acc: 0.7280 - val_loss: 0.1607 - val_acc: 0.7303\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.3939 - acc: 0.7280 - val_loss: 0.1605 - val_acc: 0.7304\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3935 - acc: 0.7281 - val_loss: 0.1604 - val_acc: 0.7304\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.3931 - acc: 0.7280 - val_loss: 0.1603 - val_acc: 0.7305\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.3928 - acc: 0.7281 - val_loss: 0.1602 - val_acc: 0.7305\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3924 - acc: 0.7281 - val_loss: 0.1600 - val_acc: 0.7305\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.3920 - acc: 0.7281 - val_loss: 0.1599 - val_acc: 0.7303\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3916 - acc: 0.7281 - val_loss: 0.1598 - val_acc: 0.7303\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3912 - acc: 0.7282 - val_loss: 0.1597 - val_acc: 0.7304\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.3909 - acc: 0.7282 - val_loss: 0.1595 - val_acc: 0.7305\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3905 - acc: 0.7282 - val_loss: 0.1594 - val_acc: 0.7304\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.3901 - acc: 0.7281 - val_loss: 0.1593 - val_acc: 0.7305\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3898 - acc: 0.7282 - val_loss: 0.1592 - val_acc: 0.7305\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3894 - acc: 0.7281 - val_loss: 0.1591 - val_acc: 0.7305\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3890 - acc: 0.7281 - val_loss: 0.1589 - val_acc: 0.7305\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.3887 - acc: 0.7281 - val_loss: 0.1588 - val_acc: 0.7305\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3883 - acc: 0.7283 - val_loss: 0.1587 - val_acc: 0.7305\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3879 - acc: 0.7282 - val_loss: 0.1586 - val_acc: 0.7306\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.3876 - acc: 0.7282 - val_loss: 0.1585 - val_acc: 0.7306\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3872 - acc: 0.7282 - val_loss: 0.1583 - val_acc: 0.7306\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3869 - acc: 0.7282 - val_loss: 0.1582 - val_acc: 0.7306\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3865 - acc: 0.7282 - val_loss: 0.1581 - val_acc: 0.7307\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3861 - acc: 0.7283 - val_loss: 0.1580 - val_acc: 0.7307\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.3858 - acc: 0.7283 - val_loss: 0.1579 - val_acc: 0.7306\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3854 - acc: 0.7283 - val_loss: 0.1578 - val_acc: 0.7305\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3851 - acc: 0.7282 - val_loss: 0.1577 - val_acc: 0.7304\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3848 - acc: 0.7280 - val_loss: 0.1575 - val_acc: 0.7303\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3844 - acc: 0.7278 - val_loss: 0.1574 - val_acc: 0.7303\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3841 - acc: 0.7278 - val_loss: 0.1573 - val_acc: 0.7303\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.3837 - acc: 0.7278 - val_loss: 0.1572 - val_acc: 0.7303\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3834 - acc: 0.7278 - val_loss: 0.1571 - val_acc: 0.7302\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3830 - acc: 0.7277 - val_loss: 0.1570 - val_acc: 0.7303\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3827 - acc: 0.7277 - val_loss: 0.1569 - val_acc: 0.7304\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3824 - acc: 0.7278 - val_loss: 0.1568 - val_acc: 0.7304\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3820 - acc: 0.7279 - val_loss: 0.1567 - val_acc: 0.7304\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3817 - acc: 0.7279 - val_loss: 0.1566 - val_acc: 0.7303\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3814 - acc: 0.7280 - val_loss: 0.1565 - val_acc: 0.7304\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3810 - acc: 0.7281 - val_loss: 0.1564 - val_acc: 0.7305\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3807 - acc: 0.7281 - val_loss: 0.1563 - val_acc: 0.7305\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3804 - acc: 0.7281 - val_loss: 0.1562 - val_acc: 0.7306\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3801 - acc: 0.7281 - val_loss: 0.1560 - val_acc: 0.7306\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3798 - acc: 0.7281 - val_loss: 0.1559 - val_acc: 0.7306\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3794 - acc: 0.7280 - val_loss: 0.1558 - val_acc: 0.7306\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.3791 - acc: 0.7281 - val_loss: 0.1557 - val_acc: 0.7307\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3788 - acc: 0.7281 - val_loss: 0.1556 - val_acc: 0.7307\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3785 - acc: 0.7282 - val_loss: 0.1555 - val_acc: 0.7308\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3782 - acc: 0.7283 - val_loss: 0.1554 - val_acc: 0.7308\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3778 - acc: 0.7283 - val_loss: 0.1553 - val_acc: 0.7310\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3775 - acc: 0.7284 - val_loss: 0.1552 - val_acc: 0.7310\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3772 - acc: 0.7285 - val_loss: 0.1552 - val_acc: 0.7312\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3769 - acc: 0.7286 - val_loss: 0.1551 - val_acc: 0.7313\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3766 - acc: 0.7289 - val_loss: 0.1550 - val_acc: 0.7313\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3763 - acc: 0.7290 - val_loss: 0.1549 - val_acc: 0.7314\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3760 - acc: 0.7290 - val_loss: 0.1548 - val_acc: 0.7313\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3757 - acc: 0.7290 - val_loss: 0.1547 - val_acc: 0.7314\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3754 - acc: 0.7290 - val_loss: 0.1546 - val_acc: 0.7314\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3751 - acc: 0.7290 - val_loss: 0.1545 - val_acc: 0.7312\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3748 - acc: 0.7290 - val_loss: 0.1544 - val_acc: 0.7311\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3745 - acc: 0.7289 - val_loss: 0.1543 - val_acc: 0.7313\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3742 - acc: 0.7290 - val_loss: 0.1542 - val_acc: 0.7313\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3739 - acc: 0.7291 - val_loss: 0.1541 - val_acc: 0.7313\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3736 - acc: 0.7291 - val_loss: 0.1540 - val_acc: 0.7313\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3733 - acc: 0.7291 - val_loss: 0.1539 - val_acc: 0.7313\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3730 - acc: 0.7291 - val_loss: 0.1539 - val_acc: 0.7311\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3727 - acc: 0.7289 - val_loss: 0.1538 - val_acc: 0.7311\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3725 - acc: 0.7288 - val_loss: 0.1537 - val_acc: 0.7311\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3722 - acc: 0.7288 - val_loss: 0.1536 - val_acc: 0.7312\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3719 - acc: 0.7288 - val_loss: 0.1535 - val_acc: 0.7312\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3716 - acc: 0.7288 - val_loss: 0.1534 - val_acc: 0.7312\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3713 - acc: 0.7289 - val_loss: 0.1533 - val_acc: 0.7314\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3710 - acc: 0.7290 - val_loss: 0.1532 - val_acc: 0.7314\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3708 - acc: 0.7290 - val_loss: 0.1532 - val_acc: 0.7315\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3705 - acc: 0.7289 - val_loss: 0.1531 - val_acc: 0.7314\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3702 - acc: 0.7289 - val_loss: 0.1530 - val_acc: 0.7315\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3699 - acc: 0.7289 - val_loss: 0.1529 - val_acc: 0.7316\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3697 - acc: 0.7290 - val_loss: 0.1528 - val_acc: 0.7314\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3694 - acc: 0.7289 - val_loss: 0.1527 - val_acc: 0.7314\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3691 - acc: 0.7290 - val_loss: 0.1527 - val_acc: 0.7314\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3688 - acc: 0.7289 - val_loss: 0.1526 - val_acc: 0.7315\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3686 - acc: 0.7290 - val_loss: 0.1525 - val_acc: 0.7315\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3683 - acc: 0.7291 - val_loss: 0.1524 - val_acc: 0.7313\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3680 - acc: 0.7289 - val_loss: 0.1523 - val_acc: 0.7313\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3678 - acc: 0.7290 - val_loss: 0.1523 - val_acc: 0.7312\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3675 - acc: 0.7289 - val_loss: 0.1522 - val_acc: 0.7312\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3673 - acc: 0.7288 - val_loss: 0.1521 - val_acc: 0.7313\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3670 - acc: 0.7290 - val_loss: 0.1520 - val_acc: 0.7314\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3667 - acc: 0.7293 - val_loss: 0.1519 - val_acc: 0.7315\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3665 - acc: 0.7293 - val_loss: 0.1519 - val_acc: 0.7316\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3662 - acc: 0.7294 - val_loss: 0.1518 - val_acc: 0.7314\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3660 - acc: 0.7293 - val_loss: 0.1517 - val_acc: 0.7315\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3657 - acc: 0.7293 - val_loss: 0.1516 - val_acc: 0.7315\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3654 - acc: 0.7293 - val_loss: 0.1516 - val_acc: 0.7315\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3652 - acc: 0.7292 - val_loss: 0.1515 - val_acc: 0.7315\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3649 - acc: 0.7293 - val_loss: 0.1514 - val_acc: 0.7316\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3647 - acc: 0.7294 - val_loss: 0.1513 - val_acc: 0.7316\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3644 - acc: 0.7294 - val_loss: 0.1513 - val_acc: 0.7316\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3642 - acc: 0.7294 - val_loss: 0.1512 - val_acc: 0.7317\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3639 - acc: 0.7296 - val_loss: 0.1511 - val_acc: 0.7316\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3637 - acc: 0.7294 - val_loss: 0.1511 - val_acc: 0.7316\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3635 - acc: 0.7295 - val_loss: 0.1510 - val_acc: 0.7315\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3632 - acc: 0.7294 - val_loss: 0.1509 - val_acc: 0.7314\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3630 - acc: 0.7294 - val_loss: 0.1508 - val_acc: 0.7315\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3627 - acc: 0.7294 - val_loss: 0.1508 - val_acc: 0.7315\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3625 - acc: 0.7294 - val_loss: 0.1507 - val_acc: 0.7315\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3622 - acc: 0.7294 - val_loss: 0.1506 - val_acc: 0.7316\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3620 - acc: 0.7294 - val_loss: 0.1506 - val_acc: 0.7314\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3618 - acc: 0.7292 - val_loss: 0.1505 - val_acc: 0.7315\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3615 - acc: 0.7293 - val_loss: 0.1504 - val_acc: 0.7313\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.3613 - acc: 0.7291 - val_loss: 0.1504 - val_acc: 0.7313\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3611 - acc: 0.7291 - val_loss: 0.1503 - val_acc: 0.7311\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3608 - acc: 0.7291 - val_loss: 0.1502 - val_acc: 0.7309\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3606 - acc: 0.7289 - val_loss: 0.1502 - val_acc: 0.7309\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3604 - acc: 0.7289 - val_loss: 0.1501 - val_acc: 0.7309\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3601 - acc: 0.7289 - val_loss: 0.1500 - val_acc: 0.7308\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3599 - acc: 0.7288 - val_loss: 0.1500 - val_acc: 0.7309\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3597 - acc: 0.7289 - val_loss: 0.1499 - val_acc: 0.7308\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3595 - acc: 0.7288 - val_loss: 0.1498 - val_acc: 0.7307\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3592 - acc: 0.7288 - val_loss: 0.1498 - val_acc: 0.7308\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.3590 - acc: 0.7288 - val_loss: 0.1497 - val_acc: 0.7308\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3588 - acc: 0.7289 - val_loss: 0.1497 - val_acc: 0.7307\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3586 - acc: 0.7287 - val_loss: 0.1496 - val_acc: 0.7307\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3584 - acc: 0.7286 - val_loss: 0.1495 - val_acc: 0.7307\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3581 - acc: 0.7286 - val_loss: 0.1495 - val_acc: 0.7307\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3579 - acc: 0.7287 - val_loss: 0.1494 - val_acc: 0.7307\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3577 - acc: 0.7288 - val_loss: 0.1493 - val_acc: 0.7307\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3575 - acc: 0.7287 - val_loss: 0.1493 - val_acc: 0.7307\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3573 - acc: 0.7287 - val_loss: 0.1492 - val_acc: 0.7307\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3571 - acc: 0.7288 - val_loss: 0.1492 - val_acc: 0.7307\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3568 - acc: 0.7289 - val_loss: 0.1491 - val_acc: 0.7307\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3566 - acc: 0.7289 - val_loss: 0.1491 - val_acc: 0.7307\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3564 - acc: 0.7289 - val_loss: 0.1490 - val_acc: 0.7306\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3562 - acc: 0.7287 - val_loss: 0.1489 - val_acc: 0.7305\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3560 - acc: 0.7288 - val_loss: 0.1489 - val_acc: 0.7305\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3558 - acc: 0.7288 - val_loss: 0.1488 - val_acc: 0.7304\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.3556 - acc: 0.7287 - val_loss: 0.1488 - val_acc: 0.7305\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.3554 - acc: 0.7290 - val_loss: 0.1487 - val_acc: 0.7305\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3552 - acc: 0.7289 - val_loss: 0.1487 - val_acc: 0.7304\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3550 - acc: 0.7288 - val_loss: 0.1486 - val_acc: 0.7305\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.3548 - acc: 0.7288 - val_loss: 0.1485 - val_acc: 0.7304\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3546 - acc: 0.7286 - val_loss: 0.1485 - val_acc: 0.7302\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3544 - acc: 0.7284 - val_loss: 0.1484 - val_acc: 0.7303\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3541 - acc: 0.7286 - val_loss: 0.1484 - val_acc: 0.7304\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3539 - acc: 0.7285 - val_loss: 0.1483 - val_acc: 0.7304\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3538 - acc: 0.7286 - val_loss: 0.1483 - val_acc: 0.7304\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3536 - acc: 0.7286 - val_loss: 0.1482 - val_acc: 0.7304\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3534 - acc: 0.7287 - val_loss: 0.1482 - val_acc: 0.7304\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3532 - acc: 0.7286 - val_loss: 0.1481 - val_acc: 0.7304\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3530 - acc: 0.7287 - val_loss: 0.1481 - val_acc: 0.7304\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3528 - acc: 0.7287 - val_loss: 0.1480 - val_acc: 0.7304\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3526 - acc: 0.7288 - val_loss: 0.1480 - val_acc: 0.7304\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3524 - acc: 0.7288 - val_loss: 0.1479 - val_acc: 0.7304\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3522 - acc: 0.7287 - val_loss: 0.1479 - val_acc: 0.7304\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3520 - acc: 0.7287 - val_loss: 0.1478 - val_acc: 0.7308\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3518 - acc: 0.7289 - val_loss: 0.1478 - val_acc: 0.7307\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3516 - acc: 0.7289 - val_loss: 0.1477 - val_acc: 0.7307\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.3514 - acc: 0.7287 - val_loss: 0.1477 - val_acc: 0.7306\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3512 - acc: 0.7286 - val_loss: 0.1476 - val_acc: 0.7307\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3511 - acc: 0.7285 - val_loss: 0.1476 - val_acc: 0.7306\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3509 - acc: 0.7286 - val_loss: 0.1475 - val_acc: 0.7306\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3507 - acc: 0.7285 - val_loss: 0.1475 - val_acc: 0.7306\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3505 - acc: 0.7286 - val_loss: 0.1474 - val_acc: 0.7308\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3503 - acc: 0.7286 - val_loss: 0.1474 - val_acc: 0.7306\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3501 - acc: 0.7285 - val_loss: 0.1473 - val_acc: 0.7307\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3500 - acc: 0.7286 - val_loss: 0.1473 - val_acc: 0.7308\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3498 - acc: 0.7286 - val_loss: 0.1472 - val_acc: 0.7308\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3496 - acc: 0.7285 - val_loss: 0.1472 - val_acc: 0.7310\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3494 - acc: 0.7286 - val_loss: 0.1471 - val_acc: 0.7309\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3492 - acc: 0.7286 - val_loss: 0.1471 - val_acc: 0.7309\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3491 - acc: 0.7286 - val_loss: 0.1470 - val_acc: 0.7308\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3489 - acc: 0.7287 - val_loss: 0.1470 - val_acc: 0.7309\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3487 - acc: 0.7286 - val_loss: 0.1469 - val_acc: 0.7308\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.3485 - acc: 0.7285 - val_loss: 0.1469 - val_acc: 0.7309\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3484 - acc: 0.7286 - val_loss: 0.1469 - val_acc: 0.7309\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.3482 - acc: 0.7285 - val_loss: 0.1468 - val_acc: 0.7310\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3480 - acc: 0.7286 - val_loss: 0.1468 - val_acc: 0.7310\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3478 - acc: 0.7285 - val_loss: 0.1467 - val_acc: 0.7310\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3477 - acc: 0.7285 - val_loss: 0.1467 - val_acc: 0.7311\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3475 - acc: 0.7286 - val_loss: 0.1466 - val_acc: 0.7310\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3473 - acc: 0.7285 - val_loss: 0.1466 - val_acc: 0.7309\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3472 - acc: 0.7285 - val_loss: 0.1466 - val_acc: 0.7309\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3470 - acc: 0.7287 - val_loss: 0.1465 - val_acc: 0.7308\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3468 - acc: 0.7286 - val_loss: 0.1465 - val_acc: 0.7309\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3467 - acc: 0.7286 - val_loss: 0.1464 - val_acc: 0.7308\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3465 - acc: 0.7286 - val_loss: 0.1464 - val_acc: 0.7306\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3463 - acc: 0.7285 - val_loss: 0.1464 - val_acc: 0.7306\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3462 - acc: 0.7286 - val_loss: 0.1463 - val_acc: 0.7308\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3460 - acc: 0.7288 - val_loss: 0.1463 - val_acc: 0.7308\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3458 - acc: 0.7287 - val_loss: 0.1462 - val_acc: 0.7306\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3457 - acc: 0.7286 - val_loss: 0.1462 - val_acc: 0.7305\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3455 - acc: 0.7285 - val_loss: 0.1462 - val_acc: 0.7305\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3454 - acc: 0.7286 - val_loss: 0.1461 - val_acc: 0.7304\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3452 - acc: 0.7284 - val_loss: 0.1461 - val_acc: 0.7303\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3450 - acc: 0.7283 - val_loss: 0.1460 - val_acc: 0.7304\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3449 - acc: 0.7284 - val_loss: 0.1460 - val_acc: 0.7306\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3447 - acc: 0.7285 - val_loss: 0.1460 - val_acc: 0.7308\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3446 - acc: 0.7285 - val_loss: 0.1459 - val_acc: 0.7305\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3444 - acc: 0.7283 - val_loss: 0.1459 - val_acc: 0.7306\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3442 - acc: 0.7285 - val_loss: 0.1458 - val_acc: 0.7306\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3441 - acc: 0.7285 - val_loss: 0.1458 - val_acc: 0.7308\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3439 - acc: 0.7288 - val_loss: 0.1458 - val_acc: 0.7307\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3438 - acc: 0.7288 - val_loss: 0.1457 - val_acc: 0.7307\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3436 - acc: 0.7287 - val_loss: 0.1457 - val_acc: 0.7307\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3435 - acc: 0.7287 - val_loss: 0.1457 - val_acc: 0.7307\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3433 - acc: 0.7287 - val_loss: 0.1456 - val_acc: 0.7307\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3432 - acc: 0.7286 - val_loss: 0.1456 - val_acc: 0.7306\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3430 - acc: 0.7284 - val_loss: 0.1456 - val_acc: 0.7305\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3429 - acc: 0.7283 - val_loss: 0.1455 - val_acc: 0.7305\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3427 - acc: 0.7282 - val_loss: 0.1455 - val_acc: 0.7305\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3426 - acc: 0.7282 - val_loss: 0.1455 - val_acc: 0.7305\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3424 - acc: 0.7282 - val_loss: 0.1454 - val_acc: 0.7305\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3423 - acc: 0.7283 - val_loss: 0.1454 - val_acc: 0.7305\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3421 - acc: 0.7282 - val_loss: 0.1454 - val_acc: 0.7304\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3420 - acc: 0.7281 - val_loss: 0.1453 - val_acc: 0.7304\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3419 - acc: 0.7281 - val_loss: 0.1453 - val_acc: 0.7307\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3417 - acc: 0.7284 - val_loss: 0.1453 - val_acc: 0.7308\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3416 - acc: 0.7285 - val_loss: 0.1452 - val_acc: 0.7309\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3414 - acc: 0.7286 - val_loss: 0.1452 - val_acc: 0.7309\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3413 - acc: 0.7286 - val_loss: 0.1452 - val_acc: 0.7308\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3411 - acc: 0.7284 - val_loss: 0.1451 - val_acc: 0.7310\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3410 - acc: 0.7285 - val_loss: 0.1451 - val_acc: 0.7309\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3409 - acc: 0.7282 - val_loss: 0.1451 - val_acc: 0.7309\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3407 - acc: 0.7282 - val_loss: 0.1450 - val_acc: 0.7309\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3406 - acc: 0.7282 - val_loss: 0.1450 - val_acc: 0.7309\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3404 - acc: 0.7282 - val_loss: 0.1450 - val_acc: 0.7307\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3403 - acc: 0.7281 - val_loss: 0.1449 - val_acc: 0.7307\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3402 - acc: 0.7281 - val_loss: 0.1449 - val_acc: 0.7307\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3400 - acc: 0.7280 - val_loss: 0.1449 - val_acc: 0.7308\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3399 - acc: 0.7281 - val_loss: 0.1448 - val_acc: 0.7310\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3398 - acc: 0.7284 - val_loss: 0.1448 - val_acc: 0.7310\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3396 - acc: 0.7284 - val_loss: 0.1448 - val_acc: 0.7309\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3395 - acc: 0.7282 - val_loss: 0.1448 - val_acc: 0.7309\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3394 - acc: 0.7282 - val_loss: 0.1447 - val_acc: 0.7310\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3392 - acc: 0.7282 - val_loss: 0.1447 - val_acc: 0.7310\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3391 - acc: 0.7283 - val_loss: 0.1447 - val_acc: 0.7308\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3390 - acc: 0.7283 - val_loss: 0.1446 - val_acc: 0.7308\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3388 - acc: 0.7282 - val_loss: 0.1446 - val_acc: 0.7308\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.3387 - acc: 0.7283 - val_loss: 0.1446 - val_acc: 0.7308\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.3386 - acc: 0.7283 - val_loss: 0.1446 - val_acc: 0.7309\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.3384 - acc: 0.7284 - val_loss: 0.1445 - val_acc: 0.7309\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.3383 - acc: 0.7283 - val_loss: 0.1445 - val_acc: 0.7308\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.3382 - acc: 0.7283 - val_loss: 0.1445 - val_acc: 0.7308\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.3381 - acc: 0.7283 - val_loss: 0.1444 - val_acc: 0.7308\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3379 - acc: 0.7282 - val_loss: 0.1444 - val_acc: 0.7309\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3378 - acc: 0.7284 - val_loss: 0.1444 - val_acc: 0.7308\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3377 - acc: 0.7283 - val_loss: 0.1444 - val_acc: 0.7309\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3376 - acc: 0.7285 - val_loss: 0.1443 - val_acc: 0.7308\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3374 - acc: 0.7284 - val_loss: 0.1443 - val_acc: 0.7307\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3373 - acc: 0.7285 - val_loss: 0.1443 - val_acc: 0.7307\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3372 - acc: 0.7285 - val_loss: 0.1443 - val_acc: 0.7308\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3371 - acc: 0.7285 - val_loss: 0.1442 - val_acc: 0.7308\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3369 - acc: 0.7285 - val_loss: 0.1442 - val_acc: 0.7308\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3368 - acc: 0.7284 - val_loss: 0.1442 - val_acc: 0.7308\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.3367 - acc: 0.7283 - val_loss: 0.1442 - val_acc: 0.7308\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3366 - acc: 0.7283 - val_loss: 0.1441 - val_acc: 0.7307\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3364 - acc: 0.7283 - val_loss: 0.1441 - val_acc: 0.7306\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3363 - acc: 0.7281 - val_loss: 0.1441 - val_acc: 0.7307\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3362 - acc: 0.7283 - val_loss: 0.1441 - val_acc: 0.7307\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3361 - acc: 0.7284 - val_loss: 0.1440 - val_acc: 0.7308\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3360 - acc: 0.7284 - val_loss: 0.1440 - val_acc: 0.7308\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3359 - acc: 0.7283 - val_loss: 0.1440 - val_acc: 0.7309\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3357 - acc: 0.7283 - val_loss: 0.1440 - val_acc: 0.7308\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3356 - acc: 0.7283 - val_loss: 0.1439 - val_acc: 0.7308\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3355 - acc: 0.7282 - val_loss: 0.1439 - val_acc: 0.7308\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3354 - acc: 0.7282 - val_loss: 0.1439 - val_acc: 0.7307\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3353 - acc: 0.7279 - val_loss: 0.1439 - val_acc: 0.7307\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3352 - acc: 0.7280 - val_loss: 0.1439 - val_acc: 0.7307\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.3350 - acc: 0.7280 - val_loss: 0.1438 - val_acc: 0.7307\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3349 - acc: 0.7282 - val_loss: 0.1438 - val_acc: 0.7305\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.3348 - acc: 0.7279 - val_loss: 0.1438 - val_acc: 0.7303\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.3347 - acc: 0.7278 - val_loss: 0.1438 - val_acc: 0.7302\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3346 - acc: 0.7277 - val_loss: 0.1437 - val_acc: 0.7302\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3345 - acc: 0.7277 - val_loss: 0.1437 - val_acc: 0.7301\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3344 - acc: 0.7276 - val_loss: 0.1437 - val_acc: 0.7300\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3343 - acc: 0.7276 - val_loss: 0.1437 - val_acc: 0.7301\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3341 - acc: 0.7276 - val_loss: 0.1437 - val_acc: 0.7301\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3340 - acc: 0.7276 - val_loss: 0.1436 - val_acc: 0.7300\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3339 - acc: 0.7276 - val_loss: 0.1436 - val_acc: 0.7298\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.3338 - acc: 0.7276 - val_loss: 0.1436 - val_acc: 0.7299\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3337 - acc: 0.7277 - val_loss: 0.1436 - val_acc: 0.7297\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3336 - acc: 0.7277 - val_loss: 0.1436 - val_acc: 0.7297\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3335 - acc: 0.7276 - val_loss: 0.1435 - val_acc: 0.7297\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3334 - acc: 0.7275 - val_loss: 0.1435 - val_acc: 0.7298\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3333 - acc: 0.7275 - val_loss: 0.1435 - val_acc: 0.7299\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3332 - acc: 0.7276 - val_loss: 0.1435 - val_acc: 0.7299\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3331 - acc: 0.7276 - val_loss: 0.1435 - val_acc: 0.7299\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3330 - acc: 0.7276 - val_loss: 0.1434 - val_acc: 0.7298\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3329 - acc: 0.7276 - val_loss: 0.1434 - val_acc: 0.7298\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3328 - acc: 0.7276 - val_loss: 0.1434 - val_acc: 0.7298\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3327 - acc: 0.7276 - val_loss: 0.1434 - val_acc: 0.7299\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3325 - acc: 0.7276 - val_loss: 0.1434 - val_acc: 0.7298\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3324 - acc: 0.7275 - val_loss: 0.1433 - val_acc: 0.7297\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3323 - acc: 0.7274 - val_loss: 0.1433 - val_acc: 0.7297\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3322 - acc: 0.7274 - val_loss: 0.1433 - val_acc: 0.7296\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3321 - acc: 0.7274 - val_loss: 0.1433 - val_acc: 0.7295\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3320 - acc: 0.7273 - val_loss: 0.1433 - val_acc: 0.7294\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3319 - acc: 0.7273 - val_loss: 0.1432 - val_acc: 0.7295\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3318 - acc: 0.7274 - val_loss: 0.1432 - val_acc: 0.7295\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3317 - acc: 0.7274 - val_loss: 0.1432 - val_acc: 0.7295\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.3316 - acc: 0.7274 - val_loss: 0.1432 - val_acc: 0.7293\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3315 - acc: 0.7273 - val_loss: 0.1432 - val_acc: 0.7294\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3314 - acc: 0.7273 - val_loss: 0.1432 - val_acc: 0.7293\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3313 - acc: 0.7273 - val_loss: 0.1431 - val_acc: 0.7294\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3312 - acc: 0.7273 - val_loss: 0.1431 - val_acc: 0.7294\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3311 - acc: 0.7273 - val_loss: 0.1431 - val_acc: 0.7294\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.3311 - acc: 0.7274 - val_loss: 0.1431 - val_acc: 0.7293\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3310 - acc: 0.7274 - val_loss: 0.1431 - val_acc: 0.7294\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3309 - acc: 0.7274 - val_loss: 0.1431 - val_acc: 0.7293\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.3308 - acc: 0.7274 - val_loss: 0.1430 - val_acc: 0.7292\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3307 - acc: 0.7274 - val_loss: 0.1430 - val_acc: 0.7292\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3306 - acc: 0.7275 - val_loss: 0.1430 - val_acc: 0.7292\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3305 - acc: 0.7273 - val_loss: 0.1430 - val_acc: 0.7292\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3304 - acc: 0.7274 - val_loss: 0.1430 - val_acc: 0.7292\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3303 - acc: 0.7274 - val_loss: 0.1430 - val_acc: 0.7291\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3302 - acc: 0.7274 - val_loss: 0.1430 - val_acc: 0.7290\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.3301 - acc: 0.7274 - val_loss: 0.1429 - val_acc: 0.7290\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3300 - acc: 0.7274 - val_loss: 0.1429 - val_acc: 0.7292\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.3299 - acc: 0.7276 - val_loss: 0.1429 - val_acc: 0.7292\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3298 - acc: 0.7277 - val_loss: 0.1429 - val_acc: 0.7291\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3297 - acc: 0.7276 - val_loss: 0.1429 - val_acc: 0.7291\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3296 - acc: 0.7276 - val_loss: 0.1429 - val_acc: 0.7291\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3296 - acc: 0.7276 - val_loss: 0.1429 - val_acc: 0.7292\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3295 - acc: 0.7277 - val_loss: 0.1428 - val_acc: 0.7293\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3294 - acc: 0.7278 - val_loss: 0.1428 - val_acc: 0.7293\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3293 - acc: 0.7278 - val_loss: 0.1428 - val_acc: 0.7294\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3292 - acc: 0.7277 - val_loss: 0.1428 - val_acc: 0.7294\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.3291 - acc: 0.7278 - val_loss: 0.1428 - val_acc: 0.7295\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3290 - acc: 0.7279 - val_loss: 0.1428 - val_acc: 0.7294\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3289 - acc: 0.7279 - val_loss: 0.1428 - val_acc: 0.7294\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.3288 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7294\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3288 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7294\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.3287 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7294\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3286 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7295\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.3285 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7297\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3284 - acc: 0.7282 - val_loss: 0.1427 - val_acc: 0.7296\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3283 - acc: 0.7280 - val_loss: 0.1427 - val_acc: 0.7294\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3282 - acc: 0.7279 - val_loss: 0.1427 - val_acc: 0.7294\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3282 - acc: 0.7279 - val_loss: 0.1426 - val_acc: 0.7296\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3281 - acc: 0.7280 - val_loss: 0.1426 - val_acc: 0.7296\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3280 - acc: 0.7281 - val_loss: 0.1426 - val_acc: 0.7296\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3279 - acc: 0.7280 - val_loss: 0.1426 - val_acc: 0.7297\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3278 - acc: 0.7284 - val_loss: 0.1426 - val_acc: 0.7298\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3277 - acc: 0.7284 - val_loss: 0.1426 - val_acc: 0.7299\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3277 - acc: 0.7285 - val_loss: 0.1426 - val_acc: 0.7299\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3276 - acc: 0.7285 - val_loss: 0.1426 - val_acc: 0.7299\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3275 - acc: 0.7284 - val_loss: 0.1425 - val_acc: 0.7300\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3274 - acc: 0.7284 - val_loss: 0.1425 - val_acc: 0.7300\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3273 - acc: 0.7283 - val_loss: 0.1425 - val_acc: 0.7300\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3273 - acc: 0.7284 - val_loss: 0.1425 - val_acc: 0.7299\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3272 - acc: 0.7284 - val_loss: 0.1425 - val_acc: 0.7298\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3271 - acc: 0.7283 - val_loss: 0.1425 - val_acc: 0.7297\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3270 - acc: 0.7282 - val_loss: 0.1425 - val_acc: 0.7297\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3269 - acc: 0.7281 - val_loss: 0.1425 - val_acc: 0.7296\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3269 - acc: 0.7280 - val_loss: 0.1425 - val_acc: 0.7297\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3268 - acc: 0.7280 - val_loss: 0.1424 - val_acc: 0.7297\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3267 - acc: 0.7281 - val_loss: 0.1424 - val_acc: 0.7297\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3266 - acc: 0.7280 - val_loss: 0.1424 - val_acc: 0.7297\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3265 - acc: 0.7280 - val_loss: 0.1424 - val_acc: 0.7296\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3265 - acc: 0.7279 - val_loss: 0.1424 - val_acc: 0.7297\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3264 - acc: 0.7279 - val_loss: 0.1424 - val_acc: 0.7296\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3263 - acc: 0.7279 - val_loss: 0.1424 - val_acc: 0.7296\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3262 - acc: 0.7279 - val_loss: 0.1424 - val_acc: 0.7297\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3262 - acc: 0.7279 - val_loss: 0.1424 - val_acc: 0.7296\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3261 - acc: 0.7278 - val_loss: 0.1424 - val_acc: 0.7296\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3260 - acc: 0.7278 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3259 - acc: 0.7278 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3259 - acc: 0.7278 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3258 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3257 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3256 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7298\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3256 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3255 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3254 - acc: 0.7277 - val_loss: 0.1423 - val_acc: 0.7296\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3253 - acc: 0.7275 - val_loss: 0.1423 - val_acc: 0.7296\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3253 - acc: 0.7276 - val_loss: 0.1423 - val_acc: 0.7297\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3252 - acc: 0.7276 - val_loss: 0.1423 - val_acc: 0.7298\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3251 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3251 - acc: 0.7275 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3250 - acc: 0.7274 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3249 - acc: 0.7274 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3248 - acc: 0.7274 - val_loss: 0.1422 - val_acc: 0.7297\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.3248 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.3247 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3246 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3246 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.3245 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.3244 - acc: 0.7277 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3244 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7296\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3243 - acc: 0.7276 - val_loss: 0.1422 - val_acc: 0.7297\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3242 - acc: 0.7276 - val_loss: 0.1421 - val_acc: 0.7296\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3242 - acc: 0.7276 - val_loss: 0.1421 - val_acc: 0.7297\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3241 - acc: 0.7276 - val_loss: 0.1421 - val_acc: 0.7296\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3240 - acc: 0.7275 - val_loss: 0.1421 - val_acc: 0.7296\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3240 - acc: 0.7274 - val_loss: 0.1421 - val_acc: 0.7296\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3239 - acc: 0.7274 - val_loss: 0.1421 - val_acc: 0.7296\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3238 - acc: 0.7275 - val_loss: 0.1421 - val_acc: 0.7295\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3238 - acc: 0.7274 - val_loss: 0.1421 - val_acc: 0.7294\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3237 - acc: 0.7273 - val_loss: 0.1421 - val_acc: 0.7295\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3236 - acc: 0.7273 - val_loss: 0.1421 - val_acc: 0.7295\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3236 - acc: 0.7272 - val_loss: 0.1421 - val_acc: 0.7297\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3235 - acc: 0.7274 - val_loss: 0.1421 - val_acc: 0.7297\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3234 - acc: 0.7275 - val_loss: 0.1421 - val_acc: 0.7297\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3234 - acc: 0.7275 - val_loss: 0.1421 - val_acc: 0.7298\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3233 - acc: 0.7276 - val_loss: 0.1421 - val_acc: 0.7298\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3232 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.3232 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3231 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7299\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3231 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3230 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3229 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3229 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3228 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.3227 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.3227 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3226 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3226 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3225 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3224 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3224 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3223 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3223 - acc: 0.7275 - val_loss: 0.1420 - val_acc: 0.7297\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3222 - acc: 0.7274 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3221 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7298\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3221 - acc: 0.7276 - val_loss: 0.1420 - val_acc: 0.7300\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3220 - acc: 0.7278 - val_loss: 0.1419 - val_acc: 0.7300\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3220 - acc: 0.7278 - val_loss: 0.1419 - val_acc: 0.7301\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3219 - acc: 0.7278 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3219 - acc: 0.7279 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3218 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3217 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3217 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3216 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3216 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3215 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3215 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.3214 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3213 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3213 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3212 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3212 - acc: 0.7283 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3211 - acc: 0.7282 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3211 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3210 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7303\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3210 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3209 - acc: 0.7282 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3208 - acc: 0.7282 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3208 - acc: 0.7282 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3207 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3207 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3206 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7304\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3206 - acc: 0.7281 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3205 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3205 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3204 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3204 - acc: 0.7280 - val_loss: 0.1419 - val_acc: 0.7302\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3203 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7302\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3203 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3202 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3202 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3201 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3201 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.3200 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3200 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3199 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3199 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3198 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3198 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3197 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3197 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3196 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7302\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3196 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3195 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3195 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3194 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3194 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3193 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3193 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3192 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7301\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.3192 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3191 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3191 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3191 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3190 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.3190 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.3189 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7300\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.3189 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.3188 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.3188 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.3187 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3187 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.3186 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3186 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3186 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7299\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3185 - acc: 0.7281 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3185 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3184 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7297\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3184 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3183 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3183 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3182 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7298\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3182 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7297\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3182 - acc: 0.7280 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.3181 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3181 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3180 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3180 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3179 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3179 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3179 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.3178 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3178 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.3177 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.3177 - acc: 0.7278 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.3177 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3176 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3176 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.3175 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3175 - acc: 0.7279 - val_loss: 0.1418 - val_acc: 0.7296\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3175 - acc: 0.7279"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-37ea86c8dac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_va\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = model.evaluate(loader_va.load(), steps=loader_va.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Val loss: {}\\n\" \"Val accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_u8p3YR6u5U",
        "outputId": "974e5187-99ee-4296-c3b0-c714baaa7863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.7296\n",
            "Done.\n",
            "Val loss: 0.14181582629680634\n",
            "Val accuracy: 0.7296142578125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eTH1GBPl-6I",
        "outputId": "84671e55-1952-44ef-87bf-1b5ee9ac6397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0293 - acc: 0.5293\n",
            "Done.\n",
            "Test loss: 0.029276948422193527\n",
            "Test accuracy: 0.5292999744415283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_production = model.predict(loader_va.load(), steps=loader_va.steps_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C8wXbeZjCxD",
        "outputId": "970a90a9-aa13-48f4-ab64-19877576bd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_df = pd.read_csv('./nodes.csv.gz', usecols = [0, 2, 6], header = 0, names = ['idx', 'y', 'match_id']).iloc[-509_000:-9_000, :].set_index('idx').sort_index()"
      ],
      "metadata": {
        "id": "CZJquo8M8cVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df = pd.DataFrame(columns = ['home', 'not_home'])"
      ],
      "metadata": {
        "id": "Qv549qxeIq9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df['home'] = nodes_df[mask_va].y.values[::2]\n",
        "predict_df['not_home'] = nodes_df[mask_va].y.values[1::2]"
      ],
      "metadata": {
        "id": "YqzYbc_BJlAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df['pred_home'] = predict_production[mask_va][::2]\n",
        "predict_df['pred_not_home'] = predict_production[mask_va][1::2]"
      ],
      "metadata": {
        "id": "PJTTWMFrLSyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df['result'] = (predict_df['pred_home'] > predict_df['pred_not_home']).astype(int)"
      ],
      "metadata": {
        "id": "SolLiYqwVXkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(predict_df['home'] == predict_df['result']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPb0dWz_JGF0",
        "outputId": "8fec325a-f9fe-4cc5-d667-732fd23faaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35442"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df['idx_home'] = nodes_df.index[mask_te][::2]\n",
        "predict_df['idx_not_home'] = nodes_df.index[mask_te][1::2]"
      ],
      "metadata": {
        "id": "006cO_8M5h9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df['match_id_home'] = nodes_df[mask_te].match_id.values[::2]\n",
        "predict_df['match_id_not_home'] = nodes_df[mask_te].match_id.values[1::2]"
      ],
      "metadata": {
        "id": "NUmYzj1cBDiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df[predict_df.match_id_home != predict_df.match_id_not_home]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Z2FZHkB6Blul",
        "outputId": "697f9768-0069-4eaf-e85a-b923fd3cf524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [home, not_home, pred_home, pred_not_home, result, idx_home, idx_not_home, match_id_home, match_id_not_home]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29a5e49d-5347-4e6c-9918-f9d8db6e87ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home</th>\n",
              "      <th>not_home</th>\n",
              "      <th>pred_home</th>\n",
              "      <th>pred_not_home</th>\n",
              "      <th>result</th>\n",
              "      <th>idx_home</th>\n",
              "      <th>idx_not_home</th>\n",
              "      <th>match_id_home</th>\n",
              "      <th>match_id_not_home</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a5e49d-5347-4e6c-9918-f9d8db6e87ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29a5e49d-5347-4e6c-9918-f9d8db6e87ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29a5e49d-5347-4e6c-9918-f9d8db6e87ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EVQog2acdgeR",
        "outputId": "e930c020-4ac5-4162-950a-b284380c4973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       home  not_home  pred_home  pred_not_home  result\n",
              "0         0         1   0.817898       0.496136       1\n",
              "1         0         1   0.181242       0.487676       0\n",
              "2         1         0   0.478412       0.515747       0\n",
              "3         1         0   0.153708       0.828872       0\n",
              "4         1         0   0.509116       0.504974       1\n",
              "...     ...       ...        ...            ...     ...\n",
              "69995     1         0   0.314261       0.688905       0\n",
              "69996     1         0   0.689033       0.312998       1\n",
              "69997     0         1   0.310236       0.325164       0\n",
              "69998     1         0   0.326383       0.326463       0\n",
              "69999     1         0   0.315417       0.680577       0\n",
              "\n",
              "[70000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de1ea036-2609-46f5-b546-c4265a154a68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home</th>\n",
              "      <th>not_home</th>\n",
              "      <th>pred_home</th>\n",
              "      <th>pred_not_home</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.817898</td>\n",
              "      <td>0.496136</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181242</td>\n",
              "      <td>0.487676</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.478412</td>\n",
              "      <td>0.515747</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.153708</td>\n",
              "      <td>0.828872</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509116</td>\n",
              "      <td>0.504974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.314261</td>\n",
              "      <td>0.688905</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.689033</td>\n",
              "      <td>0.312998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.310236</td>\n",
              "      <td>0.325164</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.326383</td>\n",
              "      <td>0.326463</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.315417</td>\n",
              "      <td>0.680577</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de1ea036-2609-46f5-b546-c4265a154a68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de1ea036-2609-46f5-b546-c4265a154a68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de1ea036-2609-46f5-b546-c4265a154a68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset_name = './prem_validation.csv'\n",
        "project = neptune.init_project(\n",
        "    name=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "project['data/validation_prem_220818'].download(validation_dataset_name)\n",
        "project.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEKFIkF4dgUS",
        "outputId": "6798b212-75ea-4d51-cd24-3f52de54571a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/project#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prem_df = pd.read_csv('./prem_validation.csv')"
      ],
      "metadata": {
        "id": "Sobdd_9Rdfd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prem_df = prem_df[prem_df.Id.isin(list(predict_df.match_id_home))]"
      ],
      "metadata": {
        "id": "hStrG0pJCA7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_dict = predict_df[predict_df.match_id_home.isin(list(prem_df.Id))].set_index('match_id_home')[['home', 'result']].to_dict(orient = 'index')"
      ],
      "metadata": {
        "id": "tiVzpJN2KbMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prem_df[['result', 'predict']] = [[predict_dict[key]['home'], predict_dict[key]['result']] for key in prem_df.Id.values]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i31t9O0OJ1q4",
        "outputId": "1aaad21d-f2c5-40ee-8791-b6bd5b1bb96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = igetitem(value, i)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prem_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4dRQX-R3rqV-",
        "outputId": "8aa10c68-3558-4f68-b46c-97e5dabebf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Id    Idbook      W1     X      W2  W1live  \\\n",
              "7614  2eqn3i74041ragwpuzow7gbo4  13812880   3.600  4.65   1.700   3.600   \n",
              "7615  59i869it1synl0z3di62wss9g  13812877   2.880  4.15   2.030   2.880   \n",
              "7616  dj1uww92e3x26gg2gw79r6g44  13812875   1.116  8.80  14.000   1.116   \n",
              "7618  4hkznpu6g79a8h32ionlfagpg  13813781   1.760  4.10   3.720   1.760   \n",
              "7619  b232tm66r4b7jsi881a6mo6qc  13813779   2.550  3.92   2.300   2.420   \n",
              "...                         ...       ...     ...   ...     ...     ...   \n",
              "7987  dgtvqq4bwqkgnal8dx3zwccgk  13857861   3.700  3.42   1.930   3.700   \n",
              "7988  1nb3ab0vbihddp9qh2qviix3o  13857924   2.240  4.25   2.510   2.240   \n",
              "7989  9q0423juf175stwpppkxi9kic  13857923   1.250  5.80   9.200   1.250   \n",
              "7990  3y4e7iany0lgbj75cp30g8t90  13857930   8.700  7.10   1.210   8.700   \n",
              "7991  2ju6pbauusfneayoz42b03nkk  13862399  15.750  8.30   1.114  15.750   \n",
              "\n",
              "      Xlive  W2live  result  predict  \n",
              "7614   4.65   1.700       0        0  \n",
              "7615   4.15   2.030       1        1  \n",
              "7616   8.80  14.000       1        0  \n",
              "7618   4.10   3.720       1        1  \n",
              "7619   3.94   2.410       0        0  \n",
              "...     ...     ...     ...      ...  \n",
              "7987   3.42   1.930       1        1  \n",
              "7988   4.25   2.510       0        0  \n",
              "7989   5.80   9.200       1        1  \n",
              "7990   7.10   1.210       0        0  \n",
              "7991   8.30   1.114       0        0  \n",
              "\n",
              "[375 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a0851c6-05e0-4513-a70e-7b5906f4f741\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Idbook</th>\n",
              "      <th>W1</th>\n",
              "      <th>X</th>\n",
              "      <th>W2</th>\n",
              "      <th>W1live</th>\n",
              "      <th>Xlive</th>\n",
              "      <th>W2live</th>\n",
              "      <th>result</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7614</th>\n",
              "      <td>2eqn3i74041ragwpuzow7gbo4</td>\n",
              "      <td>13812880</td>\n",
              "      <td>3.600</td>\n",
              "      <td>4.65</td>\n",
              "      <td>1.700</td>\n",
              "      <td>3.600</td>\n",
              "      <td>4.65</td>\n",
              "      <td>1.700</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7615</th>\n",
              "      <td>59i869it1synl0z3di62wss9g</td>\n",
              "      <td>13812877</td>\n",
              "      <td>2.880</td>\n",
              "      <td>4.15</td>\n",
              "      <td>2.030</td>\n",
              "      <td>2.880</td>\n",
              "      <td>4.15</td>\n",
              "      <td>2.030</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7616</th>\n",
              "      <td>dj1uww92e3x26gg2gw79r6g44</td>\n",
              "      <td>13812875</td>\n",
              "      <td>1.116</td>\n",
              "      <td>8.80</td>\n",
              "      <td>14.000</td>\n",
              "      <td>1.116</td>\n",
              "      <td>8.80</td>\n",
              "      <td>14.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>4hkznpu6g79a8h32ionlfagpg</td>\n",
              "      <td>13813781</td>\n",
              "      <td>1.760</td>\n",
              "      <td>4.10</td>\n",
              "      <td>3.720</td>\n",
              "      <td>1.760</td>\n",
              "      <td>4.10</td>\n",
              "      <td>3.720</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7619</th>\n",
              "      <td>b232tm66r4b7jsi881a6mo6qc</td>\n",
              "      <td>13813779</td>\n",
              "      <td>2.550</td>\n",
              "      <td>3.92</td>\n",
              "      <td>2.300</td>\n",
              "      <td>2.420</td>\n",
              "      <td>3.94</td>\n",
              "      <td>2.410</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7987</th>\n",
              "      <td>dgtvqq4bwqkgnal8dx3zwccgk</td>\n",
              "      <td>13857861</td>\n",
              "      <td>3.700</td>\n",
              "      <td>3.42</td>\n",
              "      <td>1.930</td>\n",
              "      <td>3.700</td>\n",
              "      <td>3.42</td>\n",
              "      <td>1.930</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7988</th>\n",
              "      <td>1nb3ab0vbihddp9qh2qviix3o</td>\n",
              "      <td>13857924</td>\n",
              "      <td>2.240</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.510</td>\n",
              "      <td>2.240</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.510</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7989</th>\n",
              "      <td>9q0423juf175stwpppkxi9kic</td>\n",
              "      <td>13857923</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5.80</td>\n",
              "      <td>9.200</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5.80</td>\n",
              "      <td>9.200</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7990</th>\n",
              "      <td>3y4e7iany0lgbj75cp30g8t90</td>\n",
              "      <td>13857930</td>\n",
              "      <td>8.700</td>\n",
              "      <td>7.10</td>\n",
              "      <td>1.210</td>\n",
              "      <td>8.700</td>\n",
              "      <td>7.10</td>\n",
              "      <td>1.210</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7991</th>\n",
              "      <td>2ju6pbauusfneayoz42b03nkk</td>\n",
              "      <td>13862399</td>\n",
              "      <td>15.750</td>\n",
              "      <td>8.30</td>\n",
              "      <td>1.114</td>\n",
              "      <td>15.750</td>\n",
              "      <td>8.30</td>\n",
              "      <td>1.114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a0851c6-05e0-4513-a70e-7b5906f4f741')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a0851c6-05e0-4513-a70e-7b5906f4f741 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a0851c6-05e0-4513-a70e-7b5906f4f741');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k1_win_list = []\n",
        "bet_cnt = 0\n",
        "bet_win = 0\n",
        "for k1, res, pred in zip(prem_df.W1live, prem_df.result, prem_df.predict):\n",
        "    if pred == 1:\n",
        "        bet_cnt += 1\n",
        "        if res == 1:\n",
        "            k1_win_list.append(k1 - 1)\n",
        "            bet_win += 1\n",
        "        else:\n",
        "            k1_win_list.append(-1)\n",
        "    else:\n",
        "        k1_win_list.append(0)\n",
        "print('Sum: ', round(sum(k1_win_list), 2))\n",
        "print('Bet count:', bet_cnt)\n",
        "print('Bet wins:', bet_win, ' - bet/win = ', round(bet_win / bet_cnt, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x-GwanMMueS",
        "outputId": "2b94a253-8fca-4039-b0e0-0f1a3d76a5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum:  164.69\n",
            "Bet count: 177\n",
            "Bet wins: 147  - bet/win =  0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k1_win_list = []\n",
        "bet_cnt = 0\n",
        "bet_win = 0\n",
        "for k1, res, pred in zip(prem_df.W1live, prem_df.result, prem_df.predict):\n",
        "    if pred == 0:\n",
        "        bet_cnt += 1\n",
        "        if res == 0:\n",
        "            k1_win_list.append(0.95 / (k1 - 1))\n",
        "            bet_win += 1\n",
        "        else:\n",
        "            k1_win_list.append(-1)\n",
        "    else:\n",
        "        k1_win_list.append(0)\n",
        "print('Sum: ', round(sum(k1_win_list), 2))\n",
        "print('Bet count:', bet_cnt)\n",
        "print('Bet wins:', bet_win, ' - bet/win = ', round(bet_win / bet_cnt, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBjWKIhHNxQk",
        "outputId": "225ab29a-9410-4553-b461-a6d62d28d1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum:  104.81\n",
            "Bet count: 198\n",
            "Bet wins: 166  - bet/win =  0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)"
      ],
      "metadata": {
        "id": "xNb84Y7-H1XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in loader_te.load():\n",
        "    print(x)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmeqwyltmpMZ",
        "outputId": "54b17a3c-8b78-4cdf-bada-58d56570374b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((<tf.Tensor: shape=(500100, 793), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe6f118a290>), <tf.Tensor: shape=(500100, 1), dtype=float32, numpy=\n",
            "array([[1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       ...,\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.]], dtype=float32)>, <tf.Tensor: shape=(500100,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>)\n"
          ]
        }
      ]
    }
  ]
}