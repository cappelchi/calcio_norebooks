{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JnoakdYG0WIm",
        "CNwNrot_8Otu",
        "F7qL3Au-nbm0"
      ],
      "authorship_tag": "ABX9TyPeUSuY8Vl9qm73KjR7Murk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cappelchi/calcio_notebooks/blob/main/draft/football_live_experimental_EDA_lines_heft_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project config"
      ],
      "metadata": {
        "id": "JnoakdYG0WIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import neptune.new as neptune\n",
        "except:\n",
        "    !pip install neptune-client >> None\n",
        "    import neptune.new as neptune\n",
        "#from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "def get_credential(frmwork = 'neptune_team'):\n",
        "    with open('credential.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw"
      ],
      "metadata": {
        "id": "O9bCK_dx0QSM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set API key for neptune.ai\n",
        "set_api = True #@param {type:\"boolean\"}\n",
        "if set_api:\n",
        "    username, api_key = get_credential()"
      ],
      "metadata": {
        "id": "oDK6n6CVQidT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloads"
      ],
      "metadata": {
        "id": "CNwNrot_8Otu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET6NN6BwUdJa",
        "outputId": "6bc64038-e638-42a5-a9e2-01e3a01a54d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from ./data.rar\n",
            "\n",
            "Extracting  data.csv                                                     \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  data.RDS                                                     \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  holdout_id.csv                                               \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  info.csv                                                     \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  prem.csv                                                     \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  test_id.csv                                                  \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  train_id.csv                                                 \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O ./data.rar https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/L30b3SynSzMgdQ\n",
        "!unrar e ./data.rar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l ./data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElllfNOT3N0u",
        "outputId": "480bdbd0-7af7-47f5-fb3a-dc5ea5b438b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14248527 ./data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "3eJJjJHCyrNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 100\n",
        "print(pd.__version__)\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiFFa9gDyqpS",
        "outputId": "97983044-5a25-42e3-fd3b-1ebcfbbca3c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n",
            "1.21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.iinfo(np.int8).max, np.iinfo(np.int16).max, np.iinfo(np.int32).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vnHnF0g4Eg6",
        "outputId": "d691657d-34e0-4058-fecc-6a51f5bea7a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127, 32767, 2147483647)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.finfo(np.float16).precision, np.finfo(np.float32).precision, np.finfo(np.float64).precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O24b3ZHi4SJi",
        "outputId": "e3f11bc6-99d8-4e52-bd7b-47ebe376c862"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 6, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, psutil\n",
        "from tqdm import tqdm\n",
        "import gc"
      ],
      "metadata": {
        "id": "beX-335s9PO_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "kJ0rN-QRzFTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Functions"
      ],
      "metadata": {
        "id": "F7qL3Au-nbm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bash(bashCommand:str, nameCommand = ''):\n",
        "        process = subprocess.Popen([bashCommand], \n",
        "                           shell=True)\n",
        "        _, error = process.communicate()\n",
        "        if error:\n",
        "            print(f'{nameCommand} error:\\n', error)"
      ],
      "metadata": {
        "id": "6xkKvRZwZPeg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Присоединяем итоговый результат и по первому тайму\n",
        "def add_match_results (data_df:pd.DataFrame, cols = ['Id', 'Result1', 'Result2', 'Periods'], info_path = './info.csv'):\n",
        "    info_df = pd.read_csv(info_path, sep = ';', usecols = cols)\n",
        "    info_df[['Period1', 'Period2', 'Period3', 'Period4']] = info_df['Periods'].str.split(',', expand = True)\n",
        "    info_df[['Time1Res1', 'Time1Res2']] = info_df['Period1'].str.split(':', expand = True)\n",
        "    info_df = info_df[~info_df['Id'].duplicated(keep = False)]\n",
        "    period1_result_dict = info_df.set_index('Id')[['Time1Res1', 'Time1Res2', 'Result1', 'Result2']].to_dict(orient = 'index')\n",
        "    #data_df.loc[:, ['Time1Res1', 'Time1Res2', 'Result1', 'Result2']] =  \\\n",
        "    return [[\n",
        "        #period1_result_dict[id]['Time1Res1'], period1_result_dict[id]['Time1Res1'], \n",
        "        period1_result_dict[id]['Result1'], period1_result_dict[id]['Result2']] \n",
        "    if id in period1_result_dict else [None, None] for id in tqdm(data_df['Id'].values, total = len(data_df))]\n",
        "    "
      ],
      "metadata": {
        "id": "S0Ejtg1MgCLt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем прематчевые линии\n",
        "def add_match_lines (data_df:pd.DataFrame, cols = ['P1', 'P2'], prem_path = './prem.csv'):\n",
        "    prem_df = pd.read_csv(prem_path, sep = ';')\n",
        "    prem_df = prem_df[~prem_df['Id'].duplicated(keep = False)]\n",
        "    prem_dict = prem_df.set_index('Id')[cols].to_dict(orient = 'index')\n",
        "    #data_df.loc[:,['P1', 'PX', 'P2', 'PR']] =  \\\n",
        "    return [[prem_dict[id]['P1'], prem_dict[id]['P2']] \n",
        "    if id in prem_dict else [None, None] for id in tqdm(data_df['Id'].values, total = len(data_df))]"
      ],
      "metadata": {
        "id": "5qtEkVIt86Ur"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_dataset(data_df:pd.DataFrame, remain = []):\n",
        "    new_match_vector = data_df['Id'] != data_df['Id'].shift(1)\n",
        "    # трансформируем минуты\n",
        "    data_df['min_norm'] = data_df['Minute'].astype(np.float32) / 50\n",
        "    print('1. Минуты посчитаны...')\n",
        "    # трансформируем голы\n",
        "    data_df[data_df['Score1'].isna() & new_match_vector] = 0\n",
        "    data_df['Score1_norm'] = data_df['Score1'].fillna(method = 'ffill').astype(np.float32) / 4\n",
        "    data_df.loc[data_df['Score1'] > 3, ['Score1_norm']] = 1.0\n",
        "    data_df[data_df['Score2'].isna() & new_match_vector] = 0\n",
        "    data_df['Score2_norm'] = data_df['Score2'].fillna(method = 'ffill').astype(np.float32) / 4\n",
        "    data_df.loc[data_df['Score2'] > 3, ['Score2_norm']] = 1.0\n",
        "\n",
        "    data_df['Score_diff'] = data_df['Score1'].astype(np.int16) - data_df['Score2'].astype(np.int16)\n",
        "    data_df.loc[data_df['Score_diff'] < -4, ['Score_diff']] = -4\n",
        "    data_df.loc[data_df['Score_diff'] > 4, ['Score_diff']] = 4\n",
        "    data_df[[f'Score_cat_{n}' for n in range(1, 10)]] = pd.get_dummies(data_df['Score_diff']).values\n",
        "    data_df['Score_diff'] = data_df['Score_diff'].astype(np.float32) / np.float32(4.0)\n",
        "    if 'Score1' not in remain:\n",
        "        data_df = data_df.drop(['Score1', 'Score2'], axis = 1)\n",
        "    print('2. Голы посчитаны...')\n",
        "    #трансформируем атаки\n",
        "    data_df['A1_scaled'] = data_df['A1'].astype(np.float32) / 75\n",
        "    data_df.loc[data_df['A1'] >= 60, ['A1_scaled']] = (60 + (data_df['A1'] - 60) / 4) / 75\n",
        "    data_df['A2_scaled'] = data_df['A2'].astype(np.float32) / 75\n",
        "    data_df.loc[data_df['A2'] >= 60, ['A2_scaled']] = (60 + (data_df['A2'] - 60) / 4) / 75\n",
        "    # атаки в минуту\n",
        "    data_df['A1perMIN'] = data_df['A1'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['A1perMIN'] > 4, ['A1perMIN']] = np.float32(4.0)\n",
        "    data_df['A2perMIN'] = data_df['A2'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['A2perMIN'] > 4, ['A2perMIN']] = np.float32(4.0)\n",
        "    # динамика атак\n",
        "    new_match_vector5 = data_df['Id'] != data_df['Id'].shift(5)\n",
        "    data_df['A1relativ'] = data_df['A1'].astype(np.float32) - data_df['A1'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['A1relativ']] = np.float32(0.0)\n",
        "    data_df['A1relativ'] = data_df['A1relativ'].fillna(0)\n",
        "    data_df.loc[data_df['A1relativ'] > 15, ['A1relativ']] = np.float32(15.)\n",
        "    data_df['A2relativ'] = data_df['A2'].astype(np.float32) - data_df['A2'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['A2relativ']] =  np.float32(0.0)\n",
        "    data_df['A2relativ'] = data_df['A2relativ'].fillna(0)\n",
        "    data_df.loc[data_df['A2relativ'] > 15, ['A2relativ']] = np.float32(15.)\n",
        "    if 'A1' not in remain:\n",
        "        data_df = data_df.drop(['A1', 'A2'], axis = 1)\n",
        "    print('3. Атаки посчитаны...')\n",
        "    # трансформируем опасные атаки\n",
        "    data_df['DA1_scaled'] = data_df['DA1'].astype(np.float32) / 50\n",
        "    data_df.loc[data_df['DA1'] >= 40, ['DA1_scaled']] = (80 + (data_df['DA1'] - 40) / 3) / 100\n",
        "    data_df['DA2_scaled'] = data_df['DA2'].astype(np.float32) / 50\n",
        "    data_df.loc[data_df['DA2'] >= 40, ['DA2_scaled']] = (80 + (data_df['DA2'] - 40) / 3) / 100\n",
        "    # опасные атаки в минуту    \n",
        "    data_df['DA1perMIN'] = data_df['DA1'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['DA1perMIN'] > 3, ['DA1perMIN']] = np.float32(3.0)\n",
        "    data_df['DA2perMIN'] = data_df['DA2'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['DA2perMIN'] > 3, ['DA2perMIN']] = np.float32(3.0)\n",
        "    # динамика опасных атак\n",
        "    data_df['DA1relativ'] = data_df['DA1'].astype(np.float32) - data_df['DA1'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['DA1relativ']] = np.float32(0.0)\n",
        "    data_df['DA1relativ'] = data_df['DA1relativ'].fillna(0)\n",
        "    data_df.loc[data_df['DA1relativ'] > 10, ['DA1relativ']] = np.float32(10.)\n",
        "    data_df['DA2relativ'] = data_df['DA2'].astype(np.float32) - data_df['DA2'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['DA2relativ']] = np.float32(0.0)\n",
        "    data_df['DA2relativ'] = data_df['DA2relativ'].fillna(0)\n",
        "    data_df.loc[data_df['DA2relativ'] > 10, ['DA2relativ']] = np.float32(10.)\n",
        "    if 'DA1' not in remain:\n",
        "        data_df = data_df.drop(['DA1', 'DA2'], axis = 1)\n",
        "    if 'Minute' not in remain:\n",
        "        data_df = data_df.drop(['Minute'], axis = 1)\n",
        "    print('4. Опасные атаки посчитаны...')\n",
        "    # трансформируем владение мячом\n",
        "    data_df[data_df['Pos1'].isna() & new_match_vector] = 0\n",
        "    data_df['Pos1_cleaned'] = data_df['Pos1'].fillna(method = 'ffill').astype(np.float32) /  np.float32(100.0)\n",
        "    data_df.loc[data_df['Pos1_cleaned'] < 0.2, ['Pos1_cleaned']] = np.float32(0.2)\n",
        "    data_df.loc[data_df['Pos1_cleaned'] > 0.8, ['Pos1_cleaned']] = np.float32(0.8)\n",
        "    data_df[data_df['Pos2'].isna() & new_match_vector] = 0\n",
        "    data_df['Pos2_cleaned'] = data_df['Pos2'].fillna(method = 'ffill').astype(np.float32) /  np.float32(100.0)\n",
        "    data_df.loc[data_df['Pos2_cleaned'] < 0.2, ['Pos2_cleaned']] = np.float32(0.2)\n",
        "    data_df.loc[data_df['Pos2_cleaned'] > 0.8, ['Pos2_cleaned']] = np.float32(0.8)\n",
        "    if 'Pos1' not in remain:\n",
        "        data_df = data_df.drop(['Pos1', 'Pos2'], axis = 1)\n",
        "    print('5. Владение мячом посчитпно...')\n",
        "    # трансформируем удары\n",
        "    data_df[data_df['Off1'].isna() & new_match_vector] = 0\n",
        "    data_df['Off1_norm'] = data_df['Off1'].fillna(method = 'ffill').astype(np.float32) / np.float32(10.0)\n",
        "    data_df.loc[data_df['Off1_norm'] > 1.0, ['Off1_norm']] = np.float32(1.0)\n",
        "    data_df[data_df['Off2'].isna() & new_match_vector] = 0\n",
        "    data_df['Off2_norm'] = data_df['Off2'].fillna(method = 'ffill').astype(np.float32) / np.float32(10.0)\n",
        "    data_df.loc[data_df['Off2_norm'] > 1.0, ['Off2_norm']] = np.float32(1.0)\n",
        "    if 'Off1' not in remain:\n",
        "        data_df = data_df.drop(['Off1', 'Off2'], axis = 1)\n",
        "    print('6. Удары посчитаны...')\n",
        "    # трансформируем удары в створ\n",
        "    data_df[data_df['On1'].isna() & new_match_vector] = 0\n",
        "    data_df['On1_norm'] = data_df['On1'].fillna(method = 'ffill').astype(np.float32) / np.float32(5.0)\n",
        "    data_df.loc[data_df['On1_norm'] > 1.0, ['On1_norm']] = np.float32(1.0)\n",
        "    data_df[data_df['On2'].isna() & new_match_vector] = 0\n",
        "    data_df['On2_norm'] = data_df['On2'].fillna(method = 'ffill').astype(np.float32) / np.float32(5.0)\n",
        "    data_df.loc[data_df['On2_norm'] > 1.0, ['On2_norm']] = np.float32(1.0)\n",
        "    if 'On1' not in remain:\n",
        "        data_df = data_df.drop(['On1', 'On2'], axis = 1)    \n",
        "    print('7. Удары в створ посчитаны...')\n",
        "    # трансформируем желтые карточки\n",
        "    data_df[data_df['YC1'].isna() & new_match_vector] = 0\n",
        "    data_df['YC1_transformed'] = data_df['YC1'].fillna(0).astype(np.float32) / np.float32(2.0)\n",
        "    data_df.loc[data_df['YC1_transformed'] > 1.0, ['YC1_transformed']] = np.float32(1.0)\n",
        "    data_df[data_df['YC2'].isna() & new_match_vector] = 0\n",
        "    data_df['YC2_transformed'] = data_df['YC2'].fillna(0).astype(np.float32) / np.float32(2.0)\n",
        "    data_df.loc[data_df['YC2_transformed'] > 1.0, ['YC2_transformed']] = np.float32(1.0)\n",
        "    if 'YC1' not in remain:\n",
        "        data_df = data_df.drop(['YC1', 'YC2'], axis = 1)\n",
        "    print('8. Жёлтые карточки посчитаны...')\n",
        "    # трансформируем красные карточки\n",
        "    data_df[data_df['RC1'].isna() & new_match_vector] = 0\n",
        "    data_df['RC1_transformed'] = data_df['RC1'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['RC1_transformed'] > 1, ['RC1_transformed']] = np.int8(1)\n",
        "    data_df[data_df['RC2'].isna() & new_match_vector] = 0\n",
        "    data_df['RC2_transformed'] = data_df['RC2'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['RC2_transformed'] > 1, ['RC2_transformed']] = np.int8(1)\n",
        "    if 'RC1' not in remain:\n",
        "        data_df = data_df.drop(['RC1', 'RC2'], axis = 1)\n",
        "    print('9. Красные карточки посчитаны...')\n",
        "    # трансформируем замены\n",
        "    data_df[data_df['Sub1'].isna() & new_match_vector] = 0\n",
        "    data_df['Sub1_transformed'] = data_df['Sub1'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['Sub1_transformed'] > 1, ['Sub1_transformed']] = np.int8(1)\n",
        "    data_df[data_df['Sub2'].isna() & new_match_vector] = 0\n",
        "    data_df['Sub2_transformed'] = data_df['Sub2'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['Sub2_transformed'] > 1, ['Sub2_transformed']] = np.int8(1)\n",
        "    if 'Sub1' not in remain:\n",
        "        data_df = data_df.drop(['Sub1', 'Sub2'], axis = 1)\n",
        "    print('10. Замены посчитаны...')\n",
        "    # трансформируем угловык\n",
        "    data_df[data_df['Cor1'].isna() & new_match_vector] = 0\n",
        "    data_df['Cor1_transformed'] = data_df['Cor1'].fillna(0).astype(np.float32) / np.float32(6.0)\n",
        "    data_df.loc[data_df['Cor1_transformed'] > 1.0, ['Cor1_transformed']] = np.float32(1.0)\n",
        "    data_df[data_df['Cor2'].isna() & new_match_vector] = 0\n",
        "    data_df['Cor2_transformed'] = data_df['Cor2'].fillna(0).astype(np.float32) / np.float32(6.0)\n",
        "    data_df.loc[data_df['Cor2_transformed'] > 1.0, ['Cor2_transformed']] = np.float32(1.0)\n",
        "    if 'Cor1' not in remain:\n",
        "        data_df = data_df.drop(['Cor1', 'Cor2'], axis = 1)\n",
        "    print('11. Угловые посчитаны...')\n",
        "    # трансформируем линию\n",
        "    data_df['P1_transformed'] = np.log(data_df['P1'], dtype = np.float32) / 2\n",
        "    data_df['P2_transformed'] = np.log(data_df['P2'], dtype = np.float32) / 2\n",
        "    if 'P1' not in remain:\n",
        "        data_df = data_df.drop(['P1', 'P2'], axis = 1)\n",
        "    print('12. Линии посчитаны...')\n",
        "    if 'Pen1' not in remain:\n",
        "        data_df = data_df.drop(['Pen1', 'Pen2'], axis = 1)\n",
        "    if 'Active' not in remain:\n",
        "        data_df = data_df.drop(['Active'], axis = 1)\n",
        "    return data_df"
      ],
      "metadata": {
        "id": "9bdxnVfzJb0g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Devide fo 6 parts (train, test, holdout -> 2 parts)"
      ],
      "metadata": {
        "id": "zc6Ym1FTzG0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_types_dict = {\n",
        "    'Id':np.int32, \n",
        "    'StatTime':np.datetime64, \n",
        "    'Minute':np.int8, \n",
        "    'Active': np.int8, 'Score1':np.int8, 'Score2':np.int8,\n",
        "    'A1':np.int16, 'A2':np.int16, 'DA1':np.int16, 'DA2':np.int16, 'Pos1':np.float32, 'Pos2':np.float32,\n",
        "    'Off1':np.int8, 'Off2':np.int8, 'On1':np.int8, 'On2':np.int8, 'YC1':np.int8, 'YC2':np.int8,\n",
        "    'RC1':np.int8, 'RC2':np.int8, 'Sub1':np.int8, 'Sub2':np.int8, 'Pen1':np.int8, 'Pen2':np.int8,\n",
        "    'Cor1':np.int8, 'Cor2':np.int8, 'Period':np.int8, \n",
        "    'D':np.datetime64,\n",
        "    'I':np.int32, 'Active.1':np.int8, \n",
        "    'Time':np.datetime64, \n",
        "    'Minute.1':np.int8, \n",
        "    'RawTime':np.datetime64, \n",
        "    'Score1.1':np.int8, 'Score2.1':np.int8, 'Period.1':np.int8, \n",
        "    'W1':np.float16, 'WX':np.float16, 'W2':np.float16, 'X1':np.float16, 'X2':np.float16, 'W12':np.float16, 'TotalValue':np.float16, \n",
        "    'Over':np.float16, 'Under':np.float16, 'Hand1Value':np.float16, 'H1':np.float16, 'H2':np.float16 \n",
        "}"
      ],
      "metadata": {
        "id": "1pIfsngx1_md"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = [\n",
        "    #'StatTime', \n",
        "    'Comment', 'D', 'I', 'Time', 'Minute.1', 'RawTime',\n",
        "    'Score1.1', 'Score2.1', 'Period.1', 'Period'\n",
        "]"
      ],
      "metadata": {
        "id": "uYOZhxNejKNd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_cols = [\n",
        "    'W1', 'WX', 'W2', 'X1', 'X2', 'W12', 'TotalValue' ,'Over',\n",
        "    'Under', 'Hand1Value', 'H1', 'H2' \n",
        "]"
      ],
      "metadata": {
        "id": "-uPj4aWhDsTC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "29H4D1HnC4Dy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col, col_type in data_types_dict.items(): #{'Id':np.int32 , 'StatTime':np.datetime64}.items(): #\n",
        "    if col not in drop_cols:\n",
        "        data_col = pd.read_csv('./data.csv', sep = ';', usecols = [col])\n",
        "        if col == 'Id':\n",
        "            if data_col[col].isna().sum() > 0:\n",
        "                print(col , ' nan error')\n",
        "            data_col = data_col.astype(col_type)\n",
        "            new_match_vector = data_col['Id'] != data_col['Id'].shift(1)\n",
        "            data_df[col] = data_col\n",
        "        elif col == 'StatTime':\n",
        "            data_col.loc[data_col['StatTime'] == 'NA                 ',['StatTime']] = '31.01.2010 00:00:00'\n",
        "            data_col = data_col.astype(col_type)\n",
        "            data_df[col] = data_col\n",
        "        elif col in k_cols:\n",
        "            data_col = data_col.fillna(0).astype(col_type)\n",
        "            data_df[col] = data_col             \n",
        "        else:\n",
        "            data_col[data_col[col].isna() & new_match_vector] = 0\n",
        "            data_col = data_col.fillna(method = 'ffill').astype(col_type)\n",
        "            data_df[col] = data_col\n",
        "        del data_col\n",
        "        gc.collect()\n",
        "        #---------------\n",
        "        process = psutil.Process(os.getpid())\n",
        "        print(col, ' mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes \n",
        "        #---------------    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "3rMH66prYzsx",
        "outputId": "84bc7897-5df6-4e8e-8442-dbdab536ce34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id  mem usage:  0.43 GiB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-00f628f9c3c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'StatTime'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdata_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StatTime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NA                 '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StatTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'31.01.2010 00:00:00'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5814\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5815\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5816\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# attribute \"reshape\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             return astype_nansafe(\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;31m# caching attempts to create a DatetimeIndex, which may raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2181\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                                       second=0, microsecond=0)\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0;31m# Numeric token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_numeric_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# Check weekday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36m_parse_numeric_token\u001b[0;34m(self, tokens, idx, info, ymd, res, fuzzy)\u001b[0m\n\u001b[1;32m    956\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                     \u001b[0;31m# 01-01[-01]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m                     \u001b[0mymd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                     \u001b[0;31m# 01-Jan[-01]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, val, label)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_df = data_df.drop_duplicates()\n",
        "time_df.to_csv('./time.csv', index = False)"
      ],
      "metadata": {
        "id": "6foN9xFPPl-5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Добавляем финальный результат\n",
        "data_df.loc[:, ['Result1', 'Result2']] = add_match_results (data_df)\n",
        "data_df[['Result1', 'Result2']] = data_df[['Result1', 'Result2']].astype(np.int8)\n",
        "\n",
        "## Добавляем линии\n",
        "data_df.loc[:,['P1', 'P2']] = add_match_lines (data_df)\n",
        "data_df[['P1', 'P2']] = data_df[['P1', 'P2']].astype(np.float16)\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print(col, ' mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes \n",
        "#---------------    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XZJ83ybSzNu",
        "outputId": "b4df05d5-ec67-4007-9cdf-ea34dc3d0975"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14248526/14248526 [01:45<00:00, 135408.20it/s]\n",
            "100%|██████████| 14248526/14248526 [01:36<00:00, 147028.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2  mem usage:  1.44 GiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = transform_dataset(data_df, #) \n",
        "    remain = ['Score1', 'Score2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVV94qUZWZ8w",
        "outputId": "ecdd158d-29d0-4183-8213-4bcf10a42ba3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Минуты посчитаны...\n",
            "2. Голы посчитаны...\n",
            "3. Атаки посчитаны...\n",
            "4. Опасные атаки посчитаны...\n",
            "5. Владение мячом посчитпно...\n",
            "6. Удары посчитаны...\n",
            "7. Удары в створ посчитаны...\n",
            "8. Жёлтые карточки посчитаны...\n",
            "9. Красные карточки посчитаны...\n",
            "10. Замены посчитаны...\n",
            "11. Угловые посчитаны...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12. Линии посчитаны...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('P1 NaN & P2 NaN: ', data_df['P1_transformed'].isna().sum(), data_df['P2_transformed'].isna().sum())\n",
        "\n",
        "data_df = data_df[~data_df['P1_transformed'].isna()]\n",
        "data_df = data_df[~data_df['P2_transformed'].isna()]\n",
        "\n",
        "print('Score-Result error 1&2: ', (~(data_df['Result1'] - data_df['Score1']) >= 0).sum(), (~(data_df['Result1'] - data_df['Score1']) >= 0).sum())\n",
        "data_df = data_df.loc[(data_df['Result1'] - data_df['Score1']) >= 0]\n",
        "data_df = data_df.loc[(data_df['Result2'] - data_df['Score2']) >= 0]\n",
        "\n",
        "\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print('mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes \n",
        "#---------------    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP-ddxD70oHE",
        "outputId": "8cb1831c-7a22-4c5c-da3f-e19715a56727"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1 NaN & P2 NaN:  105537 105537\n",
            "Score-Result error 1&2:  840 840\n",
            "mem usage:  4.89 GiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqXBF1XX0oDU",
        "outputId": "3ecf0519-8ba5-4a0d-9fec-1aee6513c7c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14141621 entries, 0 to 14248525\n",
            "Data columns (total 59 columns):\n",
            " #   Column            Dtype  \n",
            "---  ------            -----  \n",
            " 0   Id                int32  \n",
            " 1   Score1            int8   \n",
            " 2   Score2            int8   \n",
            " 3   Active.1          int8   \n",
            " 4   W1                float16\n",
            " 5   WX                float16\n",
            " 6   W2                float16\n",
            " 7   X1                float16\n",
            " 8   X2                float16\n",
            " 9   W12               float16\n",
            " 10  TotalValue        float16\n",
            " 11  Over              float16\n",
            " 12  Under             float16\n",
            " 13  Hand1Value        float16\n",
            " 14  H1                float16\n",
            " 15  H2                float16\n",
            " 16  Result1           int8   \n",
            " 17  Result2           int8   \n",
            " 18  min_norm          float32\n",
            " 19  Score1_norm       float32\n",
            " 20  Score2_norm       float32\n",
            " 21  Score_diff        float32\n",
            " 22  Score_cat_1       uint8  \n",
            " 23  Score_cat_2       uint8  \n",
            " 24  Score_cat_3       uint8  \n",
            " 25  Score_cat_4       uint8  \n",
            " 26  Score_cat_5       uint8  \n",
            " 27  Score_cat_6       uint8  \n",
            " 28  Score_cat_7       uint8  \n",
            " 29  Score_cat_8       uint8  \n",
            " 30  Score_cat_9       uint8  \n",
            " 31  A1_scaled         float32\n",
            " 32  A2_scaled         float32\n",
            " 33  A1perMIN          float32\n",
            " 34  A2perMIN          float32\n",
            " 35  A1relativ         float32\n",
            " 36  A2relativ         float32\n",
            " 37  DA1_scaled        float32\n",
            " 38  DA2_scaled        float32\n",
            " 39  DA1perMIN         float32\n",
            " 40  DA2perMIN         float32\n",
            " 41  DA1relativ        float32\n",
            " 42  DA2relativ        float32\n",
            " 43  Pos1_cleaned      float32\n",
            " 44  Pos2_cleaned      float32\n",
            " 45  Off1_norm         float32\n",
            " 46  Off2_norm         float32\n",
            " 47  On1_norm          float32\n",
            " 48  On2_norm          float32\n",
            " 49  YC1_transformed   float32\n",
            " 50  YC2_transformed   float32\n",
            " 51  RC1_transformed   int8   \n",
            " 52  RC2_transformed   int8   \n",
            " 53  Sub1_transformed  int8   \n",
            " 54  Sub2_transformed  int8   \n",
            " 55  Cor1_transformed  float32\n",
            " 56  Cor2_transformed  float32\n",
            " 57  P1_transformed    float32\n",
            " 58  P2_transformed    float32\n",
            "dtypes: float16(12), float32(28), int32(1), int8(9), uint8(9)\n",
            "memory usage: 2.2 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_df.to_csv('./data_all.csv', index = False)"
      ],
      "metadata": {
        "id": "m0xEB8Rn0n96"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_df = pd.read_csv('./data_all.csv',)"
      ],
      "metadata": {
        "id": "tfdjdRTwFhKp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id_df = pd.read_csv('./train_id.csv', header = None, names = ['id'])\n",
        "test_id_df = pd.read_csv('./test_id.csv', header = None, names = ['id'])\n",
        "holdout_id_df = pd.read_csv('./holdout_id.csv', header = None, names = ['id'])\n",
        "\n",
        "train_vector = data_df['Id'].isin(train_id_df['id'])\n",
        "test_vector = data_df['Id'].isin(test_id_df['id'])\n",
        "holdout_vector = data_df['Id'].isin(holdout_id_df['id'])"
      ],
      "metadata": {
        "id": "ZeakI5OoOyKL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryxlajMl8NAF",
        "outputId": "16608945-8c65-420b-f3e2-8e0b76fddc24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Score1', 'Score2', 'Active.1', 'W1', 'WX', 'W2', 'X1', 'X2',\n",
              "       'W12', 'TotalValue', 'Over', 'Under', 'Hand1Value', 'H1', 'H2',\n",
              "       'Result1', 'Result2', 'min_norm', 'Score1_norm', 'Score2_norm',\n",
              "       'Score_diff', 'Score_cat_1', 'Score_cat_2', 'Score_cat_3',\n",
              "       'Score_cat_4', 'Score_cat_5', 'Score_cat_6', 'Score_cat_7',\n",
              "       'Score_cat_8', 'Score_cat_9', 'A1_scaled', 'A2_scaled', 'A1perMIN',\n",
              "       'A2perMIN', 'A1relativ', 'A2relativ', 'DA1_scaled', 'DA2_scaled',\n",
              "       'DA1perMIN', 'DA2perMIN', 'DA1relativ', 'DA2relativ', 'Pos1_cleaned',\n",
              "       'Pos2_cleaned', 'Off1_norm', 'Off2_norm', 'On1_norm', 'On2_norm',\n",
              "       'YC1_transformed', 'YC2_transformed', 'RC1_transformed',\n",
              "       'RC2_transformed', 'Sub1_transformed', 'Sub2_transformed',\n",
              "       'Cor1_transformed', 'Cor2_transformed', 'P1_transformed',\n",
              "       'P2_transformed'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Id', 'BeginTime']\n",
        "info_path = './info.csv'\n",
        "info_df = pd.read_csv(info_path, sep = ';', \n",
        "                      usecols = cols\n",
        "                      )\n"
      ],
      "metadata": {
        "id": "81DBGaEtGqM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile save_discription.txt\n",
        "np.savez_compressed('./dataset', \n",
        "                    #id_train = id_train,\n",
        "                    #id_test = id_test,\n",
        "                    X_train =  data_df[data_df.columns[18:]][train_vector].values,\n",
        "                    X_test = data_df[data_df.columns[18:]][test_vector].values,\n",
        "                    X_holdout = data_df[data_df.columns[18:]][holdout_vector].values,\n",
        "                    y_train_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[train_vector],\n",
        "                    y_test_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[test_vector],\n",
        "                    y_holdout_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[holdout_vector],\n",
        "                    y_train_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[train_vector] + 1,\n",
        "                    y_test_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[test_vector] + 1,\n",
        "                    y_holdout_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[holdout_vector] + 1,\n",
        "                    y_train_diff = (data_df['Result1'] - data_df['Result2']).values[train_vector],\n",
        "                    y_test_diff = (data_df['Result1'] - data_df['Result2']).values[test_vector],\n",
        "                    y_holdout_diff = (data_df['Result1'] - data_df['Result2']).values[holdout_vector],\n",
        "                    y_train_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[train_vector],\n",
        "                    y_train_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[train_vector],\n",
        "                    y_test_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[test_vector],\n",
        "                    y_test_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[test_vector],\n",
        "                    y_holdout_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[holdout_vector],\n",
        "                    y_holdout_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[holdout_vector],\n",
        "                    score1_train = data_df['Score1'].values[train_vector],\n",
        "                    score2_train = data_df['Score2'].values[train_vector],\n",
        "                    result1_train = data_df['Result1'].values[train_vector],\n",
        "                    result2_train = data_df['Result2'].values[train_vector],\n",
        "                    score1_test = data_df['Score1'].values[test_vector],\n",
        "                    score2_test = data_df['Score2'].values[test_vector],\n",
        "                    result1_test = data_df['Result1'].values[test_vector],\n",
        "                    result2_test = data_df['Result2'].values[test_vector],\n",
        "                    score1_holdout = data_df['Score1'].values[holdout_vector],\n",
        "                    score2_holdout = data_df['Score2'].values[holdout_vector],\n",
        "                    result1_holdout = data_df['Result1'].values[holdout_vector],\n",
        "                    result2_holdout = data_df['Result2'].values[holdout_vector],\n",
        "                    K_train = data_df[data_df.columns[3:16]].values[train_vector],\n",
        "                    K_test = data_df[data_df.columns[3:16]].values[test_vector],\n",
        "                    K_holdout = data_df[data_df.columns[3:16]].values[holdout_vector]\n",
        "                )"
      ],
      "metadata": {
        "id": "F0yfAUhiBskl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('./additional_data', \n",
        "                    id_train = data_df['Id'][train_vector].values,\n",
        "                    id_test = data_df['Id'][test_vector].values,\n",
        "                    id_holdout = data_df['Id'][holdout_vector].values,\n",
        "                    min_train = data_df['min_norm'][train_vector].values,\n",
        "                    min_test = data_df['min_norm'][test_vector].values,\n",
        "                    min_holdout = data_df['min_norm'][holdout_vector].values\n",
        ")"
      ],
      "metadata": {
        "id": "jQHU6X889wPg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "params['description'] = 'датасет под бусты \\n' + \\\n",
        "'удалены строки с nan в P1, P2 \\n' + \\\n",
        "'простые фичи, \\n' + \\\n",
        "'4 класса задач, бинарная классификация и мультикласс, и под регрессию 2 варианта '\n",
        "params['features'] = list(data_df.columns)"
      ],
      "metadata": {
        "id": "o5kOL-QIBcPg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_version = 'football_live_npz_230131/'\n",
        "project = neptune.init_project(\n",
        "    project=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "project[data_version + 'dataset'].upload('./dataset.npz')\n",
        "project[data_version + 'description'].upload('./save_discription.txt')\n",
        "project[data_version + 'additional_data'].upload('./additional_data.npz')\n",
        "project[data_version + 'info'].upload('./info.csv')\n",
        "project[data_version + 'time'].upload('./time.csv')\n",
        "project[data_version + 'params'] = params\n",
        "project.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdrsGWUADyvJ",
        "outputId": "bbbf7c2a-0e77-4f98-dda2-d35438d51b0c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 1 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rlUNa0TDyne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.columns[:18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhGlHFO6DcIt",
        "outputId": "5f66cb5c-3a0f-41b3-f9e2-d2220b59a26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Score1', 'Score2', 'Active.1', 'W1', 'WX', 'W2', 'X1', 'X2',\n",
              "       'W12', 'TotalValue', 'Over', 'Under', 'Hand1Value', 'H1', 'H2',\n",
              "       'Result1', 'Result2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgPwRd2QBY7I",
        "outputId": "c0b24b90-2026-461e-9399-ba4b9fbe6563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Score1', 'Score2', 'Active.1', 'W1', 'WX', 'W2', 'X1', 'X2',\n",
              "       'W12', 'TotalValue', 'Over', 'Under', 'Hand1Value', 'H1', 'H2',\n",
              "       'Result1', 'Result2', 'min_norm', 'Score1_norm', 'Score2_norm',\n",
              "       'Score_diff', 'Score_cat_1', 'Score_cat_2', 'Score_cat_3',\n",
              "       'Score_cat_4', 'Score_cat_5', 'Score_cat_6', 'Score_cat_7',\n",
              "       'Score_cat_8', 'Score_cat_9', 'A1_scaled', 'A2_scaled', 'A1perMIN',\n",
              "       'A2perMIN', 'A1relativ', 'A2relativ', 'DA1_scaled', 'DA2_scaled',\n",
              "       'DA1perMIN', 'DA2perMIN', 'DA1relativ', 'DA2relativ', 'Pos1_cleaned',\n",
              "       'Pos2_cleaned', 'Off1_norm', 'Off2_norm', 'On1_norm', 'On2_norm',\n",
              "       'YC1_transformed', 'YC2_transformed', 'RC1_transformed',\n",
              "       'RC2_transformed', 'Sub1_transformed', 'Sub2_transformed',\n",
              "       'Cor1_transformed', 'Cor2_transformed', 'P1_transformed',\n",
              "       'P2_transformed'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_df[data_df.columns[18:]][train_vector].values\n",
        "X_test = data_df[data_df.columns[18:]][test_vector].values\n",
        "X_holdout = data_df[data_df.columns[18:]][holdout_vector].values"
      ],
      "metadata": {
        "id": "Wd0-kcIoEcSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[train_vector]\n",
        "y_test_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[test_vector]\n",
        "y_holdout_bin = np.array((data_df['Result1'] > data_df['Result2']) *1, dtype = np.int8)[holdout_vector])"
      ],
      "metadata": {
        "id": "JMMX9RUxuPbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[train_vector] + 1\n",
        "y_test_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[test_vector] + 1\n",
        "y_holdout_multi = np.sign((data_df['Result1'] - data_df['Result2']).values)[holdout_vector] + 1"
      ],
      "metadata": {
        "id": "FnFy4V6hxDYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_diff = (data_df['Result1'] - data_df['Result2']).values[train_vector]\n",
        "y_test_diff = (data_df['Result1'] - data_df['Result2']).values[test_vector]\n",
        "y_holdout_diff = (data_df['Result1'] - data_df['Result2']).values[holdout_vector]"
      ],
      "metadata": {
        "id": "QevUd-G-yCPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[train_vector]\n",
        "y_train_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[train_vector]\n",
        "y_test_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[test_vector]\n",
        "y_test_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[test_vector]\n",
        "y_test_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values[holdout_vector]\n",
        "y_test_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values[holdout_vector]"
      ],
      "metadata": {
        "id": "7tRQWVgkymHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, X_holdout.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irYzAjr6E02x",
        "outputId": "2c8422de-e7f7-4bd6-8640-fc7132297390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11197708, 41), (2798988, 41), (144925, 41))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[data_df['Id'].isin(train_id_df['id'])].to_csv('data_train.csv', index = False)\n",
        "data_df[data_df['Id'].isin(test_id_df['id'])].to_csv('data_test.csv', index = False)\n",
        "data_df[data_df['Id'].isin(holdout_id_df['id'])].to_csv('data_holdout.csv', index = False)"
      ],
      "metadata": {
        "id": "TOF1v6Ul_Hpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "data_df = data_df[data_df[['W1', 'WX', 'W2', 'X1', 'X2', 'W12', 'Over', 'Under', 'H1', 'H2' ]].sum(axis = 1) > 0]\n",
        "data_df = data_df[~(data_df['Active.1'] == 0)]"
      ],
      "metadata": {
        "id": "9Cgy8npmaTQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_df[data_df['Id'].isin(train_id_df['id'])]), \\\n",
        "len(data_df[data_df['Id'].isin(test_id_df['id'])]), \\\n",
        "len(data_df[data_df['Id'].isin(holdout_id_df['id'])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK8nu8Mb2CDk",
        "outputId": "955b19e8-1d4a-44b4-9e79-ff6b7d748cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3375750, 849640, 124367)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[data_df['P1_transformed'].isna()]"
      ],
      "metadata": {
        "id": "oCqvDD6u2B-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = [\n",
        "    'Id', 'StatTime', 'Minute', 'Active', 'Score1', 'Score2', 'A1', 'A2', 'DA1', 'DA2', 'Pos1', 'Pos2',\n",
        "    'Off1', 'Off2', 'On1', 'On2', 'YC1', 'YC2', 'RC1', 'RC2', 'Sub1', 'Sub2', 'Pen1', 'Pen2',\n",
        "    'Cor1', 'Cor2', 'Period', 'Comment', 'D', 'I', 'Active.1', 'Time', 'Minute.1', 'RawTime',\n",
        "    'Score1.1', 'Score2.1', 'Period.1', 'W1', 'WX', 'W2', 'X1', 'X2', 'W12', 'TotalValue' ,'Over',\n",
        "    'Under', 'Hand1Value', 'H1', 'H2' \n",
        "]\n"
      ],
      "metadata": {
        "id": "d4qWtCd29pEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train[data_train[['W1', 'WX', 'W2', 'X1', 'X2', 'W12', 'Over', 'Under', 'H1', 'H2' ]].sum(axis = 1) > 0]"
      ],
      "metadata": {
        "id": "t39IuZTl5-9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[~(data_train['Active.1'] == 0)]"
      ],
      "metadata": {
        "id": "x7K1CRZ66fd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.to_csv('./data_train.csv.gz', index = False, compression = {'method':'gzip'})\n",
        "data_test.to_csv('./data_test.csv.gz', index = False, compression = {'method':'gzip'})\n",
        "data_holdout.to_csv('./data_holdout.csv.gz', index = False, compression = {'method':'gzip'})"
      ],
      "metadata": {
        "id": "XxWWijMTqwsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\n",
        "    './data.csv', \n",
        "    sep = ';',\n",
        "#    usecols = [col],\n",
        "#    #parse_dates = ['StatTime'],\n",
        "    header = None, \n",
        "    names = names, \n",
        "#    dtype = data_types_dict, \n",
        "#    nrows = 10_000\n",
        "    skiprows = 10_000_000\n",
        "    )"
      ],
      "metadata": {
        "id": "8gsfx_wfE3zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "id": "8JxFOJ3qNLd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}