{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxslP3xesrd+hY2p3gULL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cappelchi/calcio_notebooks/blob/main/draft/football_word2vec_train_multiclass_220820.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project config"
      ],
      "metadata": {
        "id": "JnoakdYG0WIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neptune-client neptune-tensorflow-keras"
      ],
      "metadata": {
        "id": "qJoD3JIX0x58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune.new as neptune\n",
        "#from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "def get_credential(frmwork = 'neptune_team'):\n",
        "    with open('cred_andrey.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw"
      ],
      "metadata": {
        "id": "O9bCK_dx0QSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set API key for neptune.ai\n",
        "set_api = True #@param {type:\"boolean\"}\n",
        "if set_api:\n",
        "    username, api_key = get_credential()"
      ],
      "metadata": {
        "id": "oDK6n6CVQidT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dEcqW_jH4pw"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade gensim"
      ],
      "metadata": {
        "id": "dP-bo_CB7GgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X69hHEsFix4n"
      },
      "source": [
        "### Downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = './dataset_npz.npz'\n",
        "validation_dataset_name = './prem_validation.csv'\n",
        "dataset_version = 'data/dataset_val_prod_0818'\n",
        "project = neptune.init_project(\n",
        "    name=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "#project['data/dataset4train_y19_y22'].download(dataset_name)\n",
        "project['data/validation_prem_220818'].download(validation_dataset_name)\n",
        "project[dataset_version].download(dataset_name)\n",
        "w2v_model_link = project['data/word2vec_220811_link'].fetch()\n",
        "word2vec_params = project['data/word2vec_params'].fetch()\n",
        "project.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFhlCBt1jw8",
        "outputId": "c2d332ed-c17c-4926-a25d-4b9f6d13b73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/project#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RocnM6a5lPkc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyCzUjbzRuA",
        "outputId": "e1f077f0-1e82-4e0a-c001-68631d8b3737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n",
            "1.21.6\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 100\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "\n",
        "#import dask.dataframe as dd\n",
        "import subprocess\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM5QUB5pIV0T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGzwBcNbIc8V"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "from itertools import cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbfhlbNrIf2v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, GRU, LSTM\n",
        "from keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "from tensorflow.data import Dataset\n",
        "#from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umm53OS2Ljgg"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Functions"
      ],
      "metadata": {
        "id": "F7qL3Au-nbm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bash(bashCommand:str, nameCommand = ''):\n",
        "        process = subprocess.Popen([bashCommand], \n",
        "                           shell=True)\n",
        "        _, error = process.communicate()\n",
        "        if error:\n",
        "            print(f'{nameCommand} error:\\n', error)"
      ],
      "metadata": {
        "id": "jhy1ASJGGnug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    acc = history['acc'] if 'acc' in history.keys() else history['accuracy']\n",
        "    val_acc = history['val_acc'] if 'val_acc' in history.keys() else history['val_accuracy']\n",
        "    loss = history['loss'] \n",
        "    val_loss = history['val_loss'] \n",
        "    epochs = tuple(range(len(acc)))\n",
        "    fig = go.Figure()\n",
        "    fig = make_subplots(rows=1, cols=2, subplot_titles = ['Training and validation accuracy', 'Training and validation loss'])\n",
        "    fig.add_trace(go.Scatter(x = epochs, y = acc, mode = 'lines+markers', name = 'train accuracy'), \n",
        "                row = 1, col = 1)\n",
        "    fig.add_trace(go.Scatter(x = epochs, y = val_acc, mode = 'lines+markers', name = 'validation accuracy'), \n",
        "                row = 1, col = 1)\n",
        "    fig.add_trace(go.Scatter(x = epochs, y = loss, mode = 'lines+markers', name = 'train loss'), \n",
        "                row = 1, col = 2)\n",
        "    fig.add_trace(go.Scatter(x = epochs, y = val_loss, mode = 'lines+markers', name = 'validation loss'), \n",
        "                row = 1, col = 2)\n",
        "\n",
        "    fig.show()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "UsjU3CtYTo8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaxYpane0krf"
      },
      "source": [
        "#### Load tensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# трейн, тест, валидация, часть продакшн датасета + кэфы для продакшена + эмбеддингги\n",
        "X_train, X_test, X_validation,\\\n",
        "_, _, _,\\\n",
        "X_production,\\\n",
        "_,\\\n",
        "y_class_train, y_class_test,y_class_validation, y_class_production,\\\n",
        "Line_production, embedding_matrix = np.load(dataset_name).values()"
      ],
      "metadata": {
        "id": "pDVSpHiOGro3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, X_validation.shape, X_production.shape, type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAZK-zYXH0Nm",
        "outputId": "f27392bc-5643-4301-ad16-0d4183fcf805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1595638, 12), (456113, 12), (95894, 12), (7992, 12), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_class_train.shape, y_class_test.shape, y_class_validation.shape, y_class_production.shape, type(y_class_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-Fxu6BHH5KG",
        "outputId": "e5d465d2-2f46-44a6-a373-1144df0748c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1595638, 3), (456113, 3), (95894, 3), (7992, 3), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape, type(embedding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AbZb9yIu3r",
        "outputId": "07bc14c4-cc9c-4cda-9d8e-e6585fed7562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((318979, 256), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####RNN"
      ],
      "metadata": {
        "id": "5dIEUj-6NwOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Проверяем наличие GPU\n",
        "gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "if len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFjYIOgW7PUg",
        "outputId": "3a31dcc0-2ab0-46b4-9239-e77393a09287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on single GPU  /device:GPU:0\n",
            "Number of accelerators:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_params = dict(dataset_version = dataset_version)"
      ],
      "metadata": {
        "id": "lFuEq7XaJYFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_params.update({'batch_size':2048})\n",
        "steps_per_epoch = int(X_train.shape[0] / RNN_params['batch_size']) + 1\n",
        "validation_steps = int(X_test.shape[0] / RNN_params['batch_size']) + 1"
      ],
      "metadata": {
        "id": "Z7ecoR5jJcL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_params.update({'input_length':12, 'embed_dim':128, \n",
        "                   'activation_dense':'sigmoid','initial_learning_rate':1e-3},\n",
        "                  )\n",
        "class Net(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = Embedding(embedding_matrix.shape[0], \n",
        "                        word2vec_params['vector_size'],\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=RNN_params['input_length'],\n",
        "                        trainable=False)\n",
        "        self.rnn = SimpleRNN(RNN_params['embed_dim'])\n",
        "        self.dense1 = Dense(128, activation=RNN_params['activation_dense'])\n",
        "        self.dense2 = Dense(3, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        x1 = self.embed(x)\n",
        "        x2 = self.rnn(x1)\n",
        "        x3 = self.dense1(x2)\n",
        "        output = self.dense2(x3)\n",
        "        return output\n",
        "\n",
        "initial_learning_rate = RNN_params['initial_learning_rate']  # Learning rate\n",
        "\n",
        "RNN_params.update(\n",
        "    {'compile':{\n",
        "    'optimizer':RMSprop(learning_rate = initial_learning_rate),\n",
        "    'loss':BinaryCrossentropy(),\n",
        "    'weighted_metrics':[\"acc\"]\n",
        "            }})\n",
        "model = Net()\n",
        "model.compile(\n",
        "        **RNN_params['compile']\n",
        "                )"
      ],
      "metadata": {
        "id": "GoYXeKPwrej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_params.update(\n",
        "{'ROP_params':{'monitor':'val_loss', 'patience': 5,\n",
        "                   'factor':0.1, 'verbose':1, 'cooldown':25,\n",
        "                   'min_lr':1e-6}})\n",
        "ReduceLROnPlateau_callback = ReduceLROnPlateau(**RNN_params['ROP_params'])\n",
        "RNN_params.update(\n",
        "{'MCh_params':{'filepath':'./models_weights','monitor':'val_loss', 'verbose':1,\n",
        "                   'save_best_only':True, 'save_weights_only':False,\n",
        "                   }})\n",
        "ModelCheckpoint_callback = ModelCheckpoint(**RNN_params['MCh_params'])"
      ],
      "metadata": {
        "id": "SfIL5P27JkSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_params.update({'input_length':12, 'embed_dim':128, \n",
        "                   'activation_dense':'sigmoid','epochs':10})\n",
        "history = model.fit(X_train, y_class_train,\n",
        "                    epochs=RNN_params['epochs'],\n",
        "                    batch_size=RNN_params['batch_size'],\n",
        "                    validation_data = (X_test, y_class_test),\n",
        "                    #validation_split=RNN_params['validation_split'],\n",
        "                    callbacks=[\n",
        "                        ReduceLROnPlateau_callback,\n",
        "                        ModelCheckpoint_callback\n",
        "                                ]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANaawcU7JlD3",
        "outputId": "8817ba82-bc53-4dd9-d8f7-84b6a5c2596b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.4654\n",
            "Epoch 1: val_loss improved from inf to 0.62088, saving model to ./models_weights\n",
            "780/780 [==============================] - 173s 218ms/step - loss: 0.6113 - acc: 0.4654 - val_loss: 0.6209 - val_acc: 0.4570 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6060 - acc: 0.4729\n",
            "Epoch 2: val_loss improved from 0.62088 to 0.61152, saving model to ./models_weights\n",
            "780/780 [==============================] - 176s 226ms/step - loss: 0.6060 - acc: 0.4729 - val_loss: 0.6115 - val_acc: 0.4610 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.4768\n",
            "Epoch 3: val_loss improved from 0.61152 to 0.61088, saving model to ./models_weights\n",
            "780/780 [==============================] - 176s 225ms/step - loss: 0.6036 - acc: 0.4768 - val_loss: 0.6109 - val_acc: 0.4599 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.4792\n",
            "Epoch 4: val_loss did not improve from 0.61088\n",
            "780/780 [==============================] - 175s 224ms/step - loss: 0.6021 - acc: 0.4792 - val_loss: 0.6134 - val_acc: 0.4613 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.4811\n",
            "Epoch 5: val_loss improved from 0.61088 to 0.60854, saving model to ./models_weights\n",
            "780/780 [==============================] - 157s 202ms/step - loss: 0.6010 - acc: 0.4811 - val_loss: 0.6085 - val_acc: 0.4634 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.4825\n",
            "Epoch 6: val_loss improved from 0.60854 to 0.60469, saving model to ./models_weights\n",
            "780/780 [==============================] - 169s 217ms/step - loss: 0.6002 - acc: 0.4825 - val_loss: 0.6047 - val_acc: 0.4687 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.5994 - acc: 0.4834\n",
            "Epoch 7: val_loss did not improve from 0.60469\n",
            "780/780 [==============================] - 156s 199ms/step - loss: 0.5994 - acc: 0.4834 - val_loss: 0.6053 - val_acc: 0.4705 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.5988 - acc: 0.4847\n",
            "Epoch 8: val_loss did not improve from 0.60469\n",
            "780/780 [==============================] - 159s 204ms/step - loss: 0.5988 - acc: 0.4847 - val_loss: 0.6066 - val_acc: 0.4697 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.5983 - acc: 0.4856\n",
            "Epoch 9: val_loss did not improve from 0.60469\n",
            "780/780 [==============================] - 158s 203ms/step - loss: 0.5983 - acc: 0.4856 - val_loss: 0.6048 - val_acc: 0.4713 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "779/780 [============================>.] - ETA: 0s - loss: 0.5978 - acc: 0.4862\n",
            "Epoch 10: val_loss did not improve from 0.60469\n",
            "780/780 [==============================] - 161s 207ms/step - loss: 0.5978 - acc: 0.4862 - val_loss: 0.6076 - val_acc: 0.4707 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_MODEL = './model.tar.gz'\n",
        "bashCommand = f\"\"\"\n",
        "tar -czvf {PATH_TO_MODEL} {RNN_params['MCh_params']['filepath']}\n",
        "\"\"\"\n",
        "run_bash(bashCommand, 'tar_model')"
      ],
      "metadata": {
        "id": "N9mkqQrNJpB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = neptune.init_model_version(\n",
        "    model = 'FOOT-RNN',\n",
        "    project = 'scomesse/football',\n",
        "    api_token = api_key # your credentials\n",
        ")\n",
        "model_sys = model_version['sys'].fetch()\n",
        "model_version_params = dict(\n",
        "    project = 'scomesse/football',\n",
        "    model = model_sys['model_id'],\n",
        "    api_token = api_key,\n",
        "    version = model_sys['id']\n",
        ")\n",
        "model_version['model'].upload(PATH_TO_MODEL)\n",
        "model_version['parameters'] = RNN_params\n",
        "model_version.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHSa_WJ-JqXB",
        "outputId": "f1c3e733-57a3-42fe-8960-4331d2c5ace6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/m/FOOT-RNN/v/FOOT-RNN-9\n",
            "Remember to stop your model_version once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/model-version#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 22 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 22 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/m/FOOT-RNN/v/FOOT-RNN-9/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plot_training_history(history.history)"
      ],
      "metadata": {
        "id": "gusCIz5UJr6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = neptune.init_model_version(**model_version_params)\n",
        "model_version['plot_training'].upload(neptune.types.File.as_html(fig))\n",
        "model_version.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQdiWxkzJt3k",
        "outputId": "adc5a76a-8f3d-4470-9745-5d5201fe5eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/m/FOOT-RNN/v/FOOT-RNN-9\n",
            "Remember to stop your model_version once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/model-version#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 1 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/m/FOOT-RNN/v/FOOT-RNN-9/metadata\n"
          ]
        }
      ]
    }
  ]
}