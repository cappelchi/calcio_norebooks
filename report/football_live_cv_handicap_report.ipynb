{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cappelchi/calcio_notebooks/blob/main/report/football_live_cv_handicap_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaqQZgiFbJ4R"
      },
      "source": [
        "Делает отчет по предиктам в тоталах и визуализрует результат<br>\n",
        "Важные переменные"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_list = ['A1relativ', 'A2relativ', 'DA1relativ', 'DA2relativ'] #Ненужные фичи для предикта\n",
        "selected_model1_version = 6 #3 #6 # Номер модели1\n",
        "selected_model2_version = 5 #4 #5 # Номер модели2\n",
        "folded = True #False #True # Модель на фолдах или нет"
      ],
      "metadata": {
        "id": "R5EqOqdJDeGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnoakdYG0WIm"
      },
      "source": [
        "### Project config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9bCK_dx0QSM"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import neptune\n",
        "except:\n",
        "    !pip install neptune >> None\n",
        "    import neptune\n",
        "#from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "def get_credential(frmwork = 'neptune_team'):\n",
        "    with open('credential.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDK6n6CVQidT"
      },
      "outputs": [],
      "source": [
        "#@title Set API key for neptune.ai\n",
        "set_api = True #@param {type:\"boolean\"}\n",
        "if set_api:\n",
        "    username, api_key = get_credential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THFvsIdI6Jr_"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW1B1cfQ6I1M"
      },
      "outputs": [],
      "source": [
        "!pip install catboost >> None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNwNrot_8Otu"
      },
      "source": [
        "### Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7Ko3YfKS7ho"
      },
      "outputs": [],
      "source": [
        "!wget -q -O ./data.rar https://getfile.dokpub.com/yandex/get/...здесь линк на холдаут\n",
        "!unrar x ./data.rar ./ >> None\n",
        "!mv ./FirstTime ./Result2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eJJjJHCyrNF"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiFFa9gDyqpS",
        "outputId": "c9c9d5b5-756a-4828-f69f-9500a6255006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.3\n",
            "1.22.4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 100\n",
        "print(pd.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vnHnF0g4Eg6",
        "outputId": "8377eb09-2ed5-4f85-de9e-81794b71862c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127, 32767, 2147483647)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.iinfo(np.int8).max, np.iinfo(np.int16).max, np.iinfo(np.int32).max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O24b3ZHi4SJi",
        "outputId": "821df428-9569-47f8-acd7-d50a33224ecf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 6, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.finfo(np.float16).precision, np.finfo(np.float32).precision, np.finfo(np.float64).precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beX-335s9PO_"
      },
      "outputs": [],
      "source": [
        "import os, psutil, time\n",
        "from glob import glob\n",
        "from neptune.utils import stringify_unsupported\n",
        "from tqdm import tqdm\n",
        "import functools\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnbaKkivEQBH"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoost\n",
        "from scipy.stats import poisson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ0rN-QRzFTA"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7qL3Au-nbm0"
      },
      "source": [
        "#####Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x60YMEVObK5Y"
      },
      "outputs": [],
      "source": [
        "def define_files_list(data_start:str, folder:str, date_end = '') -> list:\n",
        "    '''\n",
        "    data_start, data_end\n",
        "    folder: ./folder/\n",
        "    '''\n",
        "    if date_end == '':\n",
        "        return sorted(\n",
        "            [file\n",
        "            for file in glob(folder + '*')\n",
        "            if int(file.split('/')[-1].split('.csv')[0]) >= int(date_start)]\n",
        "            )\n",
        "    else:\n",
        "        return sorted(\n",
        "            [file\n",
        "            for file in glob(folder + '*')\n",
        "            if int(file.split('/')[-1].split('.csv')[0]) >= int(date_start) & \\\n",
        "                int(file.split('/')[-1].split('.csv')[0]) <= int(date_end)]\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONZygQtsdxVx"
      },
      "outputs": [],
      "source": [
        "def create_id_dict(date_start, folder, cols, date_end = '') -> dict:\n",
        "    '''\n",
        "    '''\n",
        "    return pd.concat(map(\n",
        "        functools.partial(\n",
        "            pd.read_csv, sep=';', usecols =  cols\n",
        "                            ),\n",
        "                    define_files_list(date_start, folder, date_end = date_end)\n",
        "                    ), ignore_index=True).drop_duplicates(subset = ['Id'], keep = 'last').set_index('Id').to_dict(orient = 'index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS1TEuATxNYb"
      },
      "outputs": [],
      "source": [
        "def transform_dataset(data_df:pd.DataFrame, remain = []):\n",
        "    new_match_vector = data_df['Id'] != data_df['Id'].shift(1)\n",
        "    # трансформируем минуты\n",
        "    data_df['min_norm'] = data_df['Minute'].astype(np.float32) / 50\n",
        "    print('1. Минуты посчитаны...')\n",
        "    # трансформируем голы\n",
        "    data_df[data_df['Score1'].isna() & new_match_vector] = 0\n",
        "    data_df['Score1_norm'] = data_df['Score1'].fillna(method = 'ffill').astype(np.float32) / 4\n",
        "    data_df.loc[data_df['Score1'] > 3, ['Score1_norm']] = 1.0\n",
        "    data_df[data_df['Score2'].isna() & new_match_vector] = 0\n",
        "    data_df['Score2_norm'] = data_df['Score2'].fillna(method = 'ffill').astype(np.float32) / 4\n",
        "    data_df.loc[data_df['Score2'] > 3, ['Score2_norm']] = 1.0\n",
        "\n",
        "    data_df['Score_diff'] = data_df['Score1'].astype(np.int16) - data_df['Score2'].astype(np.int16)\n",
        "    data_df.loc[data_df['Score_diff'] < -4, ['Score_diff']] = -4\n",
        "    data_df.loc[data_df['Score_diff'] > 4, ['Score_diff']] = 4\n",
        "    data_df[[f'Score_cat_{n}' for n in range(1, 10)]] = pd.get_dummies(data_df['Score_diff']).values\n",
        "    data_df['Score_diff'] = data_df['Score_diff'].astype(np.float32) / np.float32(4.0)\n",
        "    if 'Score1' not in remain:\n",
        "        data_df = data_df.drop(['Score1', 'Score2'], axis = 1)\n",
        "    print('2. Голы посчитаны...')\n",
        "    #трансформируем атаки\n",
        "    data_df['A1_scaled'] = data_df['A1'].astype(np.float32) / 75\n",
        "    data_df.loc[data_df['A1'] >= 60, ['A1_scaled']] = (60 + (data_df['A1'] - 60) / 4) / 75\n",
        "    data_df['A2_scaled'] = data_df['A2'].astype(np.float32) / 75\n",
        "    data_df.loc[data_df['A2'] >= 60, ['A2_scaled']] = (60 + (data_df['A2'] - 60) / 4) / 75\n",
        "    # атаки в минуту\n",
        "    data_df['A1perMIN'] = data_df['A1'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['A1perMIN'] > 4, ['A1perMIN']] = np.float32(4.0)\n",
        "    data_df['A2perMIN'] = data_df['A2'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['A2perMIN'] > 4, ['A2perMIN']] = np.float32(4.0)\n",
        "    # динамика атак\n",
        "    new_match_vector5 = data_df['Id'] != data_df['Id'].shift(5)\n",
        "    data_df['A1relativ'] = data_df['A1'].astype(np.float32) - data_df['A1'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['A1relativ']] = np.float32(0.0)\n",
        "    data_df['A1relativ'] = data_df['A1relativ'].fillna(0)\n",
        "    data_df.loc[data_df['A1relativ'] > 15, ['A1relativ']] = np.float32(15.)\n",
        "    data_df['A2relativ'] = data_df['A2'].astype(np.float32) - data_df['A2'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['A2relativ']] =  np.float32(0.0)\n",
        "    data_df['A2relativ'] = data_df['A2relativ'].fillna(0)\n",
        "    data_df.loc[data_df['A2relativ'] > 15, ['A2relativ']] = np.float32(15.)\n",
        "    if 'A1' not in remain:\n",
        "        data_df = data_df.drop(['A1', 'A2'], axis = 1)\n",
        "    print('3. Атаки посчитаны...')\n",
        "    # трансформируем опасные атаки\n",
        "    data_df['DA1_scaled'] = data_df['DA1'].astype(np.float32) / 50\n",
        "    data_df.loc[data_df['DA1'] >= 40, ['DA1_scaled']] = (80 + (data_df['DA1'] - 40) / 3) / 100\n",
        "    data_df['DA2_scaled'] = data_df['DA2'].astype(np.float32) / 50\n",
        "    data_df.loc[data_df['DA2'] >= 40, ['DA2_scaled']] = (80 + (data_df['DA2'] - 40) / 3) / 100\n",
        "    # опасные атаки в минуту\n",
        "    data_df['DA1perMIN'] = data_df['DA1'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['DA1perMIN'] > 3, ['DA1perMIN']] = np.float32(3.0)\n",
        "    data_df['DA2perMIN'] = data_df['DA2'].astype(np.float32) / data_df['Minute'].astype(np.float32)\n",
        "    data_df.loc[data_df['DA2perMIN'] > 3, ['DA2perMIN']] = np.float32(3.0)\n",
        "    # динамика опасных атак\n",
        "    data_df['DA1relativ'] = data_df['DA1'].astype(np.float32) - data_df['DA1'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['DA1relativ']] = np.float32(0.0)\n",
        "    data_df['DA1relativ'] = data_df['DA1relativ'].fillna(0)\n",
        "    data_df.loc[data_df['DA1relativ'] > 10, ['DA1relativ']] = np.float32(10.)\n",
        "    data_df['DA2relativ'] = data_df['DA2'].astype(np.float32) - data_df['DA2'].shift(5).astype(np.float32)\n",
        "    data_df.loc[new_match_vector5, ['DA2relativ']] = np.float32(0.0)\n",
        "    data_df['DA2relativ'] = data_df['DA2relativ'].fillna(0)\n",
        "    data_df.loc[data_df['DA2relativ'] > 10, ['DA2relativ']] = np.float32(10.)\n",
        "    if 'DA1' not in remain:\n",
        "        data_df = data_df.drop(['DA1', 'DA2'], axis = 1)\n",
        "    if 'Minute' not in remain:\n",
        "        data_df = data_df.drop(['Minute'], axis = 1)\n",
        "    print('4. Опасные атаки посчитаны...')\n",
        "    # трансформируем владение мячом\n",
        "    data_df[data_df['Pos1'].isna() & new_match_vector] = 0\n",
        "    data_df['Pos1_cleaned'] = data_df['Pos1'].fillna(method = 'ffill').astype(np.float32) /  np.float32(100.0)\n",
        "    data_df.loc[data_df['Pos1_cleaned'] < 0.2, ['Pos1_cleaned']] = np.float32(0.2)\n",
        "    data_df.loc[data_df['Pos1_cleaned'] > 0.8, ['Pos1_cleaned']] = np.float32(0.8)\n",
        "    data_df[data_df['Pos2'].isna() & new_match_vector] = 0\n",
        "    data_df['Pos2_cleaned'] = data_df['Pos2'].fillna(method = 'ffill').astype(np.float32) /  np.float32(100.0)\n",
        "    data_df.loc[data_df['Pos2_cleaned'] < 0.2, ['Pos2_cleaned']] = np.float32(0.2)\n",
        "    data_df.loc[data_df['Pos2_cleaned'] > 0.8, ['Pos2_cleaned']] = np.float32(0.8)\n",
        "    if 'Pos1' not in remain:\n",
        "        data_df = data_df.drop(['Pos1', 'Pos2'], axis = 1)\n",
        "    print('5. Владение мячом посчитпно...')\n",
        "    # трансформируем удары\n",
        "    data_df[data_df['Off1'].isna() & new_match_vector] = 0\n",
        "    data_df['Off1_norm'] = data_df['Off1'].fillna(method = 'ffill').astype(np.float32) / np.float32(10.0)\n",
        "    data_df.loc[data_df['Off1_norm'] > 1.0, ['Off1_norm']] = np.float32(1.0)\n",
        "    data_df[data_df['Off2'].isna() & new_match_vector] = 0\n",
        "    data_df['Off2_norm'] = data_df['Off2'].fillna(method = 'ffill').astype(np.float32) / np.float32(10.0)\n",
        "    data_df.loc[data_df['Off2_norm'] > 1.0, ['Off2_norm']] = np.float32(1.0)\n",
        "    if 'Off1' not in remain:\n",
        "        data_df = data_df.drop(['Off1', 'Off2'], axis = 1)\n",
        "    print('6. Удары посчитаны...')\n",
        "    # трансформируем удары в створ\n",
        "    data_df[data_df['On1'].isna() & new_match_vector] = 0\n",
        "    data_df['On1_norm'] = data_df['On1'].fillna(method = 'ffill').astype(np.float32) / np.float32(5.0)\n",
        "    data_df.loc[data_df['On1_norm'] > 1.0, ['On1_norm']] = np.float32(1.0)\n",
        "    data_df[data_df['On2'].isna() & new_match_vector] = 0\n",
        "    data_df['On2_norm'] = data_df['On2'].fillna(method = 'ffill').astype(np.float32) / np.float32(5.0)\n",
        "    data_df.loc[data_df['On2_norm'] > 1.0, ['On2_norm']] = np.float32(1.0)\n",
        "    if 'On1' not in remain:\n",
        "        data_df = data_df.drop(['On1', 'On2'], axis = 1)\n",
        "    print('7. Удары в створ посчитаны...')\n",
        "    # трансформируем желтые карточки\n",
        "    data_df[data_df['YC1'].isna() & new_match_vector] = 0\n",
        "    data_df['YC1_transformed'] = data_df['YC1'].fillna(0).astype(np.float32) / np.float32(2.0)\n",
        "    data_df.loc[data_df['YC1_transformed'] > 1.0, ['YC1_transformed']] = np.float32(1.0)\n",
        "    data_df[data_df['YC2'].isna() & new_match_vector] = 0\n",
        "    data_df['YC2_transformed'] = data_df['YC2'].fillna(0).astype(np.float32) / np.float32(2.0)\n",
        "    data_df.loc[data_df['YC2_transformed'] > 1.0, ['YC2_transformed']] = np.float32(1.0)\n",
        "    if 'YC1' not in remain:\n",
        "        data_df = data_df.drop(['YC1', 'YC2'], axis = 1)\n",
        "    print('8. Жёлтые карточки посчитаны...')\n",
        "    # трансформируем красные карточки\n",
        "    data_df[data_df['RC1'].isna() & new_match_vector] = 0\n",
        "    data_df['RC1_transformed'] = data_df['RC1'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['RC1_transformed'] > 1, ['RC1_transformed']] = np.int8(1)\n",
        "    data_df[data_df['RC2'].isna() & new_match_vector] = 0\n",
        "    data_df['RC2_transformed'] = data_df['RC2'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['RC2_transformed'] > 1, ['RC2_transformed']] = np.int8(1)\n",
        "    if 'RC1' not in remain:\n",
        "        data_df = data_df.drop(['RC1', 'RC2'], axis = 1)\n",
        "    print('9. Красные карточки посчитаны...')\n",
        "    # трансформируем замены\n",
        "    data_df[data_df['Sub1'].isna() & new_match_vector] = 0\n",
        "    data_df['Sub1_transformed'] = data_df['Sub1'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['Sub1_transformed'] > 1, ['Sub1_transformed']] = np.int8(1)\n",
        "    data_df[data_df['Sub2'].isna() & new_match_vector] = 0\n",
        "    data_df['Sub2_transformed'] = data_df['Sub2'].fillna(0).astype(np.int8)\n",
        "    data_df.loc[data_df['Sub2_transformed'] > 1, ['Sub2_transformed']] = np.int8(1)\n",
        "    if 'Sub1' not in remain:\n",
        "        data_df = data_df.drop(['Sub1', 'Sub2'], axis = 1)\n",
        "    print('10. Замены посчитаны...')\n",
        "    # трансформируем угловык\n",
        "    data_df[data_df['Cor1'].isna() & new_match_vector] = 0\n",
        "    data_df['Cor1_transformed'] = data_df['Cor1'].fillna(0).astype(np.float32) / np.float32(6.0)\n",
        "    data_df.loc[data_df['Cor1_transformed'] > 1.0, ['Cor1_transformed']] = np.float32(1.0)\n",
        "    data_df[data_df['Cor2'].isna() & new_match_vector] = 0\n",
        "    data_df['Cor2_transformed'] = data_df['Cor2'].fillna(0).astype(np.float32) / np.float32(6.0)\n",
        "    data_df.loc[data_df['Cor2_transformed'] > 1.0, ['Cor2_transformed']] = np.float32(1.0)\n",
        "    if 'Cor1' not in remain:\n",
        "        data_df = data_df.drop(['Cor1', 'Cor2'], axis = 1)\n",
        "    print('11. Угловые посчитаны...')\n",
        "    # трансформируем линию\n",
        "    data_df['P1_transformed'] = np.log(data_df['P1'], dtype = np.float32) / 2\n",
        "    data_df['P2_transformed'] = np.log(data_df['P2'], dtype = np.float32) / 2\n",
        "    if 'P1' not in remain:\n",
        "        data_df = data_df.drop(['P1', 'P2'], axis = 1)\n",
        "    print('12. Линии посчитаны...')\n",
        "    if 'Pen1' not in remain:\n",
        "        data_df = data_df.drop(['Pen1', 'Pen2'], axis = 1)\n",
        "    if 'Active' not in remain:\n",
        "        data_df = data_df.drop(['Active'], axis = 1)\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgahlHprQDfJ"
      },
      "source": [
        "#### Predefine data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6YA-et4Ly8V"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "data_types_dict = {\n",
        "    'Id':np.int32,\n",
        "    'StatTime':str,\n",
        "    'Minute':np.int8,\n",
        "    'Active': np.int8, 'Score1':np.int8, 'Score2':np.int8,\n",
        "    'A1':np.int16, 'A2':np.int16, 'DA1':np.int16, 'DA2':np.int16, 'Pos1':np.float32, 'Pos2':np.float32,\n",
        "    'Off1':np.int8, 'Off2':np.int8, 'On1':np.int8, 'On2':np.int8, 'YC1':np.int8, 'YC2':np.int8,\n",
        "    'RC1':np.int8, 'RC2':np.int8, 'Sub1':np.int8, 'Sub2':np.int8, 'Pen1':np.int8, 'Pen2':np.int8,\n",
        "    'Cor1':np.int8, 'Cor2':np.int8, 'Period':np.int8,\n",
        "    'D':np.datetime64,\n",
        "    'I':np.int32, 'Active.1':np.int8,\n",
        "    'Time':np.datetime64,\n",
        "    'Minute.1':np.int8,\n",
        "    'RawTime':np.datetime64,\n",
        "    'Score1.1':np.int8, 'Score2.1':np.int8, 'Period.1':np.int8,\n",
        "    'W1':np.float16, 'WX':np.float16, 'W2':np.float16, 'X1':np.float16, 'X2':np.float16, 'W12':np.float16, 'TotalValue':np.float16,\n",
        "    'Over':np.float16, 'Under':np.float16, 'Hand1Value':np.float16, 'H1':np.float16, 'H2':np.float16\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDW1K2PKlibT"
      },
      "outputs": [],
      "source": [
        "k_cols = [\n",
        "    'W1', 'WX', 'W2', 'X1', 'X2', 'W12', 'TotalValue' ,'Over',\n",
        "    'Under', 'Hand1Value', 'H1', 'H2'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILPSgppbNr15"
      },
      "outputs": [],
      "source": [
        "drop_cols = [\n",
        "    #'StatTime',\n",
        "    'Comment', 'D', 'I', 'Time', 'Minute.1', 'RawTime',\n",
        "    'Score1.1', 'Score2.1', 'Period.1', 'Period', 'Periods', 'Serve'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtV7BR6vuXkz"
      },
      "source": [
        "#### Load Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FuUB09qV320"
      },
      "outputs": [],
      "source": [
        "info_cols = ['Id', 'Result1', 'Result2']\n",
        "prem_cols = ['Id', 'P1', 'PX', 'P2']\n",
        "res_cols = [cols for cols in data_types_dict if cols not in drop_cols]\n",
        "\n",
        "info_folder = './Index/'\n",
        "prem_folder = './Prem/'\n",
        "data_folder = './Result2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vpJF3BPewgM"
      },
      "outputs": [],
      "source": [
        "### собрать датасет с даты:\n",
        "year_start = '2023'\n",
        "month_start = '01'\n",
        "day_start = '01'\n",
        "### до даты\n",
        "year_end = ''\n",
        "month_end = ''\n",
        "day_end = ''\n",
        "date_start = year_start + month_start + day_start\n",
        "date_end = year_end + month_end + day_end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDRXrXwouhLQ"
      },
      "source": [
        "#### Create DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX_nGW_ydHDb"
      },
      "outputs": [],
      "source": [
        "info_dict = create_id_dict(date_start, info_folder, info_cols)\n",
        "prem_dict = create_id_dict(date_start, prem_folder, prem_cols)\n",
        "if len(prem_dict) != len(info_dict):\n",
        "    print('Нет в info: ', set(prem_dict) - set(info_dict))\n",
        "    print('Нет в prem: ', set(info_dict) - set(prem_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K69OEGIAeeD0"
      },
      "outputs": [],
      "source": [
        "#files_list =['./Result2/' + str(id) + '.csv'\n",
        "#    for id in set(info_dict)\n",
        "#    if os.path.exists('./Result2/' + str(id) + '.csv')]\n",
        "\n",
        "files_list = []\n",
        "for folder in glob('./Result2/*'):\n",
        "    files_list += glob(folder + '/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REHpPLoiWQFU"
      },
      "outputs": [],
      "source": [
        "time_point1 = time.time()\n",
        "data_df = pd.concat(map(functools.partial(\n",
        "    pd.read_csv,\n",
        "    sep = ';',\n",
        "    #parse_dates = ['StatTime'],\n",
        "    usecols = res_cols\n",
        "                                    ), files_list), ignore_index=True)\n",
        "time_point2 = time.time()\n",
        "print(f'create dataframe: {time_point2 - time_point1} sec.')\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print(round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes\n",
        "#---------------\n",
        "\n",
        "data_df[k_cols] = data_df[k_cols].fillna(0).values # Заполняем пропущенные лайв кэфы 1\n",
        "new_match_vector = data_df['Id'] != data_df['Id'].shift(1) # Отмечаем переходы между матчами в колонуах\n",
        "data_cols = list(set(res_cols) - set(k_cols)) # Отбирвем колонки для заполнения пропусков метдом ffill\n",
        "for col in data_cols:\n",
        "    data_df.loc[data_df[col].isna() & new_match_vector, col] = 0 # Сами переходы с пропусками заполняем 0\n",
        "data_df = data_df.fillna(method = 'ffill')\n",
        "################ Записываем файл с временными метками и сбрасываем время матчей\n",
        "#(data_df['Id'].astype(str) + ':' + data_df['StatTime'].astype(str).str.split(\n",
        "#        ' ', expand=True)[0]\n",
        "#        ).drop_duplicates().str.split(':', expand = True).rename(\n",
        "#                                                columns = {0:'Id', 1:'StatTime'}\n",
        "#                                                            ).to_csv('./time.csv', index = False)\n",
        "#data_df = data_df.drop(['StatTime'], axis = 1)\n",
        "############################################### Присоединяем результаты и кэфы\n",
        "data_df[['Result1', 'Result2']] = [\n",
        "    [info_dict[id]['Result1'], info_dict[id]['Result2']]\n",
        "    for id in tqdm(data_df['Id'].values, total = len(data_df))\n",
        "    ]\n",
        "data_df[['P1', 'PX', 'P2']] = [\n",
        "    [prem_dict[id]['P1'], prem_dict[id]['PX'], prem_dict[id]['P2']]\n",
        "    for id in tqdm(data_df['Id'].values, total = len(data_df))\n",
        "    ]\n",
        "\n",
        "print('\\n')\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print(round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes\n",
        "#---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cot34SU4xfao"
      },
      "outputs": [],
      "source": [
        "data_df.loc[new_match_vector & (data_df['P1'].isna()), ['P1']] = data_df['W1'][new_match_vector & (data_df['P1'].isna())]\n",
        "data_df.loc[new_match_vector & (data_df['P2'].isna()), ['P2']] = data_df['W2'][new_match_vector & (data_df['P2'].isna())]\n",
        "data_df.loc[new_match_vector & (data_df['PX'].isna()), ['PX']] = data_df['WX'][new_match_vector & (data_df['PX'].isna())]\n",
        "data_df['P1'] = data_df['P1'].fillna(method = 'ffill').values\n",
        "data_df['PX'] = data_df['PX'].fillna(method = 'ffill').values\n",
        "data_df['P2'] = data_df['P2'].fillna(method = 'ffill').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiVw40Y5TzkT"
      },
      "outputs": [],
      "source": [
        "data_df = transform_dataset(data_df, #)\n",
        "    remain = ['StatTime', 'Minute', 'Score1', 'Score2', 'Result1', 'Result2', 'P1', 'PX', 'P2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETHSuNqmhmp9",
        "outputId": "1e2d2503-56d9-46a7-8558-d69da8659e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1 -inf & P2 -inf:  1487 1487\n"
          ]
        }
      ],
      "source": [
        "# Из-за того что некоторые кэфы были пропущены, и заменены на нули в препроцессинге на их месте появились inf, удаляем\n",
        "print('P1 -inf & P2 -inf: ', (data_df['P1_transformed'] == -np.inf).sum(), (data_df['P2_transformed'] == -np.inf).sum())\n",
        "\n",
        "#data_df = data_df[~(data_df['P1_transformed'] == -np.inf)]\n",
        "#data_df = data_df[~(data_df['P2_transformed'] == -np.inf)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iu5-teMiFp-",
        "outputId": "6f4bd4e3-f055-462a-e637-a5549d993f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score-Result error 1&2:  23 23\n",
            "mem usage:  2.17 GiB\n"
          ]
        }
      ],
      "source": [
        "#Там где забито болше внутри матча чем в итоге, пока не удаляем\n",
        "print('Score-Result error 1&2: ', (~(data_df['Result1'] - data_df['Score1']) >= 0).sum(), (~(data_df['Result1'] - data_df['Score1']) >= 0).sum())\n",
        "#data_df = data_df.loc[(data_df['Result1'] - data_df['Score1']) >= 0]\n",
        "#data_df = data_df.loc[(data_df['Result2'] - data_df['Score2']) >= 0]\n",
        "\n",
        "\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print('mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes\n",
        "#---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2ydGl_Q0MDd",
        "outputId": "28895c57-9960-4f57-fc60-6d799da85a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sort by date: -22.114991664886475 sec.\n",
            "mem usage:  2.16 GiB\n"
          ]
        }
      ],
      "source": [
        "time_point1 = time.time()\n",
        "data_df['StatTime'] = pd.to_datetime(data_df['StatTime'], dayfirst=True)\n",
        "data_df = data_df.sort_values(by = ['StatTime'])\n",
        "print(f'sort by date: {time_point2 - time_point1} sec.')\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print('mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes\n",
        "#---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4_P788pjWQ7"
      },
      "outputs": [],
      "source": [
        "data_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30BjEESQjbhD"
      },
      "outputs": [],
      "source": [
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8idgb032Zoxs"
      },
      "outputs": [],
      "source": [
        "selected_cols = [item for item in data_df.columns[23:] if item not in remove_list]\n",
        "#selected_cols = [item for item in data_df.columns[23:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6bw6_wiZt-W"
      },
      "outputs": [],
      "source": [
        "X = data_df[selected_cols].values\n",
        "y_regression1 = ((data_df['Result1'] - data_df['Score1']) / 21).values\n",
        "y_regression2 = ((data_df['Result2'] - data_df['Score2']) / 21).values\n",
        "line = data_df[['Hand1Value', 'Over', 'Under']].values\n",
        "active_rows = np.ones(line.shape[0], dtype = bool)\n",
        "#active = data_df['Active.1'].values == 1\n",
        "#active_rows = (active & (line.sum(axis = 1) > 3))\n",
        "scores1 = data_df['Score1'].values\n",
        "scores2 = data_df['Score2'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE66BJ4-HO6j"
      },
      "source": [
        "#### Download models and restore predicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K24dN9EBlMY1"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orSb3NCyHO6n",
        "outputId": "455160d2-8145-42cc-e17b-d5ac95922925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/m/FOOT-LIVEBST1/v/FOOT-LIVEBST1-6\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/m/FOOT-LIVEBST1/v/FOOT-LIVEBST1-6/metadata\n"
          ]
        }
      ],
      "source": [
        "# Модель для 1-ой команды\n",
        "model_num = selected_model1_version # Указываем номер модели\n",
        "neptune_model = 'FOOT-LIVEBST1'\n",
        "neptune_model_version = neptune_model + f'-{model_num}'\n",
        "model_version_params = dict(\n",
        "    project = 'scomesse/football',\n",
        "    model = neptune_model,\n",
        "    api_token = api_key,\n",
        "    with_id = neptune_model_version\n",
        ")\n",
        "if folded:\n",
        "    model_version = neptune.init_model_version(**model_version_params)\n",
        "    description_dict = model_version[f'model_reg1_description'].fetch()\n",
        "    for kfold_num in range(description_dict['kfold_splits']):\n",
        "        model_version[f'/models/model_reg1_{kfold_num}'].download(f'./models/booster_reg1_{kfold_num}.model')\n",
        "    model_version.stop()\n",
        "else:\n",
        "    PATH_TO_MODEL = './booster.model'\n",
        "    model_version = neptune.init_model_version(**model_version_params)\n",
        "    model_version['model'].download(PATH_TO_MODEL)\n",
        "    params1 = model_version['team_parameters'].fetch()\n",
        "    model_version.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WZxvvgZHO6o",
        "outputId": "1e27245c-04e2-4c11-d8c5-0ff067aff2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/m/FOOT-LIVEBST2/v/FOOT-LIVEBST2-5\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/m/FOOT-LIVEBST2/v/FOOT-LIVEBST2-5/metadata\n"
          ]
        }
      ],
      "source": [
        "model_num_2 = selected_model2_version # Указываем номер модели\n",
        "neptune_model_2 = 'FOOT-LIVEBST2'\n",
        "neptune_model_version_2 = neptune_model_2 + f'-{model_num_2}'\n",
        "model_version_params2 = dict(\n",
        "    project = 'scomesse/football',\n",
        "    model = neptune_model_2,\n",
        "    api_token = api_key,\n",
        "    with_id = neptune_model_version_2\n",
        ")\n",
        "if folded:\n",
        "    model_version2 = neptune.init_model_version(**model_version_params2)\n",
        "    description_dict2 = model_version2[f'model_reg2_description'].fetch()\n",
        "    for kfold_num in range(description_dict2['kfold_splits']):\n",
        "        model_version2[f'/models/model_reg2_{kfold_num}'].download(f'./models/booster_reg2_{kfold_num}.model')\n",
        "    model_version2.stop()\n",
        "else:\n",
        "    PATH_TO_MODEL = './booster2.model'\n",
        "    model_version2 = neptune.init_model_version(**model_version_params2)\n",
        "    model_version2['model'].download(PATH_TO_MODEL)\n",
        "    params2 = model_version2['team_parameters'].fetch()\n",
        "    model_version2.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if folded:\n",
        "    preds_dict = {}\n",
        "    preds_dict = {1:sum(\n",
        "        CatBoost().load_model(\n",
        "            f'./models/booster_reg1_{kfold_num}.model'\n",
        "                            ).predict(X) * 21.0\n",
        "        for kfold_num in range(description_dict['kfold_splits'])\n",
        "                            ) / description_dict['kfold_splits']}\n",
        "\n",
        "    preds_dict.update({2:sum(\n",
        "        CatBoost().load_model(\n",
        "            f'./models/booster_reg2_{kfold_num}.model'\n",
        "                            ).predict(X) * 21.0\n",
        "        for kfold_num in range(description_dict['kfold_splits'])\n",
        "                            ) / description_dict['kfold_splits']})\n",
        "else:\n",
        "    preds_dict = {}\n",
        "    booster = CatBoost()\n",
        "    booster.load_model('./booster.model')\n",
        "    preds_dict = {1:booster.predict(X) * 21.0}\n",
        "\n",
        "    booster2 = CatBoost()\n",
        "    booster2.load_model('./booster2.model')\n",
        "    preds_dict.update({2:booster2.predict(X) * 21.0})\n",
        "\n",
        "#---------------\n",
        "process = psutil.Process(os.getpid())\n",
        "print('Mem usage: ', round(process.memory_info().rss / 1024 ** 3, 2), 'GiB')  # in bytes\n",
        "#---------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khpu1gpsoISA",
        "outputId": "52c51354-c2c1-4db6-f5d1-c854ec3a74f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem usage:  2.52 GiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUoqIhQIy5S_"
      },
      "source": [
        "#### Calculate probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBa_Nc_EyG_V"
      },
      "outputs": [],
      "source": [
        "# Считаем Пуассона\n",
        "poisson_dict = {}\n",
        "poisson_dict[1] = {}\n",
        "poisson_dict[2] = {}\n",
        "for goal in range(7):\n",
        "    poisson_dict[1][goal] = poisson.pmf(goal, preds_dict[1][active_rows])\n",
        "    poisson_dict[2][goal] = poisson.pmf(goal, preds_dict[2][active_rows])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQoN4RNOU4Uz"
      },
      "outputs": [],
      "source": [
        "# Считаем вероятности разности забитых мячей\n",
        "total_matrix = np.zeros((np.sum(active_rows), 13))\n",
        "for goal1 in range(7):\n",
        "    for goal2 in range(7):\n",
        "        total_matrix[:, goal1 - goal2 + 6] = total_matrix[:, goal1 - goal2 + 6] + \\\n",
        "        poisson_dict[1][goal1] * poisson_dict[2][goal2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g9YB2uWVSt4"
      },
      "outputs": [],
      "source": [
        "# Считаем вероятности победы дома over = home_win\n",
        "over_matrix = np.hstack((\n",
        "    np.zeros(np.sum(active_rows)).reshape(-1,1),\n",
        "    np.cumsum(np.flip(total_matrix, axis = 1), axis = 1)\n",
        "                                ))#[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrKmrBLHRTG9"
      },
      "outputs": [],
      "source": [
        "# Считаем вероятности победы гостей under = away_win\n",
        "under_matrix = np.hstack((\n",
        "        np.flip(np.cumsum(total_matrix, axis = 1), axis = 1),\n",
        "        np.zeros(np.sum(active_rows)).reshape(-1,1)\n",
        "                                            ))#[:, :-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b-MqvnlyhIQ"
      },
      "outputs": [],
      "source": [
        "# Считаем текущей стэйт суммы забитых мячей\n",
        "total_state = line[:,0][active_rows] + scores1[active_rows] - scores2[active_rows] + 6\n",
        "total_state[total_state < 0] = 0\n",
        "total_state[total_state > 12] = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb-J38hJYoKA"
      },
      "outputs": [],
      "source": [
        "prob = np.hstack((\n",
        "    np.take_along_axis(over_matrix, (total_state.reshape(-1, 1) + 0.5).reshape(-1, 1).astype(np.int8), axis = 1),\n",
        "    np.take_along_axis(under_matrix, (total_state.reshape(-1, 1) + 1).astype(np.int8), axis = 1),\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgdUFeBSjddY"
      },
      "source": [
        "#### Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhVNo-GlH6-L"
      },
      "outputs": [],
      "source": [
        "data_df[['H_prob', 'A_prob']] = prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPl26UIV33z5"
      },
      "outputs": [],
      "source": [
        "data_df[['H_prob_adj', 'A_prob_adj']] = prob / np.sum(prob, axis = 1).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge4RO5l5V13r"
      },
      "outputs": [],
      "source": [
        "report_cols = ['Id', 'StatTime', 'Minute', 'Active.1', 'Score1', 'Score2',\n",
        "               'Result1', 'Result2', 'Hand1Value', 'H1', 'H2',\n",
        "               'H_prob', 'A_prob', 'H_prob_adj', 'A_prob_adj']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9pP6vg5TpQI"
      },
      "outputs": [],
      "source": [
        "data_df[report_cols].tail(100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[data_df['Id'] == 5981098]"
      ],
      "metadata": {
        "id": "V9GOR575Aal7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[(data_df['StatTime'] > '2023-05-15 23:59:59') &\\\n",
        "                     (data_df['StatTime'] < '2023-05-16 12:00:59')].to_csv('./result_report_handicap.csv', index = None)"
      ],
      "metadata": {
        "id": "XtNhKK0lPZ0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NOYCSe84xmS"
      },
      "source": [
        "#### Upload to Yandex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1E3GBaQjbcI"
      },
      "outputs": [],
      "source": [
        "data_df[report_cols].to_csv('./handicap_probabilities.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhHMh1kTUeE8"
      },
      "outputs": [],
      "source": [
        "#data_df.to_csv('./handicap_dataframe.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8azstRLYjb7j",
        "outputId": "8f45be03-782f-49f4-9033-8fdbc2512ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token exists:  True\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import yadisk\n",
        "except:\n",
        "    !pip install yadisk >> None\n",
        "    import yadisk\n",
        "def get_credential2(frmwork = 'yandex token'):\n",
        "    with open('cred.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw\n",
        "_, api_key2 = get_credential2()\n",
        "y = yadisk.YaDisk(token = api_key2)\n",
        "print('Token exists: ', y.check_token())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsd5DWNXUMQL"
      },
      "outputs": [],
      "source": [
        "date_upload = 20230604"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF-tWAZejpwW"
      },
      "outputs": [],
      "source": [
        "#print(y.mkdir(f'disk:/sport_prediction/calcio_2021/uploads/{date_upload}'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGBwqaIkjq_N"
      },
      "outputs": [],
      "source": [
        "with open('/content/handicap_probabilities.csv', 'rb') as f:\n",
        "    y.upload(f, f'disk:/sport_prediction/calcio_2021/uploads/{date_upload}/handicap_cv_probabilities_wo_folds.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY1XN3NvBtt6"
      },
      "source": [
        "### visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5feh_x-FJBR"
      },
      "source": [
        "#### assign data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew2b0TtyPkuN",
        "outputId": "670fd85f-fe4c-46aa-8d89-85c54bb3dd77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1602948, (1827026,))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "np.sum((data_df['H1'] > 1) & (data_df['H2'] > 1) & (data_df['Active.1'] > 0)), data_df['Active.1'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCi6JBmCPhZ-"
      },
      "outputs": [],
      "source": [
        "results_dict = {'validation':{\n",
        "    'result1':data_df['Result1'].values,\n",
        "    'result2':data_df['Result2'].values\n",
        "    }}\n",
        "line_dict = {'validation':data_df[['Hand1Value', 'H1', 'H2']].values}\n",
        "active_rows_dict = {'validation':\\\n",
        "                    (data_df['H1'] > 1) & \\\n",
        "                    (data_df['H2'] > 1) & \\\n",
        "                    (data_df['Active.1'] > 0)\n",
        "                    }\n",
        "prob_dict = {'validation':prob}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNKb9PYxEgsP"
      },
      "source": [
        "#### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg9S4hnlEku7"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0pA-BRAErQ7"
      },
      "source": [
        "#### functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgryntGzkaGE"
      },
      "outputs": [],
      "source": [
        "def calculate_multiclass(probability_2x:np.array, line_2x:np.array):\n",
        "    '''\n",
        "    input : 0 - over, 1 - under\n",
        "    output: 0 - over, 1 - under\n",
        "    '''\n",
        "    probability_adj = probability_2x / np.sum(probability_2x, axis = 1).reshape(-1, 1)\n",
        "    probline_adj = probability_adj * line_2x\n",
        "    probline = probability_2x * line_2x\n",
        "    best_odd_result = np.argmax(probline_adj, axis = 1)\n",
        "    best_odd_float_adj = np.take_along_axis(probline_adj, best_odd_result.reshape(-1, 1), axis = 1)\n",
        "    best_odd_float = np.take_along_axis(probline, best_odd_result.reshape(-1, 1), axis = 1)\n",
        "    return {\n",
        "        'argmax':best_odd_result,\n",
        "        'float':best_odd_float,\n",
        "        'float_adj':best_odd_float_adj\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z7-LttxkkBs"
      },
      "outputs": [],
      "source": [
        "def make_filter(hda, preds_int):\n",
        "    hda_dict = {'home':0, 'away':1}\n",
        "    if hda == 'all':\n",
        "        return preds_int > -1\n",
        "    else:\n",
        "        return preds_int == hda_dict[hda]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ga_equity_separate(\n",
        "    sel_best_dict = {'home':1.1555, 'away':1.1555}, #\n",
        "    prob_dict = prob_dict,\n",
        "    line_dict = line_dict,\n",
        "    results_dict = results_dict,\n",
        "    active_rows_dict = active_rows_dict,\n",
        "    x_date = np.empty(()),\n",
        "    neptune_model_version = neptune_model_version,\n",
        "    data_split = 'validation'\n",
        "    ):\n",
        "    hda_dict = {'all':{'ltype':'solid', 'colors':'rgb(93, 164, 214)', 'line_width':3},\n",
        "                'home':{'ltype':'dot', 'colors':'rgb(255, 144, 14)', 'line_width':1},\n",
        "                'away':{'ltype':'dot', 'colors':'rgb(44, 160, 101)', 'line_width':1}}\n",
        "    layout_dict = {}\n",
        "    data_list = []\n",
        "    preds_int, preds_float, preds_float_adj = calculate_multiclass(\n",
        "        prob_dict[data_split],\n",
        "        line_dict[data_split][:,1:3]).values()\n",
        "    preds_float_adj = preds_float_adj[:,0]\n",
        "    preds_vec = preds_int * (2) - 1\n",
        "    final_goal_diff = (results_dict[data_split]['result1'] - \\\n",
        "                      results_dict[data_split]['result2'])\n",
        "    res_vec = ((final_goal_diff + line_dict[data_split][:,0]) > 0) * (-1) + \\\n",
        "             ((final_goal_diff + line_dict[data_split][:,0]) < 0) * (1)\n",
        "    win_vec, lose_vec = (preds_vec * res_vec) == 1, (preds_vec * res_vec) == -1\n",
        "    line_vec = np.take_along_axis(\n",
        "                        line_dict[data_split][:,1:3],\n",
        "                        preds_int.reshape(-1, 1),\n",
        "                        axis = 1\n",
        "                                )[:, 0]\n",
        "    placed_bets = (\n",
        "        (preds_float_adj >= sel_best_dict['home']) | \\\n",
        "        (preds_float_adj >= sel_best_dict['away'])\n",
        "                    ) & \\\n",
        "        active_rows_dict[data_split]\n",
        "    ################\n",
        "    line_vec = line_vec[placed_bets]\n",
        "    win_vec = win_vec[placed_bets]\n",
        "    lose_vec = lose_vec[placed_bets]\n",
        "    preds_int = preds_int[placed_bets]\n",
        "    x_date = pd.to_datetime(x_date).dt.date.values[placed_bets]\n",
        "    ################\n",
        "    y = ((line_vec - 1) / line_vec) * (win_vec).astype(np.float32) - \\\n",
        "        (1/line_vec) * (lose_vec).astype(np.float32)\n",
        "    side_dict = {'home':0, 'away':1}\n",
        "    for hda, value_dict in hda_dict.items():\n",
        "        if hda != 'all':\n",
        "            data_list += [\n",
        "                go.Scatter(\n",
        "                    y = np.cumsum(y * (preds_int == side_dict[hda])),\n",
        "                    x = x_date,\n",
        "                    name = hda,\n",
        "                    line = dict(color = value_dict['colors'], width = value_dict['line_width'], dash = value_dict['ltype'])\n",
        "                            )]\n",
        "        else:\n",
        "            data_list += [\n",
        "                go.Scatter(\n",
        "                    y = np.cumsum(y),\n",
        "                    x = x_date,\n",
        "                    name = 'all',\n",
        "                    line = dict(color = hda_dict['all']['colors'], width = hda_dict['all']['line_width'], dash = hda_dict['all']['ltype'])\n",
        "                            )]\n",
        "    title_text = f'<b>Handicap (cv)</b> equity curve {data_split}<br>Model in neptune.ai: FOOT-{neptune_model_version}<br>' + \\\n",
        "        f\"ROI: {np.round(np.cumsum(y)[-1] * 100 / np.sum(1/line_vec, dtype = np.float32), 4)}%\" + \\\n",
        "        f' | Bet quantity: {np.sum(placed_bets)}<br>'\n",
        "    dt_min = min(x_date)\n",
        "    dt_max = max(x_date)\n",
        "    layout_dict.update({\n",
        "    'width':1200,\n",
        "    'height':800,\n",
        "    #'title_x':0.5,\n",
        "    'title_text':title_text,\n",
        "    'paper_bgcolor':'rgb(229, 237, 247)',\n",
        "    'plot_bgcolor':'rgb(229, 237, 247)',\n",
        "    'xaxis':{'range':[dt_min, dt_max]}\n",
        "                    })\n",
        "    layout = go.Layout(**layout_dict)\n",
        "    return go.Figure(data=data_list, layout=layout)"
      ],
      "metadata": {
        "id": "XI059dp9-r9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrZClCyeEwJ8"
      },
      "source": [
        "### visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcvOKw_-Un6D"
      },
      "outputs": [],
      "source": [
        "fig = plot_ga_equity_separate(x_date = data_df['StatTime'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Betting Strategies"
      ],
      "metadata": {
        "id": "sLiuMzz6s1rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Functions"
      ],
      "metadata": {
        "id": "eSpGdYWkJNTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bet_open(match_id_dict:dict, match_minute:int, strategy = '5minute', nbets = 3, last_type = None, current_prob = None, prob_thres = 1.05):\n",
        "    '''\n",
        "    '''\n",
        "    if strategy == '5minute':\n",
        "        if 'last_bet_minute' in match_id_dict:\n",
        "            if (match_minute - match_id_dict['last_bet_minute']) > 4:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            return True\n",
        "    elif strategy == 'nbets':\n",
        "        if 'nbets' in match_id_dict:\n",
        "            if match_id_dict['nbets'] >= nbets:\n",
        "                return False\n",
        "            else:\n",
        "                return True\n",
        "        else:\n",
        "            return True\n",
        "    elif strategy == 'changes':\n",
        "        if 'last_type' in match_id_dict:\n",
        "            if match_id_dict['last_type'] != last_type:\n",
        "                return True\n",
        "            elif (current_prob / match_id_dict['last_prob']) > prob_thres:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            return True"
      ],
      "metadata": {
        "id": "IXkuBQ-DAk5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_strategy(\n",
        "    prob_dict,\n",
        "    line_dict,\n",
        "    results_dict,\n",
        "    active_rows_dict,\n",
        "    data_df,\n",
        "    strategy_type = 'nbets', #'nbets' #'5minute'\n",
        "    neptune_model_version = neptune_model_version,\n",
        "    data_split = 'validation',\n",
        "    sel_best_dict = {'home':1.1555, 'away':1.1555}\n",
        "):\n",
        "\n",
        "    type2int = {0:'home', 1:'away'}\n",
        "    hda_dict = {'all':{'ltype':'solid', 'colors':'rgb(93, 164, 214)', 'line_width':3, 'order':2},\n",
        "                'home':{'ltype':'dot', 'colors':'rgb(255, 144, 14)', 'line_width':1, 'order':0},\n",
        "                'away':{'ltype':'dot', 'colors':'rgb(44, 160, 101)', 'line_width':1, 'order':1}}\n",
        "\n",
        "    match_live_dict = {}\n",
        "    output_list = []\n",
        "    date_list = []\n",
        "    bet_size_list = []\n",
        "    preds_int, preds_float, preds_float_adj = calculate_multiclass(\n",
        "                                        prob_dict[data_split],\n",
        "                                        line_dict[data_split][:,1:3]\n",
        "                                    ).values()\n",
        "    for pred_win, pred_prob, line, results1, results2, match_id, \\\n",
        "                    match_time, match_minute, active in tqdm(zip(\n",
        "            preds_int,\n",
        "            preds_float_adj,\n",
        "            line_dict[data_split],\n",
        "            results_dict[data_split]['result1'],\n",
        "            results_dict[data_split]['result2'],\n",
        "            data_df['Id'].values,\n",
        "            data_df['StatTime'],\n",
        "            data_df['Minute'].values,\n",
        "            active_rows_dict[data_split]\n",
        "                                ), total = active_rows_dict[data_split].shape[0]):\n",
        "\n",
        "        if active:\n",
        "            if pred_prob > sel_best_dict[type2int[pred_win]]:\n",
        "                if match_id not in match_live_dict:\n",
        "                    match_live_dict[match_id] = {'nbets':0}\n",
        "\n",
        "                if bet_open(match_live_dict[match_id], match_minute, strategy = strategy_type,\n",
        "                            nbets = 3,\n",
        "                            last_type = pred_win, current_prob = pred_prob, prob_thres = 1.01):\n",
        "                    bet_size = 1 / line[pred_win + 1]\n",
        "                    final_goal_diff = results1 - results2\n",
        "\n",
        "                    if final_goal_diff == - line[0]:\n",
        "                        event_list = [0, 0]\n",
        "                        #event_list[pred_win] =  0\n",
        "                        output_list.append(event_list)\n",
        "                        date_list.append(match_time.date())\n",
        "                        bet_size_list.append(bet_size)\n",
        "                        match_live_dict[match_id]['last_bet_minute'] = match_minute\n",
        "                        match_live_dict[match_id]['nbets'] += 1\n",
        "                        match_live_dict[match_id]['last_type'] = pred_win\n",
        "                        match_live_dict[match_id]['last_prob'] = pred_prob\n",
        "                    elif pred_win.astype(bool) == (final_goal_diff + line[0] < 0):\n",
        "                        event_list = [0, 0]\n",
        "                        event_list[pred_win] =  bet_size * (line[pred_win + 1] - 1)\n",
        "                        output_list.append(event_list)\n",
        "                        date_list.append(match_time.date())\n",
        "                        bet_size_list.append(bet_size)\n",
        "                        match_live_dict[match_id]['last_bet_minute'] = match_minute\n",
        "                        match_live_dict[match_id]['nbets'] += 1\n",
        "                        match_live_dict[match_id]['last_type'] = pred_win\n",
        "                        match_live_dict[match_id]['last_prob'] = pred_prob\n",
        "                    else:\n",
        "                        event_list = [0, 0]\n",
        "                        event_list[pred_win] = -bet_size\n",
        "                        output_list.append(event_list)\n",
        "                        date_list.append(match_time.date())\n",
        "                        bet_size_list.append(bet_size)\n",
        "                        match_live_dict[match_id]['last_bet_minute'] = match_minute\n",
        "                        match_live_dict[match_id]['nbets'] += 1\n",
        "                        match_live_dict[match_id]['last_type'] = pred_win\n",
        "                        match_live_dict[match_id]['last_prob'] = pred_prob\n",
        "\n",
        "    layout_dict = {}\n",
        "    data_list = []\n",
        "    for hda, value_dict in hda_dict.items():\n",
        "        if hda != 'all':\n",
        "            data_list += [\n",
        "                go.Scatter(\n",
        "                    x = date_list,\n",
        "                    y = np.cumsum(np.array(output_list)[:, value_dict['order']]),\n",
        "                    name = hda,\n",
        "                    line = dict(color = value_dict['colors'], width = value_dict['line_width'], dash = value_dict['ltype'])\n",
        "                            )]\n",
        "    cumsum_all = np.cumsum(np.sum(np.array(output_list), axis = 1))\n",
        "    data_list += [\n",
        "        go.Scatter(\n",
        "            x = date_list,\n",
        "            y = cumsum_all,\n",
        "            name = 'all',\n",
        "            line = dict(color = hda_dict['all']['colors'], width = hda_dict['all']['line_width'], dash = hda_dict['all']['ltype'])\n",
        "                    )]\n",
        "\n",
        "    title_text = f'<b>Handicap (cv)</b>  equity curve for strategie <b><i>{strategy_type}</i></b>' + \\\n",
        "        f'<br>Model in neptune.ai: FOOT-{neptune_model_version}<br>' + \\\n",
        "        f\"ROI: {round(100 * cumsum_all[-1] / sum(bet_size_list), 2)}%\" + \\\n",
        "        f' | Bet quantity: {len(output_list)}<br>'\n",
        "    #dt_min = min(x_date[new_ard])\n",
        "    #dt_max = max(x_date[new_ard])\n",
        "    layout_dict.update({\n",
        "    'width':1200,\n",
        "    'height':800,\n",
        "    #'title_x':0.5,\n",
        "    'title_text':title_text,\n",
        "    'paper_bgcolor':'rgb(229, 237, 247)',\n",
        "    'plot_bgcolor':'rgb(229, 237, 247)',\n",
        "    #'xaxis':{'range':[dt_min, dt_max]}\n",
        "                    })\n",
        "    layout = go.Layout(**layout_dict)\n",
        "    return go.Figure(data=data_list, layout=layout) #, match_live_dict"
      ],
      "metadata": {
        "id": "o32ToxMiAvv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plot_strategy(\n",
        "    prob_dict,\n",
        "    line_dict,\n",
        "    results_dict,\n",
        "    active_rows_dict,\n",
        "    data_df,\n",
        "    strategy_type = 'changes', #'changes', #'nbets' #'5minute'\n",
        "    #neptune_model_version = neptune_model_version,\n",
        "    #data_split = 'validation',\n",
        "    #sel_best_dict = {'home':1.1465, 'draw':1.1465, 'away':1.1465}\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "HW-cn5VgBuW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JnoakdYG0WIm",
        "THFvsIdI6Jr_",
        "CNwNrot_8Otu",
        "3eJJjJHCyrNF",
        "F7qL3Au-nbm0",
        "TgahlHprQDfJ",
        "RtV7BR6vuXkz",
        "SDRXrXwouhLQ",
        "pE66BJ4-HO6j",
        "MUoqIhQIy5S_",
        "PgdUFeBSjddY",
        "i5feh_x-FJBR",
        "DNKb9PYxEgsP",
        "I0pA-BRAErQ7",
        "eSpGdYWkJNTD"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNpTrpVmcXxam1u68bYcVIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}