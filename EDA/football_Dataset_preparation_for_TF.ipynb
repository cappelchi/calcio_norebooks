{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cappelchi/calcio_notebooks/blob/main/EDA/football_Dataset_preparation_for_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZrPUmsapaC"
      },
      "source": [
        "#Data from 31.10.2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dEcqW_jH4pw"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r28X_apIH7fV"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import neptune.new as neptune\n",
        "except:\n",
        "    !pip install neptune-client >> None\n",
        "    import neptune.new as neptune\n",
        "\n",
        "def get_credential(frmwork = 'neptune_team'):\n",
        "    with open('credential.txt', 'r') as container:\n",
        "        for line in container:\n",
        "            if frmwork in line:\n",
        "                login, psw = line.split(' ')[1], line.split(' ')[2].split('\\n')[0]\n",
        "                return login, psw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lbLGj6xH9pw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f47c253-7e68-4af6-e597-e3f689f6a711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X69hHEsFix4n"
      },
      "source": [
        "### Downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_version = 'data_221101/'\n",
        "username, api_key = get_credential()\n",
        "project = neptune.init_project(\n",
        "    name=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "project[data_version + 'raw_data'].download('./results.rar')\n",
        "project.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408z2UIl0YlY",
        "outputId": "22f4b802-f370-4aef-85d5-cf144a1f1886"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RocnM6a5lPkc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj0B52SelRC1",
        "outputId": "5f44831a-4c87-4ace-ffee-c5c10df07b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 100\n",
        "print(pd.__version__)\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import functools\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUPuOvxtIe0t",
        "outputId": "272b8552-8992-41ea-a99f-b8a4a89fd2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2.0\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umm53OS2Ljgg"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQYi3DugHTw0"
      },
      "source": [
        "#### Load Dataset in DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bash(bashCommand:str, nameCommand = ''):\n",
        "        process = subprocess.Popen([bashCommand], \n",
        "                           shell=True)\n",
        "        _, error = process.communicate()\n",
        "        if error:\n",
        "            print(f'{nameCommand} error:\\n', error)"
      ],
      "metadata": {
        "id": "9ul7fQpn1ERI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bashCommand = f\"\"\"\n",
        "mkdir -p ./calcio/results\n",
        "unrar e ./results.rar ./calcio/results/\n",
        "\"\"\"\n",
        "run_bash(bashCommand, 'tar_wv') #word2vec_vs16_sg1.wordvectors.tar.gz"
      ],
      "metadata": {
        "id": "lRLcLhXY820w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHzZRsf-gtUo",
        "outputId": "0e1c053b-c5fa-439a-e3a8-6727e7dc49bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 29.3 s, sys: 3.81 s, total: 33.1 s\n",
            "Wall time: 34.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "start_date = '2008-01-01'\n",
        "end_date = '2022-09-30'\n",
        "data_csv_list = ['./calcio/results/' + str(dd).replace('-', '') + '.csv' \n",
        "                 for dd in pd.date_range(start=start_date, end=end_date).date]\n",
        "data_df = pd.concat(map(functools.partial(pd.read_csv, sep=';', compression=None),data_csv_list), ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tHrN0IUueAHp"
      },
      "outputs": [],
      "source": [
        "dups_list = list(data_df.Id.value_counts().index[data_df.Id.value_counts() > 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xO7a83hKhCNQ"
      },
      "outputs": [],
      "source": [
        "for dup in dups_list:\n",
        "    data_df.Id[data_df.Id == dup] = [id + str(cnt) for cnt, id in enumerate(data_df.Id[data_df.Id == dup])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8TFxAEYajSo",
        "outputId": "ef107115-b4b8-4e10-dd5b-107c9a7de33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-89294fdc2798>:1: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  data_df['timestamp'] = pd.to_datetime(data_df['BeginTime'], dayfirst = True).astype('int64') // 10**9\n"
          ]
        }
      ],
      "source": [
        "data_df['timestamp'] = pd.to_datetime(data_df['BeginTime'], dayfirst = True).astype('int64') // 10**9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NcrDt-KRYQkn"
      },
      "outputs": [],
      "source": [
        "data_df[['date', 'times_ext']] = data_df['BeginTime'].str.split(expand = True)\n",
        "data_df = data_df.drop(['BeginTime', 'times_ext'], axis = 'columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW_LqudwHbKQ"
      },
      "source": [
        "#### Refactoring DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hyJgri2YZVQR"
      },
      "outputs": [],
      "source": [
        "data_df['sum_score'] = data_df['Result1'] + data_df['Result2'] # Сумма голов в матче\n",
        "# Приводим все счета к сумме мячей в матче не больше 10 (adj)\n",
        "data_df['sum_score_k'] = [1 if score_k < 11 else score_k / 10 for score_k in data_df['sum_score']]\n",
        "data_df['home_score_adj'] = (data_df['Result1'] / data_df['sum_score_k']).astype(int)\n",
        "data_df['away_score_adj'] = (data_df['Result2'] / data_df['sum_score_k']).astype(int)\n",
        "data_df['score_adj'] = data_df['home_score_adj'].astype(str) + '-' + data_df['away_score_adj'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXATMwtGJTRO"
      },
      "source": [
        "#### Refactoring DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32yMhcwLwITF",
        "outputId": "fe0444c8-ee2f-4499-fb65-6292db979097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:03<00:00, 697868.20it/s]\n"
          ]
        }
      ],
      "source": [
        "winners_list = []\n",
        "for hm, aw in tqdm(data_df[['Result1', 'Result2']].values):\n",
        "    if hm > aw:\n",
        "        winners_list.append('H')\n",
        "    elif hm < aw:\n",
        "        winners_list.append('A')\n",
        "    else:\n",
        "        winners_list.append('D')\n",
        "data_df['Winner'] = winners_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xQDS-NYQvlAd"
      },
      "outputs": [],
      "source": [
        "data_df.HomeId = data_df.HomeId.astype(int)\n",
        "data_df.AwayId = data_df.AwayId.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AYGnZrMgTZlZ"
      },
      "outputs": [],
      "source": [
        "data_df = data_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZWMwlZuPRl8",
        "outputId": "0c6a9668-e586-4ae5-c8fa-6b17e9a5e9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Разнообразие результатов: 66\n",
            "Количество лиг: 1968\n",
            "Количество сезонов: 263\n",
            "Разнообразие типов встреч: 2403\n",
            "Количество стран: 202\n",
            "Повторно лиги: 1968\n"
          ]
        }
      ],
      "source": [
        "print(f'Разнообразие результатов: {len(data_df.score_adj.value_counts())}')\n",
        "print(f'Количество лиг: {len(data_df.League.value_counts())}')\n",
        "print(f'Количество сезонов: {len(data_df.Season.value_counts())}')\n",
        "print(f'Разнообразие типов встреч: {len(data_df.Round.value_counts())}')\n",
        "print(f'Количество стран: {len(data_df.Country.value_counts())}')\n",
        "print(f'Повторно лиги: {len(data_df.League.value_counts())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjC-GPlnMwKr"
      },
      "source": [
        "#### Расчитываем время прошедшее от прошлого матча и делаем словарик связей матчей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AqmBjr-3jSqj"
      },
      "outputs": [],
      "source": [
        "data_df = data_df.sort_values(by = 'timestamp').reset_index(drop = True)\n",
        "timestamp7days = 7 * 24 * 60 * 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_BSc9e_7ZIw",
        "outputId": "6069f2b7-cc4e-44ef-f046-b045e54fa1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:28<00:00, 93561.11it/s] \n"
          ]
        }
      ],
      "source": [
        "team_GId_dict = {}\n",
        "zero_diff = 0\n",
        "for info in tqdm(\n",
        "    zip(\n",
        "        data_df.timestamp,\n",
        "        data_df.HomeId,\n",
        "        data_df.AwayId,\n",
        "        data_df.Id,\n",
        "    ),\n",
        "    total=len(data_df),\n",
        "                    ):\n",
        "    time_stamp = info[0]\n",
        "    homeID = info[1]\n",
        "    awayID = info[2]\n",
        "    matchID = info[3]\n",
        "    # 1. Проверить если ID команды в словаре, если нет перейти к добавлению\n",
        "    if homeID in team_GId_dict:\n",
        "        # 2. Проверить время, если время позднее последнего добаления,\n",
        "        # то можно просто присоединить снизу, инфо о последнем матче команды,\n",
        "        # иначе перейти во вставку матча между матчами\n",
        "        if matchID not in team_GId_dict[homeID]:\n",
        "            if time_stamp >= team_GId_dict[homeID][\"last_time\"]:\n",
        "                # 3. Добавление матча для команды в словарь\n",
        "                previous_num = team_GId_dict[homeID][\"last_index\"]\n",
        "                previous_time = team_GId_dict[homeID][\"last_time\"]\n",
        "                # 4. Обновление блока последнего матча для команды\n",
        "                team_GId_dict[homeID][\"last_index\"] = matchID\n",
        "                team_GId_dict[homeID][\"last_time\"] = time_stamp\n",
        "                # 3. Добавление матча для команды в словарь\n",
        "                team_GId_dict[homeID].update(\n",
        "                    {\n",
        "                        matchID: [\n",
        "                            previous_num,\n",
        "                            time_stamp,\n",
        "                        ]\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                zero_diff += 1\n",
        "                # 5. Поиск точки вхождение для матча, который оказался не новым\n",
        "                current_index = team_GId_dict[homeID][\"last_index\"]\n",
        "                previous_match_time = team_GId_dict[homeID][current_index][1]\n",
        "                previous_index = team_GId_dict[homeID][current_index][0]\n",
        "                while (info[0] < previous_match_time) & (previous_index != -1):\n",
        "                    current_index = previous_index\n",
        "                    previous_index = team_GId_dict[homeID][previous_index][0]\n",
        "                    previous_match_time = team_GId_dict[homeID][current_index][1]\n",
        "                # 6. Вставка матча и обновление соседних 2 матчей\n",
        "                team_GId_dict[homeID].update(\n",
        "                    {matchID: [team_GId_dict[homeID][current_index][0], time_stamp]}\n",
        "                )\n",
        "                team_GId_dict[homeID].update(\n",
        "                    {current_index: [matchID, time_stamp]}\n",
        "                )\n",
        "\n",
        "    else:\n",
        "        # 3. Добавление матча для команды в словарь. Новая команда\n",
        "        team_GId_dict[homeID] = {\"last_index\": info[3]}\n",
        "        team_GId_dict[homeID].update({\"last_time\": time_stamp})\n",
        "        team_GId_dict[homeID].update(\n",
        "            {\n",
        "                matchID: [\n",
        "                    -1,\n",
        "                    time_stamp - timestamp7days\n",
        "                ]\n",
        "            }\n",
        "        )\n",
        "\n",
        "    #############################################################################\n",
        "    #############################################################################\n",
        "\n",
        "    if awayID in team_GId_dict:\n",
        "        # 2. Проверить время, если время позднее последнего добаления,\n",
        "        # то можно просто присоединить снизу, инфо о последнем матче команды,\n",
        "        # иначе перейти во вставку матча между матчами\n",
        "        if matchID not in team_GId_dict[awayID]:\n",
        "            if time_stamp >= team_GId_dict[awayID][\"last_time\"]:\n",
        "                # 3. Добавление матча для команды в словарь\n",
        "                previous_num = team_GId_dict[awayID][\"last_index\"]\n",
        "                previous_time = team_GId_dict[awayID][\"last_time\"]\n",
        "                # 4. Обновление блока последнего матча для команды\n",
        "                team_GId_dict[awayID][\"last_index\"] = matchID\n",
        "                team_GId_dict[awayID][\"last_time\"] = time_stamp\n",
        "                # 3. Добавление матча для команды в словарь\n",
        "                team_GId_dict[awayID].update(\n",
        "                    {\n",
        "                        matchID: [\n",
        "                            previous_num,\n",
        "                            time_stamp,\n",
        "                        ]\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                zero_diff += 1\n",
        "                # 5. Поиск точки вхождение для матча, который оказался не новым\n",
        "                current_index = team_GId_dict[awayID][\"last_index\"]\n",
        "                previous_match_time = team_GId_dict[awayID][current_index][1]\n",
        "                previous_index = team_GId_dict[awayID][current_index][0]\n",
        "                while (time_stamp < previous_match_time) & (previous_index != -1):\n",
        "                    current_index = previous_index\n",
        "                    previous_index = team_GId_dict[awayID][previous_index][0]\n",
        "                    previous_match_time = team_GId_dict[awayID][current_index][1]\n",
        "                # 6. Вставка матча и обновление соседних 2 матчей\n",
        "                team_GId_dict[awayID].update(\n",
        "                    {matchID: [team_GId_dict[awayID][current_index][0], time_stamp]}\n",
        "                )\n",
        "                team_GId_dict[awayID].update(\n",
        "                    {current_index: [matchID, time_stamp]}\n",
        "                )\n",
        "\n",
        "    else:\n",
        "        # 3. Добавление матча для команды в словарь. Новая команда\n",
        "        team_GId_dict[awayID] = {\"last_index\": info[3]}\n",
        "        team_GId_dict[awayID].update({\"last_time\": time_stamp})\n",
        "        team_GId_dict[awayID].update(\n",
        "            {\n",
        "                matchID: [\n",
        "                    -1,\n",
        "                    time_stamp - timestamp7days\n",
        "                ]\n",
        "            }\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkav57hyF4Aj",
        "outputId": "fc815bd8-5852-428d-d5d2-fdc9bdddb45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:07<00:00, 378542.02it/s]\n",
            "100%|██████████| 2703623/2703623 [00:07<00:00, 380970.16it/s]\n"
          ]
        }
      ],
      "source": [
        "data_df['team_rest_home'] = [team_GId_dict[team][idx][1] - team_GId_dict[team][team_GId_dict[team][idx][0]][1]\n",
        "                             if team_GId_dict[team][idx][0] != -1 else timestamp7days\n",
        "                             for team, idx in tqdm(zip(data_df.HomeId, data_df.Id), total = len(data_df))]\n",
        "data_df['team_rest_away'] = [team_GId_dict[team][idx][1] - team_GId_dict[team][team_GId_dict[team][idx][0]][1]\n",
        "                             if team_GId_dict[team][idx][0] != -1 else timestamp7days\n",
        "                             for team, idx in tqdm(zip(data_df.AwayId, data_df.Id), total = len(data_df))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GxqxJ6ty0Jb8"
      },
      "outputs": [],
      "source": [
        "# Отдых команд разделяем на 3 группы\n",
        "data_df['team_rest_home_adj'] = [0 if tm < 500_000 else 1 if tm < 1_000_000 else 2 for tm in data_df['team_rest_home']]\n",
        "data_df['team_rest_away_adj'] = [0 if tm < 500_000 else 1 if tm < 1_000_000 else 2 for tm in data_df['team_rest_away']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jSlMDhZr7WdP"
      },
      "outputs": [],
      "source": [
        "non_regular_slice = \\\n",
        "(data_df.League.str.contains('copa')) | \\\n",
        "(data_df.League.str.contains('coppa')) | \\\n",
        "(data_df.League.str.contains('cup')) | \\\n",
        "(data_df.League.str.contains('final')) | \\\n",
        "(data_df.League.str.contains('friend')) | \\\n",
        "(data_df.League.str.contains('play-off')) | \\\n",
        "(data_df.League.str.contains('qual')) | \\\n",
        "(data_df.League.str.contains('tourn')) | \\\n",
        "(data_df.League.str.contains('pokal'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nYe7GS1ANdbs"
      },
      "outputs": [],
      "source": [
        "data_df['local_match'] = 1\n",
        "data_df['local_match'][non_regular_slice] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZcoQED__rwf",
        "outputId": "ebe6aa3d-e09d-4c29-8205-38b5597994d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len_match_cat_dict4:  792\n",
            "none_idx4:  792\n"
          ]
        }
      ],
      "source": [
        "match_cat_dict4 = {}\n",
        "cnt4 = 1\n",
        "for home_score in range(11):\n",
        "    for away_score in range(11):\n",
        "        for home_place in range(2):\n",
        "            for regular_match in range(2):\n",
        "                for rest_time in range(3):\n",
        "                    if (home_score + away_score) < 11:\n",
        "                        match_cat_dict4[\n",
        "                            str(home_score) + '-' + \\\n",
        "                            str(away_score) + ':' + \\\n",
        "                            str(home_place) + ':' + \\\n",
        "                            str(regular_match) + ':' + \\\n",
        "                            str(rest_time)\n",
        "                                    ] = cnt4\n",
        "                        cnt4 += 1\n",
        "none_idx4 = max(match_cat_dict4.values())\n",
        "print('len_match_cat_dict4: ', len(match_cat_dict4))\n",
        "print('none_idx4: ', none_idx4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55dzOFoVNV0w",
        "outputId": "9f675d7e-1a86-4a19-a957-6947acef8d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:04<00:00, 595079.23it/s]\n"
          ]
        }
      ],
      "source": [
        "input_list = []\n",
        "for info in tqdm(zip(data_df['score_adj'], data_df['local_match'],   data_df['team_rest_home_adj']), total = len(data_df)):\n",
        "    cat_key = info[0] + ':' + '0' + ':' + str(info[1]) + ':' + str(info[2])\n",
        "    input_list.append(cat_key)\n",
        "#data_df['home_token3'] = input_list\n",
        "data_df['home_token4'] = input_list #data_df['home_token3'] + ':' +  data_df['team_rest_home_adj'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4kozJI5NaK_",
        "outputId": "bd48206d-a47b-4e5b-dc84-c1e9b5bcd045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:04<00:00, 615789.24it/s]\n"
          ]
        }
      ],
      "source": [
        "input_list = []\n",
        "for info in tqdm(zip(data_df['score_adj'], data_df['local_match'],  data_df['team_rest_away_adj']), total = len(data_df)):\n",
        "    cat_key = info[0] + ':' + '1' + ':' + str(info[1]) + ':' + str(info[2])\n",
        "    input_list.append(cat_key)\n",
        "data_df['away_token4'] = input_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppnlWS91ztwK",
        "outputId": "ace7e3c1-de56-46c3-fa44-0b9613845fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:01<00:00, 2238850.24it/s]\n",
            "100%|██████████| 2703623/2703623 [00:01<00:00, 1579334.39it/s]\n"
          ]
        }
      ],
      "source": [
        "data_df['home_idx'] = [match_cat_dict4[idx] for idx in tqdm(data_df['home_token4'], total = len(data_df))]\n",
        "data_df['away_idx'] = [match_cat_dict4[idx] for idx in tqdm(data_df['away_token4'], total = len(data_df))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64i-IrHsoCUg",
        "outputId": "091ebd7f-35cf-49ee-93d1-4e48f9d3e1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:10<00:00, 263158.31it/s]\n"
          ]
        }
      ],
      "source": [
        "for info in tqdm(zip(data_df.HomeId, data_df.AwayId, data_df.Id, data_df.home_idx, data_df.away_idx), total = len(data_df)):\n",
        "    homeID = info[0]\n",
        "    awayID = info[1]\n",
        "    matchID = info[2]\n",
        "    homeIDX = info[3]\n",
        "    awayIDX = info[4]\n",
        "    team_GId_dict[homeID][matchID] += [homeIDX]\n",
        "    team_GId_dict[awayID][matchID] += [awayIDX]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgLE25W5Nsuh"
      },
      "source": [
        "#### Кодируем вектор истории произвольной глубины"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ULj3r9CZqtMN"
      },
      "outputs": [],
      "source": [
        "def idx_recursive(current_team:int, \n",
        "                  current_index:int,\n",
        "                  loop_back:int,\n",
        "                  main_dict = team_GId_dict,\n",
        "                  final_list = None) -> list:\n",
        "    if final_list is None:\n",
        "        final_list = []\n",
        "    previous_index = main_dict[current_team][current_index][0]\n",
        "    if previous_index == -1:\n",
        "        final_list = [0] * loop_back\n",
        "        return final_list\n",
        "        \n",
        "    previous_idx = main_dict[current_team][previous_index][2]\n",
        "    loop_back -=1\n",
        "    if loop_back > 0:    \n",
        "        final_list = idx_recursive(current_team,\n",
        "                                   previous_index,\n",
        "                                   loop_back,\n",
        "                                   main_dict = main_dict,\n",
        "                                   final_list = final_list)\n",
        "    final_list.append(previous_idx)\n",
        "    return final_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jESyCLlHUVhG",
        "outputId": "7bacf996-b8d3-406d-ca9e-ae496eb20fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:42<00:00, 64152.50it/s]\n"
          ]
        }
      ],
      "source": [
        "look_back = 10\n",
        "input_list = []\n",
        "for idx in tqdm(zip(data_df.Id, data_df['HomeId']),\n",
        "                total = len(data_df)):\n",
        "\n",
        "    input_list.append(  \n",
        "        idx_recursive(\n",
        "            idx[1], \n",
        "            idx[0],\n",
        "            look_back,\n",
        "                      )[::-1])\n",
        "data_df[[f'home_input_{num}' for num in range(1, 1 + look_back)]] = input_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNDfK7wLtYpc",
        "outputId": "68aa6718-cd48-42e0-d8fb-379d53b0f716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:47<00:00, 56983.40it/s]\n"
          ]
        }
      ],
      "source": [
        "look_back = 10\n",
        "input_list = []\n",
        "for idx in tqdm(zip(data_df.Id, data_df['AwayId']),\n",
        "                total = len(data_df)):\n",
        "\n",
        "    input_list.append(  \n",
        "        idx_recursive(\n",
        "            idx[1], \n",
        "            idx[0],\n",
        "            look_back,\n",
        "                      )[::-1])\n",
        "data_df[[f'away_input_{num}' for num in range(1, 1 + look_back)]] = input_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Tb2e0AOZjp"
      },
      "source": [
        "#### Encoding output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O9UggXA-Roz5"
      },
      "outputs": [],
      "source": [
        "data_df['binary_output'] = 0\n",
        "data_df['binary_output'][data_df['Winner'] == 'H'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tn95_Yi1RR3I"
      },
      "outputs": [],
      "source": [
        "data_df['class_H'] = 0\n",
        "data_df['class_D'] = 0\n",
        "data_df['class_A'] = 0\n",
        "data_df['class_H'][data_df['Winner'] == 'H'] = 1\n",
        "data_df['class_D'][data_df['Winner'] == 'D'] = 1\n",
        "data_df['class_A'][data_df['Winner'] == 'A'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pcvaXXpJhktx"
      },
      "outputs": [],
      "source": [
        "data_ready_columns = [\n",
        "         'date',\n",
        "         'timestamp',\n",
        "         'Id',\n",
        "         'local_match',\n",
        "         'team_rest_home_adj',  \n",
        "         'home_input_1', \n",
        "         'home_input_2', \n",
        "         'home_input_3', \n",
        "         'home_input_4', \n",
        "         'home_input_5', \n",
        "         'home_input_6', \n",
        "         'home_input_7', \n",
        "         'home_input_8', \n",
        "         'home_input_9', \n",
        "         'home_input_10', \n",
        "         'team_rest_away_adj', \n",
        "         'away_input_1', \n",
        "         'away_input_2', \n",
        "         'away_input_3', \n",
        "         'away_input_4', \n",
        "         'away_input_5', \n",
        "         'away_input_6', \n",
        "         'away_input_7', \n",
        "         'away_input_8', \n",
        "         'away_input_9', \n",
        "         'away_input_10',\n",
        "         'binary_output', \n",
        "         'class_H',\n",
        "         'class_D', \n",
        "         'class_A']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ODwS3mnpelNu"
      },
      "outputs": [],
      "source": [
        "data_version = 'data_221101/'\n",
        "username, api_key = get_credential()\n",
        "upload = False\n",
        "if upload:\n",
        "    import pickle\n",
        "    with open(\"./team_GId_dict.pickle\", \"wb\") as f:\n",
        "        pickle.dump(team_GId_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(\"./match_cat_dict4.pickle\", \"wb\") as f:\n",
        "        pickle.dump(match_cat_dict4, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    data_df[data_ready_columns].to_csv('./data_ready.csv.gz', compression ={'method':'gzip'}, index = None)\n",
        "    dataset_params = {}\n",
        "    dataset_params['description'] = ''\n",
        "    project = neptune.init_project(\n",
        "        name=\"scomesse/football\", \n",
        "        api_token = api_key\n",
        "        )\n",
        "    project[data_version + 'team_GId_dict'].upload('./team_GId_dict.pickle')\n",
        "    project[data_version + 'match_cat_dict4'].upload('./match_cat_dict4.pickle')\n",
        "    project[data_version + 'data_ready'].upload('./data_ready.csv.gz')\n",
        "    project[data_version + 'params'] = dataset_params\n",
        "    project.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8O1i22K12Es"
      },
      "source": [
        "####Create new Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQrjajRlOtsv",
        "outputId": "2e891044-37b6-490f-fcf1-f48c30388f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ],
      "source": [
        "word2vec_is_ready = True\n",
        "if word2vec_is_ready:\n",
        "    data_version = 'data_221101/'\n",
        "    username, api_key = get_credential()\n",
        "    project = neptune.init_project(\n",
        "        name=\"scomesse/football\", \n",
        "        api_token = api_key\n",
        "        )\n",
        "    project[data_version + 'word2vec'].download('./word2vec.wordvectors.tar.gz')\n",
        "    word2vec_params = project[data_version + 'word2vec_params'].fetch()\n",
        "    project.stop()\n",
        "\n",
        "    def run_bash(bashCommand:str, nameCommand = ''):\n",
        "            process = subprocess.Popen([bashCommand], \n",
        "                            shell=True)\n",
        "            _, error = process.communicate()\n",
        "            if error:\n",
        "                print(f'{nameCommand} error:\\n', error)\n",
        "    bashCommand = f\"\"\"\n",
        "    tar -zxvf ./word2vec.wordvectors.tar.gz \n",
        "    \"\"\"\n",
        "    run_bash(bashCommand, 'tar_wv')\n",
        "    from gensim.models import KeyedVectors\n",
        "    wv = KeyedVectors.load('./word2vec_vs16_sg1.wordvectors', mmap='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "A7PF9uHs5txz"
      },
      "outputs": [],
      "source": [
        "names =['home_input_1', \n",
        "         'home_input_2', \n",
        "         'home_input_3', \n",
        "         'home_input_4', \n",
        "         'home_input_5', \n",
        "         'home_input_6', \n",
        "         'home_input_7', \n",
        "         'home_input_8', \n",
        "         'home_input_9', \n",
        "         'home_input_10',\n",
        "         'away_input_1', \n",
        "         'away_input_2', \n",
        "         'away_input_3', \n",
        "         'away_input_4', \n",
        "         'away_input_5', \n",
        "         'away_input_6', \n",
        "         'away_input_7', \n",
        "         'away_input_8', \n",
        "         'away_input_9', \n",
        "         'away_input_10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZa1SuU655vN",
        "outputId": "340d8452-2f23-419b-b8d7-f18616844d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2703623/2703623 [00:30<00:00, 87248.39it/s] \n"
          ]
        }
      ],
      "source": [
        "# каждый и строку историй для каждой команды в матче переводим в list, условное строковое предложение\n",
        "# далее для этих предложений или корпуса предложений создаём word2vec модель\n",
        "corpus = []\n",
        "for document in tqdm(data_df[names].values, total = len(data_df)):\n",
        "    #words = [tokenizer[word] for word in document if word != 0]\n",
        "    words = [word for word in document if word != 0]\n",
        "    if words:\n",
        "        corpus.append(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBX10YRj6_9B"
      },
      "source": [
        "<img src=\"https://api.monosnap.com/file/download?id=lq8rws2WsGIDPxadAfE9VA5lqv5VvK\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G51W25RS6pr6",
        "outputId": "c9eab7f1-2a9c-4406-827c-13b653ce9996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec trained model KeyedVectors<vector_size=16, 792 keys>\n",
            "./word2vec.wordvectors\n"
          ]
        }
      ],
      "source": [
        "#@title Create new Word2Vec model\n",
        "create_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "if create_model:\n",
        "    # Using params from Word2Vec_FastText_Comparison\n",
        "    #EMBEDDING_DIM = 256\n",
        "    word2vec_params = {\n",
        "        #'alpha': 0.05,\n",
        "        'vector_size': 16,\n",
        "        'window': 20,\n",
        "        'epochs': 5,\n",
        "        'min_count': 1,\n",
        "        #'sample': 1e-4,\n",
        "        'sg': 1,\n",
        "        'hs': 0,\n",
        "        #'negative': 5,\n",
        "    }\n",
        "    model = Word2Vec(corpus, **word2vec_params)\n",
        "    wv = model.wv\n",
        "    print(\"Word2Vec trained model\", wv)\n",
        "    vectors_path = './word2vec.wordvectors'\n",
        "    wv.save(vectors_path)\n",
        "    !tar -zcvf {vectors_path}.tar.gz {vectors_path}*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3byZTqXUdOB",
        "outputId": "dc9b9a9a-3232-4f7d-8c30-9dcd07127365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 7 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 7 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ],
      "source": [
        "if create_model:\n",
        "    data_version = 'data_221101/'\n",
        "    vectors_path = './word2vec_vs16_sg1.wordvectors'\n",
        "\n",
        "    username, api_key = get_credential()\n",
        "    upload = True\n",
        "    if upload:\n",
        "        project = neptune.init_project(\n",
        "            name=\"scomesse/football\", \n",
        "            api_token = api_key\n",
        "            )\n",
        "        project[data_version + 'word2vec'].upload(f'{vectors_path}.tar.gz')\n",
        "        project[data_version+ 'word2vec_params'] = word2vec_params\n",
        "        project.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создаём матрицу векторов слов из word2vec модели\n",
        "# а потом вектор слова будем индексировать по словарю из след. ячейки\n",
        "# (wv.index_to_key) или word ->  слово у нас представлено цифрой\n",
        "embedding_matrix = np.zeros((len(wv.index_to_key) + 1, word2vec_params['vector_size']))\n",
        "for num in tqdm(range(len(wv.index_to_key)), total = len(wv.index_to_key)):\n",
        "    embedding_matrix[num + 1] = wv[wv.index_to_key[num]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXSLJnDJ4LCr",
        "outputId": "5bc0742f-0420-40a4-b4f2-22d586db0376"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792/792 [00:00<00:00, 123835.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KAdOsapYY-ZO"
      },
      "outputs": [],
      "source": [
        "idx_arr = np.zeros(max(wv.key_to_index) + 1)\n",
        "for key, value in wv.key_to_index.items():\n",
        "    idx_arr[key] = value + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NCZFEMGPN5-h"
      },
      "outputs": [],
      "source": [
        "val_date = pd.to_datetime('2022-01-01').timestamp()\n",
        "train_date = pd.to_datetime('2019-01-01').timestamp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0VAuEKaZrWx",
        "outputId": "f7ea22dc-e961-4d3f-b711-9bab346efb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1923326 582753 197544\n"
          ]
        }
      ],
      "source": [
        "val_date = pd.to_datetime('2022-01-01').timestamp()\n",
        "train_date = pd.to_datetime('2019-01-01').timestamp()\n",
        "validation_vector = (data_df['timestamp'] > val_date).values\n",
        "test_vector = ((data_df['timestamp'] < val_date) & (data_df['timestamp'] > train_date)).values\n",
        "train_vector = (data_df['timestamp'] < train_date).values\n",
        "print(train_vector.sum(), test_vector.sum(), validation_vector.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SEZz6AatZImr"
      },
      "outputs": [],
      "source": [
        "# Делим трейн -тест - валидация\n",
        "X_train = idx_arr[data_df[names][train_vector].values].astype(int)\n",
        "X_test = idx_arr[data_df[names][test_vector].values].astype(int)\n",
        "X_validation = idx_arr[data_df[names][validation_vector].values].astype(int)\n",
        "\n",
        "# Our target variable\n",
        "y_train = data_df['binary_output'][train_vector].values\n",
        "y_test = data_df['binary_output'][test_vector].values\n",
        "y_validation = data_df['binary_output'][validation_vector].values\n",
        "\n",
        "# Our target variable\n",
        "y_class_train = data_df[['class_H', 'class_D', 'class_A']][train_vector].values\n",
        "y_class_test = data_df[['class_H', 'class_D', 'class_A']][test_vector].values\n",
        "y_class_validation = data_df[['class_H', 'class_D', 'class_A']][validation_vector].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czlLCgPY1fxB",
        "outputId": "e191f8f9-f58c-43bb-d909-7d0dfce6c448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "All 0 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ],
      "source": [
        "# Обрабатываем кэфы, для последующих валидаций\n",
        "data_version = 'data_221101/'\n",
        "project = neptune.init_project(\n",
        "    name=\"scomesse/football\", \n",
        "    api_token = api_key\n",
        "    )\n",
        "project[data_version + 'SwCoefs'].download('./SwCoefs.csv')\n",
        "project.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './SwCoefs.csv'"
      ],
      "metadata": {
        "id": "OJJsDLbDH2zU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mnn3Dy2A2ojV"
      },
      "outputs": [],
      "source": [
        "perm_df = pd.read_csv(file_path , sep = ';')\n",
        "perm_df = perm_df.drop_duplicates(subset = ['Id'], keep = False)\n",
        "perm_df = perm_df[perm_df[['LW1', 'LX', 'LW2']].notna().all(axis = 1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nII5jUGo5cTN"
      },
      "outputs": [],
      "source": [
        "production_vector = data_df.Id.isin(perm_df.Id)\n",
        "X_production = idx_arr[data_df[names][production_vector].values].astype(int)\n",
        "y_production = data_df['binary_output'][production_vector].values\n",
        "y_class_production = data_df[['class_H', 'class_D', 'class_A']][production_vector].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5tNap8vJOCt9"
      },
      "outputs": [],
      "source": [
        "perm_df.set_index('Id').reindex(\n",
        "                data_df['Id'][production_vector]\n",
        "                                ).to_csv(f'{file_path.replace(\".csv\", \"\")}_filtered.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "K5_X29x5P5Z1"
      },
      "outputs": [],
      "source": [
        "line_array = perm_df.set_index('Id')[\n",
        "    ['LW1', 'LX', 'LW2']\n",
        "            ].reindex(\n",
        "                data_df['Id'][production_vector]\n",
        "                                ).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jm_twr-m0awh"
      },
      "outputs": [],
      "source": [
        "npz_name = 'dataset'\n",
        "np.savez_compressed('./' + npz_name, \n",
        "                    X_train = X_train, X_test = X_test, X_validation = X_validation,\n",
        "                    X_production = X_production,\n",
        "                    y_train = y_train, y_test = y_test, y_validation = y_validation,\n",
        "                    y_production = y_production,\n",
        "                    y_class_train = y_class_train, y_class_test = y_class_test,\n",
        "                    y_class_validation = y_class_validation,\n",
        "                    y_class_production = y_class_production,\n",
        "                    Line_production = line_array,\n",
        "                    embedding_matrix = embedding_matrix\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGR0FpP2EyA0",
        "outputId": "b279aec4-4869-4577-9033-3d082be416db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 1 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ],
      "source": [
        "npz_upload = False\n",
        "if npz_upload:\n",
        "    data_version = 'data_221212/'\n",
        "    project = neptune.init_project(\n",
        "        name=\"scomesse/football\", \n",
        "        api_token = api_key\n",
        "        )\n",
        "    project[data_version + npz_name +'_npz'].upload('./' + npz_name + '.npz')\n",
        "    project.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "wxw_SnriNPF2"
      },
      "outputs": [],
      "source": [
        "perm_df = perm_df.set_index('Id').reindex(\n",
        "                data_df['Id'][production_vector]\n",
        "                                )\n",
        "hasprem_vector = (perm_df.HasPrem.values == 'F')\n",
        "tier2_vector = (perm_df.Tier.values == 2)\n",
        "tier3_vector = (perm_df.Tier.values == 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6m5ZFk6QQw65"
      },
      "outputs": [],
      "source": [
        "vector_name = 'vectors'\n",
        "np.savez_compressed('./' + vector_name, \n",
        "                    hasprem_vector = hasprem_vector,\n",
        "                    tier2_vector = tier2_vector,\n",
        "                    tier3_vector = tier3_vector\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79LkMb3yQkLa",
        "outputId": "9d82506b-f8ce-474b-9986-57b6beed1d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/scomesse/football/\n",
            "Remember to stop your project once you’ve finished logging your metadata (https://docs.neptune.ai/api/project#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 1 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/scomesse/football/metadata\n"
          ]
        }
      ],
      "source": [
        "special_vectors_upload = False:\n",
        "if special_vectors_upload:\n",
        "    data_version = 'data_221212/'\n",
        "    project = neptune.init_project(\n",
        "        name=\"scomesse/football\", \n",
        "        api_token = api_key\n",
        "        )\n",
        "    project[data_version + vector_name].upload('./' + vector_name + '.npz')\n",
        "    project.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7dEcqW_jH4pw",
        "X69hHEsFix4n",
        "RocnM6a5lPkc",
        "iQYi3DugHTw0",
        "BW_LqudwHbKQ",
        "aXATMwtGJTRO",
        "YjC-GPlnMwKr",
        "VgLE25W5Nsuh",
        "O_Tb2e0AOZjp"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPzMetDm/SCCWw2Y8wzWI8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}